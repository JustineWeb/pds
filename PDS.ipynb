{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import itertools\n",
    "\n",
    "import progressbar\n",
    "from time import sleep\n",
    "\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTT_DIR = \"../MTT/\"\n",
    "DATA_DIRECTORY = MTT_DIR + \"dataset/\"\n",
    "# CSV containing song details (title, artist, id, mp3_path,...)\n",
    "CLIP_INFO_FINAL = \"clip_info_final.csv\"\n",
    "# CSV containg the labels (clip_id, labels, mp3_path)\n",
    "ANNOTATIONS_FINAL = \"annotations_final.csv\"\n",
    "# CSV : what is it useful for ?\n",
    "COMPARISONS_FINAL = \"comparisons_final.csv\"\n",
    "LABELS_FILE = MTT_DIR + ANNOTATIONS_FINAL\n",
    "\n",
    "SUB_DIRS = \"0123456789abcdef\"\n",
    "\n",
    "AUDIO1_path = \"../MTT/mtt_data_mp3.zip/0/american_bach_soloists-j_s__bach_\\\n",
    "_transcriptions_of_italian_music-02-concerto_in_a_minor_for_four_harpsichords\\\n",
    "_bwv_1065_ii_largo-88-117.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NB = 25880 #25863\n",
    "FILE_LENGTH = 465984\n",
    "# 465984 = 2 × 2 × 2 × 2 × 2 × 2 × 3 × 3 × 809\n",
    "# useful for batches > for now divide by 9 (instead of 10)\n",
    "\n",
    "BATCH_NB = 9\n",
    "BATCH_SIZE = int(FILE_LENGTH/BATCH_NB)\n",
    "SAMPLE_SIZE = 0\n",
    "SAMPLE_RATE = 16000\n",
    "RECEPTIVE_FIELD = 0\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "BASIC_CONFIG ={'numOutputNeurons':500}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading tool functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(labels_file_name):\n",
    "    pd.read_csv(labels_file_name)\n",
    "\n",
    "#def load_1label(labels_file_name):\n",
    " #   data = pd.read_csv(labels_file_name)\n",
    "  #  print(data.head())\n",
    "\n",
    "def randomize_files(files):\n",
    "    for file in files:\n",
    "        file_index = random.randint(0, (len(files) - 1))\n",
    "        yield files[file_index]\n",
    "        \n",
    "def load_generic_audio(directory, sample_rate):\n",
    "    '''Generator that yields audio waveforms from the directory.'''\n",
    "    files = find_files(directory)\n",
    "    # format of content of files :\n",
    "    # <../MTT/dataset/9/the_kokoon-berlin-07-sm_art-146-175.mp3>\n",
    "    # files[i][len(DATA_DIRECTORY):] extract the part corresponding\n",
    "    # to mp3_path in annotations csv :  <9/the_kokoon-berlin-07-sm_art-146-175.mp3>\n",
    "\n",
    " #   x = load_1label(LABELS_FILE)\n",
    "  #  return \n",
    "    #print(\"files length: {}\".format(len(files)))\n",
    "   # randomized_files = randomize_files(files)\n",
    "    count = 0\n",
    "   # for filename in randomized_files:\n",
    "    for filename in files:\n",
    "\n",
    "        try :\n",
    "            audio, _ = librosa.load(filename, sr=sample_rate, mono=True)\n",
    "            audio = audio.reshape(-1, 1)\n",
    "            count +=1\n",
    "            yield audio, filename, count\n",
    "        except EOFError :\n",
    "            print(\"EOFERROR : The following file could not be loaded with librosa - \", filename)\n",
    "\n",
    "\n",
    "\n",
    "def find_files(directory, pattern='*.mp3', sample=None):\n",
    "    '''Recursively finds all files matching the pattern.'''\n",
    "    files = []\n",
    "    for root, dirnames, filenames in os.walk(directory):\n",
    "        for filename in fnmatch.filter(filenames, pattern):\n",
    "            files.append(os.path.join(root, filename))\n",
    "    if sample!=None :\n",
    "        try:\n",
    "            return files[:sample]\n",
    "        except TypeError:\n",
    "            print(\"Argument sample should be either None, or an integer :\\\n",
    "             the number of first n samples to take.\")\n",
    "    else :\n",
    "        return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean labels for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv(LABELS_FILE, sep = '\"\\t\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare header to put back in the end\n",
    "# remove quotes and take all columns except the first one\n",
    "header = list(map(lambda x : x.replace('\"', ''), labels))[1:]\n",
    "# add back the first column, separated in two\n",
    "header = ['clip_id', 'no_voice']+header\n",
    "# create dictionary\n",
    "header = dict(enumerate(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_id</th>\n",
       "      <th>no_voice</th>\n",
       "      <th>singer</th>\n",
       "      <th>duet</th>\n",
       "      <th>plucking</th>\n",
       "      <th>hard rock</th>\n",
       "      <th>world</th>\n",
       "      <th>bongos</th>\n",
       "      <th>harpsichord</th>\n",
       "      <th>female singing</th>\n",
       "      <th>...</th>\n",
       "      <th>rap</th>\n",
       "      <th>metal</th>\n",
       "      <th>hip hop</th>\n",
       "      <th>quick</th>\n",
       "      <th>water</th>\n",
       "      <th>baroque</th>\n",
       "      <th>women</th>\n",
       "      <th>fiddle</th>\n",
       "      <th>english</th>\n",
       "      <th>mp3_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  clip_id no_voice singer duet plucking hard rock world bongos harpsichord  \\\n",
       "0       2        0      0    0        0         0     0      0           0   \n",
       "1       6        0      0    0        0         0     0      0           0   \n",
       "2      10        0      0    0        0         0     0      0           0   \n",
       "3      11        0      0    0        0         0     0      0           0   \n",
       "4      12        0      0    0        0         0     0      0           0   \n",
       "\n",
       "  female singing                        ...                         rap metal  \\\n",
       "0              0                        ...                           0     0   \n",
       "1              0                        ...                           0     0   \n",
       "2              0                        ...                           0     0   \n",
       "3              0                        ...                           0     0   \n",
       "4              0                        ...                           0     0   \n",
       "\n",
       "  hip hop quick water baroque women fiddle english  \\\n",
       "0       0     0     0       0     0      0       0   \n",
       "1       0     0     0       1     0      0       0   \n",
       "2       0     0     0       0     0      0       0   \n",
       "3       0     0     0       0     0      0       0   \n",
       "4       0     0     0       0     0      0       0   \n",
       "\n",
       "                                            mp3_path  \n",
       "0  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "1  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "2  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "3  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "4  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solve format problem : two first columns are merged\n",
    "# extract first column and rest\n",
    "left, right = labels['\"clip_id\\t\"\"no voice\"'], labels.iloc[:, 1:]\n",
    "# split first column in two part at separator \"\\t\"\n",
    "split = left.str.split(pat = \"\\t\", expand=True).replace('\"', '')\n",
    "\n",
    "# put back the first column which is now two, with the rest\n",
    "cleaned = pd.concat([split, right], axis=1, ignore_index=True) \n",
    "# clean by removing quotes and add back header\n",
    "cleaned = cleaned.apply(lambda col : col.apply(lambda x : x.replace('\"', ''))).rename(columns = header)\n",
    "cleaned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : Some statistics on the MTT dataset ?\n",
    "nb_labels_per_song = cleaned.iloc[:,1:-1].astype(int).sum(axis=1)\n",
    "nb_song_per_label = cleaned.iloc[:,1:-1].astype(int).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs :  25863\n",
      "Number of labels :  190\n",
      "Max number of songs tagged with the same label :  4852\n",
      "Max number of labels for a single song :  27\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of songs : \" , cleaned.shape[0])\n",
    "print(\"Number of labels : \" , cleaned.shape[1])\n",
    "print(\"Max number of songs tagged with the same label : \",max(nb_song_per_label))\n",
    "print(\"Max number of labels for a single song : \",max(nb_labels_per_song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(nb_labels_per_song)#, bins = [0,20,40,60,80,100]) \n",
    "#plt.title(\"histogram\") \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25863, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_labels = cleaned[['clip_id', 'no_voice', 'singer', 'mp3_path']]\n",
    "sample_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and format mp3 data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = load_generic_audio(DATA_DIRECTORY, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : not efficient to \n",
    "# - give the whole label dataset to the function as argument\n",
    "# - look in the label dataset at each iteration to retrieve the label\n",
    "#   > should concat before randomize\n",
    "# - append to an array and then convert to numpy ? > check\n",
    "\n",
    "def load_audio_label(labels, directory, sample_rate, num_songs):\n",
    "    files = find_files(directory, sample=num_songs)\n",
    "        # format of content of files :\n",
    "        # <../MTT/dataset/9/the_kokoon-berlin-07-sm_art-146-175.mp3>\n",
    "        # files[i][len(DATA_DIRECTORY):] extract the part corresponding\n",
    "        # to mp3_path in annotations csv :  <9/the_kokoon-berlin-07-sm_art-146-175.mp3>\n",
    "\n",
    "     #   x = load_1label(LABELS_FILE)\n",
    "      #  return \n",
    "        #print(\"files length: {}\".format(len(files)))\n",
    "    randomized_files = randomize_files(files)\n",
    "    count = 0\n",
    "    audios = np.ndarray(shape=(num_songs, BATCH_NB, BATCH_SIZE, 1), dtype=float, order='F')\n",
    "    tags = np.ndarray(shape=(num_songs, BATCH_NB, labels.shape[1]-2, 1), dtype=float, order='F')\n",
    "    \n",
    "    for filename in randomized_files:\n",
    "    #    for filename in files:\n",
    "\n",
    "        #if count > 200 :\n",
    "         #   return\n",
    "        \n",
    "        try :\n",
    "            audio, _ = librosa.load(filename, sr=sample_rate, mono=True)\n",
    "        except EOFError :\n",
    "            print(\"EOFERROR : The following file could not be loaded with librosa - \", filename)\n",
    "        #print(audio)\n",
    "        audio = audio.reshape(-1, 1)\n",
    "        #print(audio)\n",
    "        #create batches\n",
    "        audio_batch = np.ndarray(shape=(BATCH_NB, BATCH_SIZE, 1), dtype=float, order='F')\n",
    "        label_batch = np.ndarray(shape=(BATCH_NB, labels.shape[1]-2, 1), dtype=float, order='F')\n",
    "        for n in range(BATCH_NB) :\n",
    "            audio_batch[n] = audio[n*BATCH_SIZE: (n+1)*BATCH_SIZE,:]\n",
    "            label_batch[n] = labels.loc[labels['mp3_path']==filename[len(DATA_DIRECTORY):]] \\\n",
    "                               .values[:, 1:-1].reshape(labels.shape[1]-2,1)\n",
    "        #print(len(audio_batch), len(audio_batch[0]), len(audio_batch[0][0]))\n",
    "        \n",
    "        #audios.append(audio_batch) \n",
    "        audios[count] = audio_batch\n",
    "        tags[count] = label_batch\n",
    "        \n",
    "        count +=1\n",
    "        if (count % 100) == 0:\n",
    "            print(count)\n",
    "            #print(\"AUDIO : \", audio)\n",
    "            #print(\"LABELS : \", labels.loc[labels['mp3_path']==filename[len(DATA_DIRECTORY):]])\n",
    "            #print(\"FILENAME :\", filename)\n",
    "         \n",
    "        # TODO : create batches > here or later to rereandomize the order ?\n",
    "\n",
    "        #print()\n",
    "        \n",
    "        \n",
    "    return audios, tags\n",
    "        #yield audio, labels, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load audios and labels > convert to numpy\n",
    "# CAREFUL : the argument num_songs is important and shouldn't be too big \n",
    "# > otherwise MEMORY ISSUES !!!!!!\n",
    "audios_sample, tags_sample = load_audio_label(sample_labels, DATA_DIRECTORY, None, num_songs = 3)\n",
    "#audios_sample = np.asarray(audios_sample)\n",
    "tags_sample = np.asarray(tags_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of audios list :\n",
      "(3, 9, 51776, 1)\n",
      "\n",
      ">> shape is : [num_song, num_batches, batch_size, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of audios list :\")\n",
    "print(audios_sample.shape)\n",
    "print()\n",
    "print(\">> shape is : [num_song, num_batches, batch_size, 1]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tags list :\n",
      "(3, 9, 2, 1)\n",
      "\n",
      ">> shape is : [num_song, num_labels (mp3 file and id excluded), 1] \n",
      "(or : [num_song, num_labels, 1, str_len, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of tags list :\")\n",
    "print(tags_sample.shape)\n",
    "print()\n",
    "print(\">> shape is : [num_song, num_labels (mp3 file and id excluded), 1] \")\n",
    "print(\"(or : [num_song, num_labels, 1, str_len, 1])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all batches at the same level (remove song dimension in the array)\n",
    "# ex : go from dimensions (3, 9, 51776, 1) > to (27, 51776, 1)\n",
    "audios_sample_flatten = audios_sample.reshape(-1, audios_sample.shape[-2], audios_sample.shape[-1])\n",
    "tags_sample_flatten = tags_sample.reshape(-1, tags_sample.shape[-2], tags_sample.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 1)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice_no_voice = tags_sample_flatten[:,1,:]\n",
    "voice_no_voice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXAMPLE FROM TOWARDS DATASCIENCE\n",
    "    #EPOCHS = 10\n",
    "    #BATCH_SIZE = 16\n",
    "    ## using two numpy arrays\n",
    "    #features, labels = (np.array([np.random.sample((100,2))]), \n",
    "    #                    np.array([np.random.sample((100,1))]))\n",
    "    #dataset = tf.data.Dataset.from_tensor_slices((features,labels)).repeat().batch(BATCH_SIZE)\n",
    "    #iter = dataset.make_one_shot_iterator()\n",
    "    #x, y = iter.get_next()\n",
    "    ## make a simple model\n",
    "    #net = tf.layers.dense(x, 8, activation=tf.tanh) # pass the first value from iter.get_next() as input\n",
    "    #net = tf.layers.dense(net, 8, activation=tf.tanh)\n",
    "    #prediction = tf.layers.dense(net, 1, activation=tf.tanh)\n",
    "    #loss = tf.losses.mean_squared_error(prediction, y) # pass the second value from iter.get_net() as label\n",
    "    #train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "    #with tf.Session() as sess:\n",
    "    #    sess.run(tf.global_variables_initializer())\n",
    "    #    for i in range(EPOCHS):\n",
    "    #        _, loss_value = sess.run([train_op, loss])\n",
    "    #        print(\"Iter: {}, Loss: {:.4f}\".format(i, loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 51776, 1)\n",
      "Iter: 0, Loss: 0.3362\n",
      "Iter: 1, Loss: 0.2398\n",
      "Iter: 2, Loss: 0.1775\n",
      "Iter: 3, Loss: 0.1845\n",
      "Iter: 4, Loss: 0.2480\n",
      "Iter: 5, Loss: 0.2809\n",
      "Iter: 6, Loss: 0.1809\n",
      "Iter: 7, Loss: 0.1597\n",
      "Iter: 8, Loss: 0.2054\n",
      "Iter: 9, Loss: 0.1596\n",
      "Iter: 10, Loss: 0.1308\n",
      "Iter: 11, Loss: 0.2189\n",
      "Iter: 12, Loss: 0.2347\n",
      "Iter: 13, Loss: 0.1724\n",
      "Iter: 14, Loss: 0.2413\n",
      "Iter: 15, Loss: 0.1937\n",
      "Iter: 16, Loss: 0.1857\n",
      "Iter: 17, Loss: 0.2029\n",
      "Iter: 18, Loss: 0.1291\n",
      "Iter: 19, Loss: 0.1768\n",
      "Iter: 20, Loss: 0.1764\n",
      "Iter: 21, Loss: 0.0937\n",
      "Iter: 22, Loss: 0.1230\n",
      "Iter: 23, Loss: 0.1274\n",
      "Iter: 24, Loss: 0.1406\n",
      "Iter: 25, Loss: 0.0779\n",
      "Iter: 26, Loss: 0.1005\n",
      "Iter: 27, Loss: 0.1233\n",
      "Iter: 28, Loss: 0.0865\n",
      "Iter: 29, Loss: 0.0960\n",
      "Iter: 30, Loss: 0.0908\n",
      "Iter: 31, Loss: 0.0841\n",
      "Iter: 32, Loss: 0.0938\n",
      "Iter: 33, Loss: 0.1221\n",
      "Iter: 34, Loss: 0.0803\n",
      "Iter: 35, Loss: 0.1015\n",
      "Iter: 36, Loss: 0.0873\n",
      "Iter: 37, Loss: 0.0798\n",
      "Iter: 38, Loss: 0.0669\n",
      "Iter: 39, Loss: 0.0929\n",
      "Iter: 40, Loss: 0.0853\n",
      "Iter: 41, Loss: 0.0548\n",
      "Iter: 42, Loss: 0.0578\n",
      "Iter: 43, Loss: 0.0431\n",
      "Iter: 44, Loss: 0.0711\n",
      "Iter: 45, Loss: 0.0570\n",
      "Iter: 46, Loss: 0.0545\n",
      "Iter: 47, Loss: 0.0589\n",
      "Iter: 48, Loss: 0.0330\n",
      "Iter: 49, Loss: 0.0675\n",
      "Iter: 50, Loss: 0.0637\n",
      "Iter: 51, Loss: 0.0408\n",
      "Iter: 52, Loss: 0.0657\n",
      "Iter: 53, Loss: 0.0470\n",
      "Iter: 54, Loss: 0.0567\n",
      "Iter: 55, Loss: 0.0520\n",
      "Iter: 56, Loss: 0.0377\n",
      "Iter: 57, Loss: 0.0428\n",
      "Iter: 58, Loss: 0.0519\n",
      "Iter: 59, Loss: 0.0507\n",
      "Iter: 60, Loss: 0.0626\n",
      "Iter: 61, Loss: 0.0537\n",
      "Iter: 62, Loss: 0.0792\n",
      "Iter: 63, Loss: 0.0392\n",
      "Iter: 64, Loss: 0.0436\n",
      "Iter: 65, Loss: 0.0395\n",
      "Iter: 66, Loss: 0.0526\n",
      "Iter: 67, Loss: 0.0529\n",
      "Iter: 68, Loss: 0.0524\n",
      "Iter: 69, Loss: 0.0863\n",
      "Iter: 70, Loss: 0.0562\n",
      "Iter: 71, Loss: 0.0632\n",
      "Iter: 72, Loss: 0.0550\n",
      "Iter: 73, Loss: 0.0456\n",
      "Iter: 74, Loss: 0.0512\n",
      "Iter: 75, Loss: 0.0399\n",
      "Iter: 76, Loss: 0.0709\n",
      "Iter: 77, Loss: 0.0381\n",
      "Iter: 78, Loss: 0.0574\n",
      "Iter: 79, Loss: 0.0634\n",
      "Iter: 80, Loss: 0.0328\n",
      "Iter: 81, Loss: 0.0585\n",
      "Iter: 82, Loss: 0.0381\n",
      "Iter: 83, Loss: 0.0474\n",
      "Iter: 84, Loss: 0.0360\n",
      "Iter: 85, Loss: 0.0287\n",
      "Iter: 86, Loss: 0.0560\n",
      "Iter: 87, Loss: 0.0531\n",
      "Iter: 88, Loss: 0.0358\n",
      "Iter: 89, Loss: 0.0499\n",
      "Iter: 90, Loss: 0.0337\n",
      "Iter: 91, Loss: 0.0352\n",
      "Iter: 92, Loss: 0.0446\n",
      "Iter: 93, Loss: 0.0393\n",
      "Iter: 94, Loss: 0.0495\n",
      "Iter: 95, Loss: 0.0270\n",
      "Iter: 96, Loss: 0.0381\n",
      "Iter: 97, Loss: 0.0421\n",
      "Iter: 98, Loss: 0.0351\n",
      "Iter: 99, Loss: 0.0334\n",
      "Iter: 100, Loss: 0.0291\n",
      "Iter: 101, Loss: 0.0324\n",
      "Iter: 102, Loss: 0.0266\n",
      "Iter: 103, Loss: 0.0307\n",
      "Iter: 104, Loss: 0.0351\n",
      "Iter: 105, Loss: 0.0228\n",
      "Iter: 106, Loss: 0.0117\n",
      "Iter: 107, Loss: 0.0525\n",
      "Iter: 108, Loss: 0.0522\n",
      "Iter: 109, Loss: 0.0228\n",
      "Iter: 110, Loss: 0.0282\n",
      "Iter: 111, Loss: 0.0352\n",
      "Iter: 112, Loss: 0.0333\n",
      "Iter: 113, Loss: 0.0261\n",
      "Iter: 114, Loss: 0.0317\n",
      "Iter: 115, Loss: 0.0536\n",
      "Iter: 116, Loss: 0.0292\n",
      "Iter: 117, Loss: 0.0473\n",
      "Iter: 118, Loss: 0.0414\n",
      "Iter: 119, Loss: 0.0417\n",
      "Iter: 120, Loss: 0.0328\n",
      "Iter: 121, Loss: 0.0385\n",
      "Iter: 122, Loss: 0.0328\n",
      "Iter: 123, Loss: 0.0374\n",
      "Iter: 124, Loss: 0.0281\n",
      "Iter: 125, Loss: 0.0412\n",
      "Iter: 126, Loss: 0.0493\n",
      "Iter: 127, Loss: 0.0332\n",
      "Iter: 128, Loss: 0.0540\n",
      "Iter: 129, Loss: 0.0428\n",
      "Iter: 130, Loss: 0.0414\n",
      "Iter: 131, Loss: 0.0257\n",
      "Iter: 132, Loss: 0.0237\n",
      "Iter: 133, Loss: 0.0360\n",
      "Iter: 134, Loss: 0.0401\n",
      "Iter: 135, Loss: 0.0379\n",
      "Iter: 136, Loss: 0.0369\n",
      "Iter: 137, Loss: 0.0288\n",
      "Iter: 138, Loss: 0.0251\n",
      "Iter: 139, Loss: 0.0388\n",
      "Iter: 140, Loss: 0.0178\n",
      "Iter: 141, Loss: 0.0452\n",
      "Iter: 142, Loss: 0.0189\n",
      "Iter: 143, Loss: 0.0382\n",
      "Iter: 144, Loss: 0.0403\n",
      "Iter: 145, Loss: 0.0219\n",
      "Iter: 146, Loss: 0.0188\n",
      "Iter: 147, Loss: 0.0384\n",
      "Iter: 148, Loss: 0.0329\n",
      "Iter: 149, Loss: 0.0247\n",
      "Iter: 150, Loss: 0.0185\n",
      "Iter: 151, Loss: 0.0272\n",
      "Iter: 152, Loss: 0.0375\n",
      "Iter: 153, Loss: 0.0320\n",
      "Iter: 154, Loss: 0.0398\n",
      "Iter: 155, Loss: 0.0483\n",
      "Iter: 156, Loss: 0.0334\n",
      "Iter: 157, Loss: 0.0330\n",
      "Iter: 158, Loss: 0.0164\n",
      "Iter: 159, Loss: 0.0166\n",
      "Iter: 160, Loss: 0.0261\n",
      "Iter: 161, Loss: 0.0249\n",
      "Iter: 162, Loss: 0.0245\n",
      "Iter: 163, Loss: 0.0333\n",
      "Iter: 164, Loss: 0.0273\n",
      "Iter: 165, Loss: 0.0199\n",
      "Iter: 166, Loss: 0.0227\n",
      "Iter: 167, Loss: 0.0473\n",
      "Iter: 168, Loss: 0.0216\n",
      "Iter: 169, Loss: 0.0241\n",
      "Iter: 170, Loss: 0.0205\n",
      "Iter: 171, Loss: 0.0189\n",
      "Iter: 172, Loss: 0.0125\n",
      "Iter: 173, Loss: 0.0375\n",
      "Iter: 174, Loss: 0.0379\n",
      "Iter: 175, Loss: 0.0321\n",
      "Iter: 176, Loss: 0.0291\n",
      "Iter: 177, Loss: 0.0142\n",
      "Iter: 178, Loss: 0.0366\n",
      "Iter: 179, Loss: 0.0620\n",
      "Iter: 180, Loss: 0.0318\n",
      "Iter: 181, Loss: 0.0329\n",
      "Iter: 182, Loss: 0.0215\n",
      "Iter: 183, Loss: 0.0476\n",
      "Iter: 184, Loss: 0.0455\n",
      "Iter: 185, Loss: 0.0342\n",
      "Iter: 186, Loss: 0.0324\n",
      "Iter: 187, Loss: 0.0228\n",
      "Iter: 188, Loss: 0.0398\n",
      "Iter: 189, Loss: 0.0292\n",
      "Iter: 190, Loss: 0.0567\n",
      "Iter: 191, Loss: 0.0316\n",
      "Iter: 192, Loss: 0.0114\n",
      "Iter: 193, Loss: 0.0183\n",
      "Iter: 194, Loss: 0.0385\n",
      "Iter: 195, Loss: 0.0286\n",
      "Iter: 196, Loss: 0.0254\n",
      "Iter: 197, Loss: 0.0182\n",
      "Iter: 198, Loss: 0.0467\n",
      "Iter: 199, Loss: 0.0122\n"
     ]
    }
   ],
   "source": [
    "#audio,_,_ = next(iterator)\n",
    "\n",
    "# Load the first song (entirely, without cutting into 3 pieces)\n",
    "#print(audios[0])\n",
    "#audio_np = np.asarray(audios_sample[0], np.float32)\n",
    "audio_tf= tf.convert_to_tensor(audios_sample_flatten, np.float32)\n",
    "print(audio_tf.shape)\n",
    "\n",
    "# TODO : do I need to include the labels in the audio batch ?\n",
    "net = build_model(audio_tf, is_training=True, config=BASIC_CONFIG) \n",
    "prediction = tf.layers.dense(net, 1, activation=tf.tanh) # should be the nb pf layers > activation sigmoid\n",
    "loss = tf.losses.mean_squared_error(prediction, voice_no_voice) # pass the second value from iter.get_net() as label\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(EPOCHS):\n",
    "        _, loss_value = sess.run([train_op, loss])\n",
    "        print(\"Iter: {}, Loss: {:.4f}\".format(i, loss_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell everytime before relaunching tensorflow session\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tags' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-7ec289c5694f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tags' is not defined"
     ]
    }
   ],
   "source": [
    "len(tags)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
