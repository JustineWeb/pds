{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is this useful ? >> I think yes to avaoid taking all ressources available from the 4 GPUs\n",
    "from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "import fnmatch\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import itertools\n",
    "\n",
    "#import progressbar\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from tools import *\n",
    "from loading import * \n",
    "from labels_analysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTT_DIR = \"../MTT/\"\n",
    "DATA_DIRECTORY = MTT_DIR + \"dataset/\"\n",
    "WAV_DIRECTORY = MTT_DIR + \"wav-dataset/\"\n",
    "\n",
    "# CSV containing song details (title, artist, id, mp3_path,...)\n",
    "CLIP_INFO_FINAL = \"clip_info_final.csv\"\n",
    "# CSV containg the labels (clip_id, labels, mp3_path)\n",
    "ANNOTATIONS_FINAL = \"annotations_final.csv\"\n",
    "# CSV : what is it useful for ?\n",
    "COMPARISONS_FINAL = \"comparisons_final.csv\"\n",
    "LABELS_FILE = MTT_DIR + ANNOTATIONS_FINAL\n",
    "\n",
    "LOGDIR = \"checkpoints/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LTS2 Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines all the needed data paths, when running on LTS2 server.\n",
    "Don't run this cell if you are not running the jupyter notebook on the LTS2 server ! (will overwrite the variables defined on the cell above).\n",
    "\n",
    "You can either create a cell with your own paths, or modify the cell above with your custom paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTT_DIR = \"/mnt/scratch/students/jjgweber-MagnaTagATune/\"\n",
    "DATA_DIRECTORY = MTT_DIR + \"dataset/\"\n",
    "WAV_DIRECTORY = MTT_DIR + \"wav-dataset/\"\n",
    "\n",
    "# CSV containg the labels (clip_id, labels, mp3_path)\n",
    "ANNOTATIONS_FINAL = \"annotations_final.csv\"\n",
    "\n",
    "LABELS_FILE = MTT_DIR + ANNOTATIONS_FINAL\n",
    "\n",
    "# need to create this directory on the server !!\n",
    "LOGDIR = \"checkpoints/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NB = 25880 #25863\n",
    "FILE_LENGTH = 465984\n",
    "# 465984 = 2 × 2 × 2 × 2 × 2 × 2 × 3 × 3 × 809\n",
    "# useful for batches > for now divide by 9 (instead of 10)\n",
    "\n",
    "BATCH_NB = 9\n",
    "BATCH_SIZE = int(FILE_LENGTH/BATCH_NB)\n",
    "SAMPLE_SIZE = 0\n",
    "SAMPLE_RATE = 16000\n",
    "RECEPTIVE_FIELD = 0\n",
    "\n",
    "TRAIN_DIR = \"0123456789abcde\"\n",
    "TEST_DIR =\"f\"\n",
    "\n",
    "BASIC_CONFIG ={'numOutputNeurons':500}\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables which are often modified to test the algorithm\n",
    "NB_SONGS = 20\n",
    "GROUP_SIZE = 20\n",
    "EPOCHS = 16 # check in paper\n",
    "LABELS_NAME = ['guitar', 'techno']\n",
    "NB_LABELS = len(LABELS_NAME)\n",
    "threshold_tag = 0.7\n",
    "majority = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justineweber/EPFL/Master/semester_project/pds/loading.py:98: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  labels = pd.read_csv(labels_path, sep = '\"\\t\"')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading csv file : 2.19\n"
     ]
    }
   ],
   "source": [
    "labels, header = load_and_clean_labels(LABELS_FILE)\n",
    "#labels.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs :  25863\n",
      "Number of labels :  188\n",
      "Max number of songs tagged with the same label :  4852\n",
      "Max number of labels for a single song :  27\n"
     ]
    }
   ],
   "source": [
    "nb_labels_per_song, nb_song_per_label, label_header_by_freq = label_stats(labels, header, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_10_labels = label_header_by_freq[:10]\n",
    "best_30_labels = label_header_by_freq[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-occurence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_labels = best_10_labels\n",
    "#check_overlaps(chosen_labels, labels.loc[:,chosen_labels].values.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and format mp3 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training variables \n",
    "TRAIN_DIR =\n",
    "EPOCHS =\n",
    "BATCH_SIZE =\n",
    "BATCH_NB =\n",
    "LOGDIR =\n",
    "LABELS_NAME = \n",
    "NB_LABELS =\n",
    "LEARNING_RATE =\n",
    "GROUP_SIZE =\n",
    "SAMPLE_SIZE ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir, pattern, file_type = return_params_mp3_wav(\"mp3\", DATA_DIRECTORY, WAV_DIRECTORY)\n",
    "# also need labels but computed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_shape(group_size, sample_size) :\n",
    "    train_loss_results, train_auc_results = train(data_dir, group_size, sample_size, file_type,\\\n",
    "                                                  TRAIN_DIR, EPOCHS, labels, LABELS_NAME, NB_LABELS, \\\n",
    "                                                  BATCH_SIZE, BATCH_NB, LOGDIR, LEARNING_RATE)\n",
    "    return train_loss_results, train_auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_labels_choice(labels_name, nb_labels) :\n",
    "    train_loss_results, train_auc_results = train(data_dir, GROUP_SIZE, SAMPLE_SIZE, file_type, \\\n",
    "                                                  TRAIN_DIR, EPOCHS, labels, labels_name, nb_labels, \\\n",
    "                                                  BATCH_SIZE, BATCH_NB, LOGDIR, LEARNING_RATE)\n",
    "    return train_loss_results, train_auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_learning_rate(l_rate) :\n",
    "    train_loss_results, train_auc_results = train(data_dir, group_size, sample_size, file_type, \\\n",
    "                                                  TRAIN_DIR, EPOCHS, labels, labels_name, nb_labels, \\\n",
    "                                                  BATCH_SIZE, BATCH_NB, LOGDIR, l_rate)\n",
    "    return train_loss_results, train_auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_tf_model(input_shape, nb_labels, nb_batch, batch_size, learning_rate, is_training=True) :\n",
    "    print(\"Initialize tf model ...\")\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=(input_shape*nb_batch, batch_size, 1))\n",
    "    y = tf.placeholder(tf.float32, shape=(input_shape*nb_batch, nb_labels))\n",
    "\n",
    "    net = build_model(x, is_training=is_training, config=BASIC_CONFIG) \n",
    "    predictions = tf.layers.dense(net, nb_labels, activation=tf.sigmoid)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = y, logits = predictions)\n",
    "    reduced_loss = tf.reduce_mean(loss)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(reduced_loss)\n",
    "    auc = tf.metrics.auc(labels = y, predictions=predictions)\n",
    "    \n",
    "    # Saver for storing checkpoints of the model. (Wavenets)\n",
    "    saver = tf.train.Saver(var_list=tf.global_variables())\n",
    "    \n",
    "    return x, y, net, predictions, loss, reduced_loss,  train_op, auc, saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_dir, group_size, sample_size, file_type, train_dir, epochs, \\\n",
    "          labels, labels_name, nb_labels, batch_size, nb_batch, logdir, learning_rate) :\n",
    "    \n",
    "    pattern = \"\"\n",
    "    if file_type == \"mp3\" :\n",
    "        pattern = \"*.mp3\"\n",
    "    if file_type == \"wav\" :\n",
    "        pattern = \"*.wav\"\n",
    "    else :\n",
    "        print(\"Argument should be either \\\"mp3\\\" or \\\"wav\\\".\")\n",
    "        \n",
    "    # keep results for plotting\n",
    "    train_loss_results = []\n",
    "    train_auc_results = []\n",
    "\n",
    "\n",
    "    files_by_group = find_files_group(data_dir, group_size, sample=sample_size, pattern=pattern, sub_dir=train_dir)\n",
    "    n_groups = len(files_by_group)\n",
    "\n",
    "    x, y, net, predictions, loss, reduced_loss, \\\n",
    "    train_op, auc, saver = initialize_tf_model(len(files_by_group[0]), nb_labels, nb_batch,\\\n",
    "                                               batch_size, learning_rate)\n",
    "    print(\"Start training...\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "        sess.run(init)\n",
    "\n",
    "        # Go through the whole DS at each EPOCH\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "\n",
    "            t0_epoch = time.time()\n",
    "\n",
    "            # Group by group\n",
    "            for count, g in enumerate(files_by_group) :\n",
    "\n",
    "                # Load audio and labels\n",
    "                tload0 = time.time()\n",
    "                audios, tags = load_audio_label_aux(labels, g, len(data_dir), labels_name=labels_name, \\\n",
    "                        nb_labels=nb_labels, file_type=file_type, batch_size=batch_size, nb_batch=nb_batch)\n",
    "                \n",
    "                tload1 = time.time()\n",
    "\n",
    "                if count==0 :\n",
    "                    print(\">> Total loading time : {:.2f} sec\".format(tload1-tload0))\n",
    "                #audio_tf = tf.convert_to_tensor(audios, np.float32)\n",
    "\n",
    "                # add check to verify if there is something to restore\n",
    "                #saver.restore(sess, LOGDIR)\n",
    "\n",
    "                predict, _, loss_value, auc_score = sess.run([predictions, train_op, reduced_loss, auc],\\\n",
    "                                                             feed_dict={x: audios, y: tags})\n",
    "                auc_result, update_op = auc_score\n",
    "\n",
    "                saver.save(sess, logdir)\n",
    "\n",
    "\n",
    "                train_loss_results.append(loss_value)\n",
    "                train_auc_results.append(auc_result)\n",
    "\n",
    "                print(\"Group {} done. {} left.\".format(count, n_groups-count))\n",
    "\n",
    "\n",
    "            t1_epoch = time.time()\n",
    "\n",
    "            dur = t1_epoch-t0_epoch\n",
    "\n",
    "            print(\"Iter: {:3}, Time (in sec): {:.2f}, Loss: {:.4f}, AUC : {:.4f}\"\\\n",
    "                  .format(epoch, dur, loss_value, auc_result))\n",
    "            print()\n",
    "\n",
    "    end = time.time()\n",
    "    duration2 = end-start\n",
    "    print(\"Total time: {:.2f} sec.\".format(duration2))\n",
    "    return train_loss_results, train_auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argument should be either \"mp3\" or \"wav\".\n",
      "Initialize tf model ...\n",
      "Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9567b6adea5c4037aa6c7d6743b255fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 10 songs ...\n",
      ">> Total loading time : 0.42 sec\n",
      "Group 0 done. 5 left.\n",
      "Loading 10 songs ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-eadf0fc897b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_input_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-4bcc4d45f16f>\u001b[0m in \u001b[0;36mtrain_input_shape\u001b[0;34m(group_size, sample_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_input_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_loss_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auc_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_type\u001b[0m\u001b[0;34m,\u001b[0m                                                  \u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLABELS_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNB_LABELS\u001b[0m\u001b[0;34m,\u001b[0m                                                   \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_NB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOGDIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loss_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auc_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-22956e26b276>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_dir, group_size, sample_size, file_type, train_dir, epochs, labels, labels_name, nb_labels, batch_size, nb_batch, logdir, learning_rate)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;31m#saver.restore(sess, LOGDIR)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                                                             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maudios\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mauc_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_input_shape(10, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 10 songs ...\n"
     ]
    }
   ],
   "source": [
    "test_size = 10\n",
    "\n",
    "test_files = find_files_group(data_dir, test_size, sample=test_size, pattern=pattern, sub_dir=TEST_DIR)\n",
    "\n",
    "audios_test, tags_test = load_audio_label_aux(labels, test_files[0], len(data_dir), labels_name=LABELS_NAME, \\\n",
    "                        nb_labels=NB_LABELS, file_type=file_type, batch_size=BATCH_SIZE, nb_batch=BATCH_NB)\n",
    "#audios_test_tf = tf.convert_to_tensor(audios_test, np.float32)\n",
    "\n",
    "# for testing I guess no need to give several groups to the network ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize tf model ...\n"
     ]
    }
   ],
   "source": [
    "x, y, net, predictions, loss, reduced_loss,  train_op, auc, saver = initialize_tf_model(len(test_files[0]), \\\n",
    "                                                                                        is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/\n",
      "Model restored.\n"
     ]
    }
   ],
   "source": [
    "variables_to_restore = {\n",
    "    var.name[:-2]: var for var in tf.global_variables()\n",
    "    if not ('state_buffer' in var.name or 'pointer' in var.name)}\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "      # Restore variables from disk.\n",
    "    saver.restore(sess, LOGDIR)\n",
    "    print(\"Model restored.\")\n",
    "    \n",
    "    init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "    sess.run(init) \n",
    "\n",
    "    predicts = sess.run([predictions, train_op, reduced_loss, auc], \\\n",
    "                        feed_dict={x: audios_test, y: tags_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score : (0.0, 0.9525666)\n"
     ]
    }
   ],
   "source": [
    "# Print some results \n",
    "print(\"AUC Score :\", predicts[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS : [[0.39762467 0.5317022 ]\n",
      " [0.41376293 0.5442593 ]\n",
      " [0.40786144 0.5408588 ]\n",
      " [0.41314897 0.55215746]\n",
      " [0.40527916 0.53530353]\n",
      " [0.41508767 0.5404672 ]\n",
      " [0.40992323 0.55352896]\n",
      " [0.40987948 0.5446132 ]\n",
      " [0.40410063 0.5533281 ]\n",
      " [0.4037748  0.5468923 ]\n",
      " [0.41175076 0.53373635]\n",
      " [0.37350586 0.5440748 ]\n",
      " [0.37320533 0.54743737]\n",
      " [0.42032704 0.544655  ]\n",
      " [0.41377208 0.50805855]\n",
      " [0.38474667 0.51823187]\n",
      " [0.3984042  0.520919  ]\n",
      " [0.42120805 0.5191214 ]\n",
      " [0.43589783 0.5107603 ]\n",
      " [0.41017565 0.53928274]\n",
      " [0.43246457 0.5266577 ]\n",
      " [0.4295476  0.52487886]\n",
      " [0.4221722  0.51602966]\n",
      " [0.42679927 0.5201455 ]\n",
      " [0.4195264  0.51714844]\n",
      " [0.42418894 0.52547896]\n",
      " [0.42918113 0.5242856 ]\n",
      " [0.45320967 0.45734808]\n",
      " [0.44791922 0.4246144 ]\n",
      " [0.44401696 0.44591367]\n",
      " [0.44415256 0.4571646 ]\n",
      " [0.4513004  0.416689  ]\n",
      " [0.45326284 0.42711696]\n",
      " [0.4497077  0.43057668]\n",
      " [0.4529647  0.41719246]\n",
      " [0.44833606 0.42987123]\n",
      " [0.4452741  0.48318714]\n",
      " [0.45110035 0.49947786]\n",
      " [0.45012206 0.5001798 ]\n",
      " [0.4510177  0.49341547]\n",
      " [0.4190827  0.49890056]\n",
      " [0.44855672 0.49769822]\n",
      " [0.45192498 0.4874377 ]\n",
      " [0.4547795  0.487284  ]\n",
      " [0.4538817  0.48899993]\n",
      " [0.4169332  0.5269769 ]\n",
      " [0.4201784  0.51867074]\n",
      " [0.389655   0.5254746 ]\n",
      " [0.42662075 0.52083886]\n",
      " [0.42241332 0.52348274]\n",
      " [0.39135656 0.5214875 ]\n",
      " [0.39889622 0.51700693]\n",
      " [0.4156664  0.53880465]\n",
      " [0.40294868 0.52797323]\n",
      " [0.42255613 0.51135707]\n",
      " [0.4238886  0.5170773 ]\n",
      " [0.43316743 0.51199496]\n",
      " [0.4312153  0.529607  ]\n",
      " [0.43079254 0.5221378 ]\n",
      " [0.40325183 0.50999117]\n",
      " [0.42281044 0.5081729 ]\n",
      " [0.41108975 0.53502536]\n",
      " [0.43470043 0.5222268 ]\n",
      " [0.4422705  0.51562387]\n",
      " [0.4432149  0.51567864]\n",
      " [0.4539413  0.5236758 ]\n",
      " [0.45567387 0.51805305]\n",
      " [0.4450448  0.5242185 ]\n",
      " [0.44353914 0.51641285]\n",
      " [0.44967443 0.52181196]\n",
      " [0.44517893 0.5136464 ]\n",
      " [0.44302174 0.5315063 ]\n",
      " [0.3951159  0.5470862 ]\n",
      " [0.41351938 0.54368824]\n",
      " [0.3963875  0.5455298 ]\n",
      " [0.4220127  0.5480099 ]\n",
      " [0.41753578 0.53320426]\n",
      " [0.4135087  0.55146354]\n",
      " [0.39671564 0.5367305 ]\n",
      " [0.40074804 0.54581165]\n",
      " [0.42664313 0.5522124 ]\n",
      " [0.45155326 0.4085453 ]\n",
      " [0.45070714 0.4088155 ]\n",
      " [0.44370702 0.442685  ]\n",
      " [0.45231545 0.41978437]\n",
      " [0.45275068 0.4185345 ]\n",
      " [0.4533176  0.41014504]\n",
      " [0.45229936 0.41040444]\n",
      " [0.45114675 0.40529367]\n",
      " [0.44390652 0.429328  ]]\n",
      "TRUE : [[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"PREDICTIONS :\", predicts[0])\n",
    "print(\"TRUE :\", tags_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following TF tutorial for custom training\n",
    "https://github.com/tensorflow/docs/blob/master/site/en/tutorials/eager/custom_training_walkthrough.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argument should be either \"mp3\" or \"wav\".\n",
      "Initialize tf model ...\n",
      "Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190155866d4641f7b187b809cbc380bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 10 songs ...\n",
      ">> Total loading time : 0.42 sec\n",
      "Group 0 done. 5 left.\n",
      "Loading 10 songs ...\n",
      "Group 1 done. 4 left.\n",
      "Loading 10 songs ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-dcdec6bc3f73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_params_mp3_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mp3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_DIRECTORY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWAV_DIRECTORY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgroup_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLABELS_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNB_LABELS\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_NB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOGDIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-22956e26b276>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_dir, group_size, sample_size, file_type, train_dir, epochs, labels, labels_name, nb_labels, batch_size, nb_batch, logdir, learning_rate)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;31m#saver.restore(sess, LOGDIR)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                                                             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maudios\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mauc_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_dir, pattern, file_type = return_params_mp3_wav(\"mp3\", DATA_DIRECTORY, WAV_DIRECTORY)\n",
    "group_size, sample_size =10, 50\n",
    "train(data_dir, group_size, sample_size, file_type, TRAIN_DIR, EPOCHS, labels, LABELS_NAME, NB_LABELS, \\\n",
    "     BATCH_SIZE, BATCH_NB, LOGDIR, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VERSION 2 : feed group by group\n",
    "def train_v2(group_size=10, sample_size=50):\n",
    "\n",
    "    files_by_group = find_files_group(data_dir, group_size, sample=sample_size, pattern=pattern, sub_dir=TRAIN_DIR)\n",
    "    n_groups = len(files_by_group)\n",
    "\n",
    "    x, y, net, predictions, loss, reduced_loss,  train_op, auc, saver = initialize_tf_model()\n",
    "\n",
    "    print(\"Start training...\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "        sess.run(init)\n",
    "\n",
    "        # Go through the whole DS at each EPOCH\n",
    "        for epoch in tqdm(range(EPOCHS)):\n",
    "\n",
    "            t0_epoch = time.time()\n",
    "\n",
    "            # Group by group\n",
    "            for count, g in enumerate(files_by_group) :\n",
    "\n",
    "                # Load audio and labels\n",
    "                tload0 = time.time()\n",
    "                audios, tags = load_audio_label_aux(labels, g, len(data_dir), labels_name=LABELS_NAME, \\\n",
    "                        nb_labels=NB_LABELS, file_type=file_type, batch_size=BATCH_SIZE, nb_batch=BATCH_NB)\n",
    "                tload1 = time.time()\n",
    "\n",
    "                if count==0 :\n",
    "                    print(\">> Total loading time : {:.2f} sec\".format(tload1-tload0))\n",
    "                #audio_tf = tf.convert_to_tensor(audios, np.float32)\n",
    "\n",
    "                # add check to verify if there is something to restore\n",
    "                #saver.restore(sess, LOGDIR)\n",
    "\n",
    "                predict, _, loss_value, auc_score = sess.run([predictions, train_op, reduced_loss, auc],\\\n",
    "                                                             feed_dict={x: audios, y: tags})\n",
    "                auc_result, update_op = auc_score\n",
    "\n",
    "                saver.save(sess, LOGDIR)\n",
    "\n",
    "\n",
    "                train_loss_results.append(loss_value)\n",
    "                train_auc_results.append(auc_result)\n",
    "\n",
    "                print(\"Group {} done. {} left.\".format(count, n_groups-count))\n",
    "\n",
    "\n",
    "            t1_epoch = time.time()\n",
    "\n",
    "            dur = t1_epoch-t0_epoch\n",
    "\n",
    "            print(\"Iter: {:3}, Time (in sec): {:.2f}, Loss: {:.4f}, AUC : {:.4f}\"\\\n",
    "                  .format(epoch, dur, loss_value, auc_result))\n",
    "            print()\n",
    "\n",
    "        end = time.time()\n",
    "        duration2 = end-start\n",
    "        print(\"Total time: {:.2f} sec.\".format(duration2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and format mp3 data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading audio & tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Use Example \n",
    " load audios and labels > convert to numpy\n",
    " CAREFUL : the argument num_songs is important and shouldn't be too big \n",
    " > otherwise MEMORY ISSUES !!!!!!\n",
    "\n",
    "audios, tags, order, order2 = load_audio_label(cleaned, num_songs=NB_SONGS, sub_dir=TRAIN_DIR, \\\n",
    "                                file_type=\"mp3\", directory=DATA_DIRECTORY, randomize_batch=True) '''\n",
    "\n",
    "def load_audio_label(labels, num_songs, sample_rate=None, directory=WAV_DIRECTORY, \\\n",
    "                     labels_name=LABELS_NAME, sub_dir=None, file_type=\"wav\", randomize_batch=False):\n",
    "    \n",
    "    assert (file_type==\"wav\" or file_type==\"mp3\"), \"The argument file_type should be either 'wav', either 'mp3'.\"\n",
    "    if (file_type==\"wav\" and directory!=WAV_DIRECTORY) or (file_type==\"mp3\" and directory!=DATA_DIRECTORY):\n",
    "        warnings.warn(\"File type and directory may not correspond. Make sure the \\\n",
    "        directory gave as parameter contains the right type of files\", FutureWarning, stacklevel=2)\n",
    "        \n",
    "    if num_songs > 20 :\n",
    "        warnings.warn(\"The argument num_song should not be too high (above 20), make sure this will \\\n",
    "        not cause memory error.\", FutureWarning, stacklevel=2)\n",
    "       \n",
    "    \n",
    "    print(\"Loading data ...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    if file_type==\"mp3\" :\n",
    "        files = find_files(directory, sample=num_songs, sub_dir=sub_dir)\n",
    "    if file_type==\"wav\" :\n",
    "        files = find_files(directory, sample=num_songs, sub_dir=sub_dir, pattern='*.wav')\n",
    " \n",
    "    randomized_files = randomize_files(files)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    audios = np.ndarray(shape=(num_songs * BATCH_NB, BATCH_SIZE, 1), dtype=np.float32, order='F')\n",
    "    tags = np.ndarray(shape=(num_songs * BATCH_NB, NB_LABELS), dtype=np.float32, order='F')\n",
    "    order = np.zeros(num_songs * BATCH_NB, dtype=int)\n",
    "    order2 = np.zeros(num_songs * BATCH_NB, dtype=int)\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    for filename in randomized_files:\n",
    "\n",
    "        # Load audio (MP3/WAV) file        \n",
    "        try :\n",
    "            audio, _ = librosa.load(filename, sr=sample_rate, mono=True)\n",
    "        except EOFError :\n",
    "            print(\"EOFERROR : The following file could not be loaded with librosa - \", filename)\n",
    "\n",
    "        audio = audio.reshape(-1, 1)\n",
    "         \n",
    "        for n in range(BATCH_NB) :\n",
    "            audios[idx] = audio[n*BATCH_SIZE: (n+1)*BATCH_SIZE,:]\n",
    "            \n",
    "            # take labels or corresponding song\n",
    "            \n",
    "            if file_type==\"mp3\" :\n",
    "                select_labels  = labels.loc[labels['mp3_path']==filename[len(directory):]]\n",
    "            \n",
    "            if file_type==\"wav\" :\n",
    "                select_labels  = labels.loc[labels['mp3_path']==filename[len(directory):-4]+\".mp3\"]\n",
    "\n",
    "            # select wanted labels\n",
    "            select_labels = select_labels[labels_name]\n",
    "\n",
    "            tags[idx] = select_labels.values.reshape(NB_LABELS)\n",
    "            \n",
    "            order[idx] = count\n",
    "            order2[idx] = idx\n",
    "            idx +=1\n",
    "        \n",
    "        count +=1\n",
    "        if (count % 10) == 0:\n",
    "            print(count)\n",
    "    \n",
    "    if randomize_batch :\n",
    "        rng_state = np.random.get_state()\n",
    "        np.random.shuffle(audios)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(tags)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(order)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(order2)\n",
    "        \n",
    "    end = time.time()\n",
    "    duration = end-start\n",
    "    print(\">> Total loading time - {} songs : {:.2f} sec\".format(num_songs, duration))\n",
    "    print()\n",
    "    print(\"Shape of audios list :\", audios.shape)\n",
    "    print(\"Shape of tags list :\", tags.shape)\n",
    "    return audios, tags, order, order2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one is not correct yet I think\n",
    "def load_audio_label_prim(labels, num_songs, sample_rate=None, directory=WAV_DIRECTORY, \\\n",
    "                     labels_name=LABELS_NAME, sub_dir=None, file_type=\"wav\", randomize_batch=False):\n",
    "    \n",
    "    \n",
    "    assert (file_type==\"wav\" or file_type==\"mp3\"), \"The argument file_type should be either 'wav', either 'mp3'.\"\n",
    "    if (file_type==\"wav\" and directory!=WAV_DIRECTORY) or (file_type==\"mp3\" and directory!=DATA_DIRECTORY):\n",
    "        warnings.warn(\"File type and directory may not correspond. Make sure the \\\n",
    "        directory gave as parameter contains the right type of files\", FutureWarning, stacklevel=2)\n",
    "        \n",
    "    if num_songs > 20 :\n",
    "        warnings.warn(\"The argument num_song should not be too high (above 20), make sure this will \\\n",
    "        not cause memory error.\", FutureWarning, stacklevel=2)\n",
    "        \n",
    "    print(\"Loading data ...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    if group_size != None:\n",
    "        if file_type==\"mp3\" :\n",
    "            files = find_files_group(directory, group_size, sample=num_songs, sub_dir=sub_dir, pattern='*.mp3')\n",
    "        if file_type==\"wav\" :\n",
    "            files = find_files_group(directory, group_size, sample=num_songs, sub_dir=sub_dir, pattern='*.wav')\n",
    "    \n",
    "    else :\n",
    "        if file_type==\"mp3\" :\n",
    "            files = find_files(directory, sample=num_songs, sub_dir=sub_dir, pattern='*.mp3')\n",
    "        if file_type==\"wav\" :\n",
    "            files = find_files(directory, sample=num_songs, sub_dir=sub_dir, pattern='*.wav')\n",
    "            \n",
    "    randomized_files = randomize_files(files)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    audios = np.ndarray(shape=(num_songs * BATCH_NB, BATCH_SIZE, 1), dtype=np.float32, order='F')\n",
    "    tags = np.ndarray(shape=(num_songs * BATCH_NB, NB_LABELS), dtype=np.float32, order='F')\n",
    "    order = np.zeros(num_songs * BATCH_NB, dtype=int)\n",
    "    order2 = np.zeros(num_songs * BATCH_NB, dtype=int)\n",
    "    \n",
    "\n",
    "    \n",
    "    if group_size != None :\n",
    "        for group in files :\n",
    "            load_audio_label_aux(cleaned, group, len(directory), labels_name=labels_name, file_type=file_type)\n",
    "    \n",
    "    # check where to put this after        \n",
    "    if randomize_batch :\n",
    "        rng_state = np.random.get_state()\n",
    "        np.random.shuffle(audios)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(tags)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(order)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(order2)\n",
    "        \n",
    "    end = time.time()\n",
    "    duration = end-start\n",
    "    print(\">> Total loading time - {} songs : {:.2f} sec\".format(num_songs, duration))\n",
    "    print()\n",
    "    print(\"Shape of audios list :\", audios.shape)\n",
    "    print(\"Shape of tags list :\", tags.shape)\n",
    "    return audios, tags, order, order2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save neural net state tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used for now\n",
    "def save(saver, sess, logdir, step):\n",
    "    model_name = 'model.ckpt'\n",
    "    checkpoint_path = os.path.join(logdir, model_name)\n",
    "    print('Storing checkpoint to {} ...'.format(logdir), end=\"\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if not os.path.exists(logdir):\n",
    "        os.makedirs(logdir)\n",
    "\n",
    "    saver.save(sess, checkpoint_path, global_step=step)\n",
    "    print(' Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean argument passing\n",
    "def merge_predictions(predictions, order, num_songs = NB_SONGS, threshold=0.5, majority=5):\n",
    "    print(\"ORD:\",order)\n",
    "    print(type(predictions[0]))\n",
    "    #tf.map_fn(tf.invert_permutation, (predictions, order))\n",
    "    ordered = tf.gather(predictions, indices=order, axis=0)\n",
    "    \n",
    "    new_predictions = np.zeros(num_songs * BATCH_NB, dtype= np.float32)\n",
    "    \n",
    "    count1 = 0\n",
    "    for b in range(BATCH_NB) :\n",
    "        if ordered[b] > threshold :\n",
    "            count1 +=1\n",
    "            \n",
    "    if count1 >= majority :\n",
    "        for b in range(BATCH_NB) :\n",
    "            new_predictions[b] = 1\n",
    "    \n",
    "    return tf.convert_to_tensor(new_predictions, np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell everytime before relaunching tensorflow session\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VERSION 1 : DOESN'T HANDLE GROUPS - feeds all sample of given size to the network \n",
    "\n",
    "def train_v1() :\n",
    "    \n",
    "    # keep results for plotting\n",
    "    train_loss_results = []\n",
    "    train_auc_results = []\n",
    "\n",
    "    print(\"Initializing tf model ...\")\n",
    "\n",
    "    audio_tf= tf.convert_to_tensor(audios, np.float32)\n",
    "    print(\"Input shape : {}\".format(audio_tf.shape))\n",
    "    print(\"Labels : {}\".format(tags.flatten()))\n",
    "    print()\n",
    "\n",
    "    net = build_model(audio_tf, is_training=True, config=BASIC_CONFIG) \n",
    "    predictions = tf.layers.dense(net, NB_LABELS, activation=tf.sigmoid)\n",
    "    #predictions = merge_predictions(predictions, order2)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = tags, logits = predictions)\n",
    "    reduced_loss = tf.reduce_mean(loss)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(reduced_loss)\n",
    "    auc = tf.metrics.auc(labels = tags, predictions=predictions)\n",
    "\n",
    "\n",
    "    # Saver for storing checkpoints of the model. (Wavenets)\n",
    "    saver = tf.train.Saver(var_list=tf.global_variables())\n",
    "\n",
    "    print(\"Start training...\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "        sess.run(init)\n",
    "\n",
    "        for epoch in tqdm(range(EPOCHS)):\n",
    "            t0_epoch = time.time()\n",
    "            predict, _, loss_value, auc_score = sess.run([predictions, train_op, reduced_loss, auc])\n",
    "            #print(type(predict))\n",
    "            auc_result, update_op = auc_score\n",
    "\n",
    "            train_loss_results.append(loss_value)\n",
    "            train_auc_results.append(auc_result)\n",
    "\n",
    "            t1_epoch = time.time()\n",
    "            dur = t1_epoch-t0_epoch\n",
    "            print(\"Iter: {:3}, Time (in sec): {:.2f}, Loss: {:.4f}, AUC : {:.4f}\".format(epoch,\\\n",
    "                                                                                        dur, \\\n",
    "                                                                                         loss_value, auc_result))\n",
    "            #print(\"Predictions : {}\".format(predict.flatten()))\n",
    "            #print()\n",
    "\n",
    "        # use wavenet function > see later (for now simplest way)\n",
    "        #save(saver, sess, LOGDIR, EPOCHS)\n",
    "        saver.save(sess, LOGDIR)\n",
    "\n",
    "    end = time.time()\n",
    "    duration2 = end-start\n",
    "    print(\"Total time: {:.2f} sec.\".format(duration2))\n",
    "    \n",
    "    return train_loss_results, train_auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import wave\n",
    "#files_by_group = find_files_group(WAV_DIRECTORY, GROUP_SIZE, pattern='*.wav', sub_dir=TRAIN_DIR)\n",
    "\n",
    "#for g in files_by_group:\n",
    "  #  for f in g :\n",
    "   #     print(f)\n",
    "    #    audio = wave.open(f, mode='rb')\n",
    "     #   print(audio.getparams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment1():\n",
    "    GROUP_SIZE=10\n",
    "\n",
    "    files_by_group = find_files_group(WAV_DIRECTORY, GROUP_SIZE, pattern='*.wav', sub_dir=TRAIN_DIR)\n",
    "\n",
    "    print(\"Initialize tf model ...\")\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=(len(files_by_group[0])*BATCH_NB, BATCH_SIZE, 1))\n",
    "    y = tf.placeholder(tf.float32, shape=(len(files_by_group[0])*BATCH_NB, NB_LABELS))\n",
    "\n",
    "    net = build_model(x, is_training=True, config=BASIC_CONFIG) \n",
    "    predictions = tf.layers.dense(net, NB_LABELS, activation=tf.sigmoid)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = y, logits = predictions)\n",
    "    reduced_loss = tf.reduce_mean(loss)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(reduced_loss)\n",
    "    auc = tf.metrics.auc(labels = y, predictions=predictions)\n",
    "\n",
    "    # Saver for storing checkpoints of the model. (Wavenets)\n",
    "    saver = tf.train.Saver(var_list=tf.global_variables())\n",
    "\n",
    "    print(\"Start training...\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "        sess.run(init)\n",
    "\n",
    "        # Go through the whole DS at each EPOCH\n",
    "        for epoch in tqdm(range(EPOCHS)):\n",
    "\n",
    "            t0_epoch = time.time()\n",
    "\n",
    "            # Group by group\n",
    "            for g in files_by_group :\n",
    "\n",
    "                # Load audio and labels\n",
    "                audios, tags = load_audio_label_aux(cleaned, g, len(WAV_DIRECTORY), labels_name=LABELS_NAME, \\\n",
    "                        nb_labels=NB_LABELS, file_type=\"wav\", batch_size=BATCH_SIZE, nb_batch=BATCH_NB)\n",
    "\n",
    "                #audio_tf = tf.convert_to_tensor(audios, np.float32)\n",
    "\n",
    "                # add check to verify if there is something to restore\n",
    "                #saver.restore(sess, LOGDIR)\n",
    "\n",
    "                predict, _, loss_value, auc_score = sess.run([predictions, train_op, reduced_loss, auc],\\\n",
    "                                                             feed_dict={x: audios, y: tags})\n",
    "                auc_result, update_op = auc_score\n",
    "\n",
    "                saver.save(sess, LOGDIR)\n",
    "\n",
    "\n",
    "                train_loss_results.append(loss_value)\n",
    "                train_auc_results.append(auc_result)\n",
    "\n",
    "                print(\"Group done.\")\n",
    "\n",
    "\n",
    "            t1_epoch = time.time()\n",
    "\n",
    "            dur = t1_epoch-t0_epoch\n",
    "\n",
    "            print(\"Iter: {:3}, Time (in sec): {:.2f}, Loss: {:.4f}, AUC : {:.4f}\"\\\n",
    "                  .format(epoch, dur, loss_value, auc_result))\n",
    "\n",
    "\n",
    "\n",
    "        end = time.time()\n",
    "        duration2 = end-start\n",
    "        print(\"Total time: {:.2f} sec.\".format(duration2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this : the epoch axis not not integers which doesn't make sense\n",
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"AUC score\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_auc_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 10\n",
    "\n",
    "audios_test, tags_test, order_test, order_test2 = load_audio_label(cleaned, num_songs=TEST_SIZE, sub_dir=TEST_DIR)\n",
    "\n",
    "audios_test_tf = tf.convert_to_tensor(audios_test, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = build_model(audio_tf, is_training=False, config=BASIC_CONFIG) \n",
    "predictions = tf.layers.dense(net, NB_LABELS, activation=tf.sigmoid)\n",
    "#predictions = merge_predictions(predictions, order2)\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = tags, logits = predictions)\n",
    "reduced_loss = tf.reduce_mean(loss)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(reduced_loss)\n",
    "auc = tf.metrics.auc(labels = tags, predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_restore = {\n",
    "    var.name[:-2]: var for var in tf.global_variables()\n",
    "    if not ('state_buffer' in var.name or 'pointer' in var.name)}\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "      # Restore variables from disk.\n",
    "    saver.restore(sess, LOGDIR)\n",
    "    print(\"Model restored.\")\n",
    "    \n",
    "    init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "    sess.run(init) \n",
    "\n",
    "    predicts = sess.run([audios_test_tf, predictions, train_op, reduced_loss, auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some results \n",
    "print(\"AUC Score :\", predicts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PREDICTIONS :\", predicts[1])\n",
    "print(\"TRUE :\", tags_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following TF tutorial for custom training\n",
    "https://github.com/tensorflow/docs/blob/master/site/en/tutorials/eager/custom_training_walkthrough.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
