{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import itertools\n",
    "\n",
    "#import progressbar\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from time import sleep\n",
    "\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTT_DIR = \"../MTT/\"\n",
    "DATA_DIRECTORY = MTT_DIR + \"dataset/\"\n",
    "WAV_DIRECTORY = MTT_DIR + \"wav-dataset/\"\n",
    "\n",
    "# CSV containing song details (title, artist, id, mp3_path,...)\n",
    "CLIP_INFO_FINAL = \"clip_info_final.csv\"\n",
    "# CSV containg the labels (clip_id, labels, mp3_path)\n",
    "ANNOTATIONS_FINAL = \"annotations_final.csv\"\n",
    "# CSV : what is it useful for ?\n",
    "COMPARISONS_FINAL = \"comparisons_final.csv\"\n",
    "LABELS_FILE = MTT_DIR + ANNOTATIONS_FINAL\n",
    "\n",
    "SUB_DIRS = \"0123456789abcdef\"\n",
    "\n",
    "LOGDIR = \"checkpoints/\"\n",
    "\n",
    "AUDIO1_path = \"../MTT/mtt_data_mp3.zip/0/american_bach_soloists-j_s__bach_\\\n",
    "_transcriptions_of_italian_music-02-concerto_in_a_minor_for_four_harpsichords\\\n",
    "_bwv_1065_ii_largo-88-117.mp3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LTS2 Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines all the needed data paths, when running on LTS2 server.\n",
    "Don't run this cell if you are not running the jupyter notebook on the LTS2 server ! (will overwrite the variables defined on the cell above).\n",
    "\n",
    "You can either create a cell with your own paths, or modify the cell above with your custom paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTT_DIR = \"/mnt/scratch/students/jjgweber-MagnaTagATune/\"\n",
    "DATA_DIRECTORY = MTT_DIR + \"dataset/\"\n",
    "WAV_DIRECTORY = MTT_DIR + \"wav-dataset/\"\n",
    "\n",
    "# CSV containg the labels (clip_id, labels, mp3_path)\n",
    "ANNOTATIONS_FINAL = \"annotations_final.csv\"\n",
    "\n",
    "LABELS_FILE = MTT_DIR + ANNOTATIONS_FINAL\n",
    "\n",
    "# need to create this directory on the server !!\n",
    "LOGDIR = \"checkpoints/\"\n",
    "\n",
    "SUB_DIRS = \"0123456789abcdef\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NB = 25880 #25863\n",
    "FILE_LENGTH = 465984\n",
    "# 465984 = 2 × 2 × 2 × 2 × 2 × 2 × 3 × 3 × 809\n",
    "# useful for batches > for now divide by 9 (instead of 10)\n",
    "\n",
    "BATCH_NB = 9\n",
    "BATCH_SIZE = int(FILE_LENGTH/BATCH_NB)\n",
    "SAMPLE_SIZE = 0\n",
    "SAMPLE_RATE = 16000\n",
    "RECEPTIVE_FIELD = 0\n",
    "\n",
    "TRAIN_DIR = \"0123456789abcde\"\n",
    "TEST_DIR =\"f\"\n",
    "\n",
    "BASIC_CONFIG ={'numOutputNeurons':500}\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables which are often modified to test the algorithm\n",
    "NB_SONGS = 20\n",
    "GROUP_SIZE = 20\n",
    "EPOCHS = 16 # check in paper\n",
    "LABELS_NAME = ['guitar', 'techno']\n",
    "NB_LABELS = len(LABELS_NAME)\n",
    "threshold_tag = 0.7\n",
    "majority = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading tool functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# later : replace the cell below by this import\n",
    "from loading import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration : 2.32\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "labels = pd.read_csv(LABELS_FILE, sep = '\"\\t\"')\n",
    "end = time.time()\n",
    "print(\"Duration : {:.3}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare header to put back in the end\n",
    "# remove quotes and take all columns except the first one\n",
    "header = list(map(lambda x : x.replace('\"', ''), labels))[1:]\n",
    "# add back the first column, separated in two\n",
    "header = ['clip_id', 'no_voice']+header\n",
    "# create dictionary\n",
    "header = dict(enumerate(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_id</th>\n",
       "      <th>no_voice</th>\n",
       "      <th>singer</th>\n",
       "      <th>duet</th>\n",
       "      <th>plucking</th>\n",
       "      <th>hard rock</th>\n",
       "      <th>world</th>\n",
       "      <th>bongos</th>\n",
       "      <th>harpsichord</th>\n",
       "      <th>female singing</th>\n",
       "      <th>...</th>\n",
       "      <th>rap</th>\n",
       "      <th>metal</th>\n",
       "      <th>hip hop</th>\n",
       "      <th>quick</th>\n",
       "      <th>water</th>\n",
       "      <th>baroque</th>\n",
       "      <th>women</th>\n",
       "      <th>fiddle</th>\n",
       "      <th>english</th>\n",
       "      <th>mp3_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  clip_id no_voice singer duet plucking hard rock world bongos harpsichord  \\\n",
       "0       2        0      0    0        0         0     0      0           0   \n",
       "1       6        0      0    0        0         0     0      0           0   \n",
       "2      10        0      0    0        0         0     0      0           0   \n",
       "3      11        0      0    0        0         0     0      0           0   \n",
       "4      12        0      0    0        0         0     0      0           0   \n",
       "\n",
       "  female singing                        ...                         rap metal  \\\n",
       "0              0                        ...                           0     0   \n",
       "1              0                        ...                           0     0   \n",
       "2              0                        ...                           0     0   \n",
       "3              0                        ...                           0     0   \n",
       "4              0                        ...                           0     0   \n",
       "\n",
       "  hip hop quick water baroque women fiddle english  \\\n",
       "0       0     0     0       0     0      0       0   \n",
       "1       0     0     0       1     0      0       0   \n",
       "2       0     0     0       0     0      0       0   \n",
       "3       0     0     0       0     0      0       0   \n",
       "4       0     0     0       0     0      0       0   \n",
       "\n",
       "                                            mp3_path  \n",
       "0  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "1  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "2  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "3  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "4  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solve format problem : two first columns are merged\n",
    "# extract first column and rest\n",
    "left, right = labels['\"clip_id\\t\"\"no voice\"'], labels.iloc[:, 1:]\n",
    "# split first column in two part at separator \"\\t\"\n",
    "split = left.str.split(pat = \"\\t\", expand=True).replace('\"', '')\n",
    "\n",
    "# put back the first column which is now two, with the rest\n",
    "cleaned = pd.concat([split, right], axis=1, ignore_index=True) \n",
    "# clean by removing quotes and add back header\n",
    "cleaned = cleaned.apply(lambda col : col.apply(lambda x : x.replace('\"', ''))).rename(columns = header)\n",
    "cleaned.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : Some statistics on the MTT dataset ?\n",
    "nb_labels_per_song = cleaned.iloc[:,1:-1].astype(int).sum(axis=1)\n",
    "nb_song_per_label = cleaned.iloc[:,1:-1].astype(int).sum(axis=0)\n",
    "nb_song_per_label = nb_song_per_label.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label header is the header without clip_id and mp3_path > length 188 instead of 190\n",
    "label_header = np.asarray(list(header.values()))[1:-1]\n",
    "label_header_by_freq = np.asarray(nb_song_per_label.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,6))\n",
    "\n",
    "plot_nb = 70\n",
    "\n",
    "y_pos = np.arange(plot_nb)\n",
    "plt.bar(y_pos, nb_song_per_label[:plot_nb], align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, nb_song_per_label[:plot_nb])\n",
    "plt.ylabel('Occurence')\n",
    "plt.title('Label histogram')\n",
    "plt.xticks(np.arange(plot_nb), label_header_by_freq[:plot_nb], rotation=90, fontsize = 13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most frequent labels to start with for training\n",
    "most_freq = nb_song_per_label\n",
    "for i in range(len(nb_song_per_label)) :\n",
    "    if nb_song_per_label[i] > 2000:\n",
    "        print(i, \"> \", label_header_by_freq[i], \" -- \", nb_song_per_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_10_labels = label_header_by_freq[:10]\n",
    "best_30_labels = label_header_by_freq[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of songs : \" , cleaned.shape[0])\n",
    "print(\"Number of labels : \" , cleaned.shape[1]-2) # -2 is for index columns and mp3 path column\n",
    "print(\"Max number of songs tagged with the same label : \",max(nb_song_per_label))\n",
    "print(\"Max number of labels for a single song : \",max(nb_labels_per_song))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-occurence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from : https://stackoverflow.com/questions/20574257/constructing-a-co-occurrence-matrix-in-python-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cooccmatrix import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_labels = best_10_labels\n",
    "check_overlaps(chosen_labels, cleaned.loc[:,chosen_labels].values.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and format mp3 data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading audio & tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Example \n",
    "#to add\n",
    "\n",
    "def load_audio_label(labels, num_songs, sample_rate=None, directory=WAV_DIRECTORY, \\\n",
    "                     labels_name=LABELS_NAME, sub_dir=None, file_type=\"wav\", randomize_batch=False):\n",
    "    \n",
    "    assert (file_type==\"wav\" or file_type==\"mp3\"), \"The argument file_type should be either 'wav', either 'mp3'.\"\n",
    "    if (file_type==\"wav\" and directory!=WAV_DIRECTORY) or (file_type==\"mp3\" and directory!=DATA_DIRECTORY):\n",
    "        warnings.warn(\"File type and directory may not correspond. Make sure the \\\n",
    "        directory gave as parameter contains the right type of files\", FutureWarning, stacklevel=2)\n",
    "        \n",
    "    if num_songs > 20 :\n",
    "        warnings.warn(\"The argument num_song should not be too high (above 20), make sure this will \\\n",
    "        not cause memory error.\", FutureWarning, stacklevel=2)\n",
    "       \n",
    "    \n",
    "    print(\"Loading data ...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    if file_type==\"mp3\" :\n",
    "        files = find_files(directory, sample=num_songs, sub_dir=sub_dir)\n",
    "    if file_type==\"wav\" :\n",
    "        files = find_files(directory, sample=num_songs, sub_dir=sub_dir, pattern='*.wav')\n",
    " \n",
    "    randomized_files = randomize_files(files)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    audios = np.ndarray(shape=(num_songs * BATCH_NB, BATCH_SIZE, 1), dtype=np.float32, order='F')\n",
    "    tags = np.ndarray(shape=(num_songs * BATCH_NB, NB_LABELS), dtype=np.float32, order='F')\n",
    "    order = np.zeros(num_songs * BATCH_NB, dtype=int)\n",
    "    order2 = np.zeros(num_songs * BATCH_NB, dtype=int)\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    for filename in randomized_files:\n",
    "\n",
    "        # Load audio (MP3/WAV) file        \n",
    "        try :\n",
    "            audio, _ = librosa.load(filename, sr=sample_rate, mono=True)\n",
    "        except EOFError :\n",
    "            print(\"EOFERROR : The following file could not be loaded with librosa - \", filename)\n",
    "\n",
    "        audio = audio.reshape(-1, 1)\n",
    "         \n",
    "        for n in range(BATCH_NB) :\n",
    "            audios[idx] = audio[n*BATCH_SIZE: (n+1)*BATCH_SIZE,:]\n",
    "            \n",
    "            # take labels or corresponding song\n",
    "            \n",
    "            if file_type==\"mp3\" :\n",
    "                select_labels  = labels.loc[labels['mp3_path']==filename[len(directory):]]\n",
    "            \n",
    "            if file_type==\"wav\" :\n",
    "                select_labels  = labels.loc[labels['mp3_path']==filename[len(directory):-4]+\".mp3\"]\n",
    "\n",
    "            # select wanted labels\n",
    "            select_labels = select_labels[labels_name]\n",
    "\n",
    "            tags[idx] = select_labels.values.reshape(NB_LABELS)\n",
    "            \n",
    "            order[idx] = count\n",
    "            order2[idx] = idx\n",
    "            idx +=1\n",
    "        \n",
    "        count +=1\n",
    "        if (count % 10) == 0:\n",
    "            print(count)\n",
    "    \n",
    "    if randomize_batch :\n",
    "        rng_state = np.random.get_state()\n",
    "        np.random.shuffle(audios)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(tags)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(order)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(order2)\n",
    "        \n",
    "    end = time.time()\n",
    "    duration = end-start\n",
    "    print(\">> Total loading time - {} songs : {:.2f} sec\".format(num_songs, duration))\n",
    "    print()\n",
    "    print(\"Shape of audios list :\", audios.shape)\n",
    "    print(\"Shape of tags list :\", tags.shape)\n",
    "    return audios, tags, order, order2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_label_prim(labels, num_songs, sample_rate=None, directory=WAV_DIRECTORY, \\\n",
    "                     labels_name=LABELS_NAME, sub_dir=None, file_type=\"wav\", randomize_batch=False):\n",
    "    \n",
    "    \n",
    "    assert (file_type==\"wav\" or file_type==\"mp3\"), \"The argument file_type should be either 'wav', either 'mp3'.\"\n",
    "    if (file_type==\"wav\" and directory!=WAV_DIRECTORY) or (file_type==\"mp3\" and directory!=DATA_DIRECTORY):\n",
    "        warnings.warn(\"File type and directory may not correspond. Make sure the \\\n",
    "        directory gave as parameter contains the right type of files\", FutureWarning, stacklevel=2)\n",
    "        \n",
    "    if num_songs > 20 :\n",
    "        warnings.warn(\"The argument num_song should not be too high (above 20), make sure this will \\\n",
    "        not cause memory error.\", FutureWarning, stacklevel=2)\n",
    "        \n",
    "    print(\"Loading data ...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    if group_size != None:\n",
    "        if file_type==\"mp3\" :\n",
    "            files = find_files_group(directory, group_size, sample=num_songs, sub_dir=sub_dir, pattern='*.mp3')\n",
    "        if file_type==\"wav\" :\n",
    "            files = find_files_group(directory, group_size, sample=num_songs, sub_dir=sub_dir, pattern='*.wav')\n",
    "    \n",
    "    else :\n",
    "        if file_type==\"mp3\" :\n",
    "            files = find_files(directory, sample=num_songs, sub_dir=sub_dir, pattern='*.mp3')\n",
    "        if file_type==\"wav\" :\n",
    "            files = find_files(directory, sample=num_songs, sub_dir=sub_dir, pattern='*.wav')\n",
    "            \n",
    "    randomized_files = randomize_files(files)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    audios = np.ndarray(shape=(num_songs * BATCH_NB, BATCH_SIZE, 1), dtype=np.float32, order='F')\n",
    "    tags = np.ndarray(shape=(num_songs * BATCH_NB, NB_LABELS), dtype=np.float32, order='F')\n",
    "    order = np.zeros(num_songs * BATCH_NB, dtype=int)\n",
    "    order2 = np.zeros(num_songs * BATCH_NB, dtype=int)\n",
    "    \n",
    "\n",
    "    \n",
    "    if group_size != None :\n",
    "        for group in files :\n",
    "            load_audio_label_aux(cleaned, group, len(directory), labels_name=labels_name, file_type=file_type)\n",
    "    \n",
    "    # check where to put this after        \n",
    "    if randomize_batch :\n",
    "        rng_state = np.random.get_state()\n",
    "        np.random.shuffle(audios)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(tags)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(order)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(order2)\n",
    "        \n",
    "    end = time.time()\n",
    "    duration = end-start\n",
    "    print(\">> Total loading time - {} songs : {:.2f} sec\".format(num_songs, duration))\n",
    "    print()\n",
    "    print(\"Shape of audios list :\", audios.shape)\n",
    "    print(\"Shape of tags list :\", tags.shape)\n",
    "    return audios, tags, order, order2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_label_aux(labels, filenames, prefix_len, labels_name=LABELS_NAME, nb_labels=NB_LABELS, \\\n",
    "                         file_type=\"mp3\", batch_size=BATCH_SIZE, nb_batch=BATCH_NB):\n",
    "    \n",
    "    nb_songs = len(filenames)\n",
    "    \n",
    "    print(\"Loading {} songs ...\".format(nb_songs))\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    audios = np.ndarray(shape=(nb_songs * nb_batch, batch_size, 1), dtype=np.float32, order='F')\n",
    "    tags = np.ndarray(shape=(nb_songs * nb_batch, nb_labels), dtype=np.float32, order='F')\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    idx = 0\n",
    "        \n",
    "    for f in filenames:\n",
    "\n",
    "        # Load audio (MP3/WAV) file        \n",
    "        try :\n",
    "            audio, _ = librosa.load(f, sr=None, mono=True)\n",
    "        except EOFError :\n",
    "            print(\"EOFERROR : The following file could not be loaded with librosa - \", f)\n",
    "\n",
    "        audio = audio.reshape(-1, 1)\n",
    "        \n",
    "        for n in range(nb_batch) :\n",
    "            audios[idx] = audio[n*batch_size: (n+1)*batch_size,:]\n",
    "            \n",
    "            # take labels or corresponding song\n",
    "            \n",
    "            if file_type==\"mp3\" :\n",
    "                select_labels  = labels.loc[labels['mp3_path']==f[prefix_len:]]\n",
    "            \n",
    "            if file_type==\"wav\" :\n",
    "                select_labels  = labels.loc[labels['mp3_path']==f[prefix_len:-4]+\".mp3\"]\n",
    "\n",
    "            # select wanted labels\n",
    "            select_labels = select_labels[labels_name]\n",
    "\n",
    "            tags[idx] = select_labels.values.reshape(nb_labels)\n",
    "            \n",
    "            idx +=1\n",
    "        \n",
    "        count +=1\n",
    "        if (count % 10) == 0:\n",
    "            print(count)\n",
    "        \n",
    "    end = time.time()\n",
    "    duration = end-start\n",
    "    \n",
    "    print(\">> Total loading time - {} songs : {:.2f} sec\".format(nb_songs, duration))\n",
    "    print()\n",
    "    print(\"Shape of audios list :\", audios.shape)\n",
    "    print(\"Shape of tags list :\", tags.shape)\n",
    "    \n",
    "    return audios, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "['../MTT/dataset/0/william_brooks-bitter_circus-10-my_love_looks_the_other_way-59-88.mp3', '../MTT/dataset/0/barbara_leoni-human_needs-06-haunted-117-146.mp3', '../MTT/dataset/0/the_bots-truth-02-power_and_domination-59-88.mp3', '../MTT/dataset/0/williamson-a_few_things_to_hear_before_we_all_blow_up-11-whiffle-146-175.mp3', '../MTT/dataset/0/williamson-a_few_things_to_hear_before_we_all_blow_up-04-time_youll_never_get_back-175-204.mp3']\n",
      "10\n",
      "20\n",
      ">> Total loading time - 20 songs : 1.05 sec\n",
      "\n",
      "Shape of audios list : (180, 51776, 1)\n",
      "Shape of tags list : (180, 2)\n"
     ]
    }
   ],
   "source": [
    "# load audios and labels > convert to numpy\n",
    "# CAREFUL : the argument num_songs is important and shouldn't be too big \n",
    "# > otherwise MEMORY ISSUES !!!!!!\n",
    "audios, tags, order, order2 = load_audio_label(cleaned, num_songs=NB_SONGS, sub_dir=TRAIN_DIR, \\\n",
    "                                file_type=\"mp3\", directory=DATA_DIRECTORY, randomize_batch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save neural net state tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used for now\n",
    "def save(saver, sess, logdir, step):\n",
    "    model_name = 'model.ckpt'\n",
    "    checkpoint_path = os.path.join(logdir, model_name)\n",
    "    print('Storing checkpoint to {} ...'.format(logdir), end=\"\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if not os.path.exists(logdir):\n",
    "        os.makedirs(logdir)\n",
    "\n",
    "    saver.save(sess, checkpoint_path, global_step=step)\n",
    "    print(' Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean argument passing\n",
    "def merge_predictions(predictions, order, num_songs = NB_SONGS, threshold=0.5, majority=5):\n",
    "    print(\"ORD:\",order)\n",
    "    print(type(predictions[0]))\n",
    "    #tf.map_fn(tf.invert_permutation, (predictions, order))\n",
    "    ordered = tf.gather(predictions, indices=order, axis=0)\n",
    "    \n",
    "    new_predictions = np.zeros(num_songs * BATCH_NB, dtype= np.float32)\n",
    "    \n",
    "    count1 = 0\n",
    "    for b in range(BATCH_NB) :\n",
    "        if ordered[b] > threshold :\n",
    "            count1 +=1\n",
    "            \n",
    "    if count1 >= majority :\n",
    "        for b in range(BATCH_NB) :\n",
    "            new_predictions[b] = 1\n",
    "    \n",
    "    return tf.convert_to_tensor(new_predictions, np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell everytime before relaunching tensorflow session\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep results for plotting\n",
    "train_loss_results = []\n",
    "train_auc_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(\"GLOBAL :\", [str(i.name) for i in tf.global_variables()])\\n    print(\"LOCAL :\", [str(i.name) for i in tf.local_variables()])\\n    print(\"TRAINABLE :\",[str(i.name) for i in tf.trainable_variables()]) '"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lines used to understand local vs global vs trainable\n",
    "'''print(\"GLOBAL :\", [str(i.name) for i in tf.global_variables()])\n",
    "    print(\"LOCAL :\", [str(i.name) for i in tf.local_variables()])\n",
    "    print(\"TRAINABLE :\",[str(i.name) for i in tf.trainable_variables()]) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing tf model ...\n",
      "Input shape : (180, 51776, 1)\n",
      "Labels : [0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
      " 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8306ac3163749268cc89b2632ad6de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:   0, Time (in sec): 24.80, Loss: 0.9404, AUC : 0.0000\n",
      "Iter:   1, Time (in sec): 16.95, Loss: 0.8653, AUC : 0.2589\n",
      "Iter:   2, Time (in sec): 16.33, Loss: 0.8232, AUC : 0.6345\n",
      "Iter:   3, Time (in sec): 17.32, Loss: 0.7796, AUC : 0.7534\n",
      "Iter:   4, Time (in sec): 16.22, Loss: 0.7426, AUC : 0.8180\n",
      "Iter:   5, Time (in sec): 16.08, Loss: 0.7159, AUC : 0.8687\n",
      "Iter:   6, Time (in sec): 16.61, Loss: 0.6959, AUC : 0.9032\n",
      "Iter:   7, Time (in sec): 17.03, Loss: 0.6828, AUC : 0.9264\n",
      "Iter:   8, Time (in sec): 16.72, Loss: 0.6720, AUC : 0.9424\n",
      "Iter:   9, Time (in sec): 22.52, Loss: 0.6641, AUC : 0.9540\n",
      "Iter:  10, Time (in sec): 17.91, Loss: 0.6560, AUC : 0.9626\n",
      "Iter:  11, Time (in sec): 16.89, Loss: 0.6532, AUC : 0.9690\n",
      "Iter:  12, Time (in sec): 16.94, Loss: 0.6487, AUC : 0.9738\n",
      "Iter:  13, Time (in sec): 18.18, Loss: 0.6457, AUC : 0.9777\n",
      "Iter:  14, Time (in sec): 16.90, Loss: 0.6442, AUC : 0.9808\n",
      "Iter:  15, Time (in sec): 17.20, Loss: 0.6421, AUC : 0.9832\n",
      "\n",
      "Total time: 287.56 sec.\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing tf model ...\")\n",
    "\n",
    "audio_tf= tf.convert_to_tensor(audios, np.float32)\n",
    "print(\"Input shape : {}\".format(audio_tf.shape))\n",
    "print(\"Labels : {}\".format(tags.flatten()))\n",
    "print()\n",
    "\n",
    "net = build_model(audio_tf, is_training=True, config=BASIC_CONFIG) \n",
    "predictions = tf.layers.dense(net, NB_LABELS, activation=tf.sigmoid)\n",
    "#predictions = merge_predictions(predictions, order2)\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = tags, logits = predictions)\n",
    "reduced_loss = tf.reduce_mean(loss)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(reduced_loss)\n",
    "auc = tf.metrics.auc(labels = tags, predictions=predictions)\n",
    "\n",
    "\n",
    "# Saver for storing checkpoints of the model. (Wavenets)\n",
    "saver = tf.train.Saver(var_list=tf.global_variables())\n",
    "    \n",
    "print(\"Start training...\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        t0_epoch = time.time()\n",
    "        predict, _, loss_value, auc_score = sess.run([predictions, train_op, reduced_loss, auc])\n",
    "        #print(type(predict))\n",
    "        auc_result, update_op = auc_score\n",
    "        \n",
    "        train_loss_results.append(loss_value)\n",
    "        train_auc_results.append(auc_result)\n",
    "        \n",
    "        t1_epoch = time.time()\n",
    "        dur = t1_epoch-t0_epoch\n",
    "        print(\"Iter: {:3}, Time (in sec): {:.2f}, Loss: {:.4f}, AUC : {:.4f}\".format(epoch,\\\n",
    "                                                                                    dur, loss_value, auc_result))\n",
    "        #print(\"Predictions : {}\".format(predict.flatten()))\n",
    "        #print()\n",
    "     \n",
    "    # use wavenet function > see later (for now simplest way)\n",
    "    #save(saver, sess, LOGDIR, EPOCHS)\n",
    "    saver.save(sess, LOGDIR)\n",
    "\n",
    "end = time.time()\n",
    "duration2 = end-start\n",
    "print(\"Total time: {:.2f} sec.\".format(duration2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 songs ...\n",
      "10\n",
      "20\n",
      ">> Total loading time - 20 songs : 0.93 sec\n",
      "\n",
      "Shape of audios list : (180, 51776, 1)\n",
      "Shape of tags list : (180, 2)\n"
     ]
    }
   ],
   "source": [
    "files_by_group = find_files_group(DATA_DIRECTORY, GROUP_SIZE,sample =  pattern='*.mp3', sub_dir=TRAIN_DIR)\n",
    "\n",
    "#for g in files_by_group :\n",
    "g = files_by_group[10]\n",
    "\n",
    "audios, tags = load_audio_label_aux(cleaned, g, len(DATA_DIRECTORY), labels_name=LABELS_NAME, \\\n",
    "                    nb_labels=NB_LABELS, file_type=\"mp3\", batch_size=BATCH_SIZE, nb_batch=BATCH_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-88-8453d738c045>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-88-8453d738c045>\"\u001b[0;36m, line \u001b[0;32m44\u001b[0m\n\u001b[0;31m    t0_epoch = time.time()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# VERSION 2 : feed group by group\n",
    "files_by_group = find_files_group(DATA_DIRECTORY, GROUP_SIZE, pattern='*.mp3', sub_dir=TRAIN_DIR)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Go through the whole DS at each EPOCH\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "\n",
    "        for subdir in TRAIN_DIR :\n",
    "            audios, tags, order, order2 = load_audio_label(cleaned, num_songs = GROUP_SIZE, sub_dir=subdir, \\\n",
    "                                        file_type=\"mp3\", directory=DATA_DIRECTORY, randomize_batch=True)\n",
    "            \n",
    "            audio_tf= tf.convert_to_tensor(audios, np.float32)\n",
    "\n",
    "\n",
    "print(\"Initializing tf model ...\")\n",
    "\n",
    "audio_tf= tf.convert_to_tensor(audios, np.float32)\n",
    "print(\"Input shape : {}\".format(audio_tf.shape))\n",
    "print(\"Labels : {}\".format(tags.flatten()))\n",
    "print()\n",
    "\n",
    "net = build_model(audio_tf, is_training=True, config=BASIC_CONFIG) \n",
    "predictions = tf.layers.dense(net, NB_LABELS, activation=tf.sigmoid)\n",
    "#predictions = merge_predictions(predictions, order2)\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = tags, logits = predictions)\n",
    "reduced_loss = tf.reduce_mean(loss)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(reduced_loss)\n",
    "auc = tf.metrics.auc(labels = tags, predictions=predictions)\n",
    "\n",
    "\n",
    "# Saver for storing checkpoints of the model. (Wavenets)\n",
    "saver = tf.train.Saver(var_list=tf.global_variables())\n",
    "    \n",
    "print(\"Start training...\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "\n",
    "        t0_epoch = time.time()\n",
    "        predict, _, loss_value, auc_score = sess.run([predictions, train_op, reduced_loss, auc])\n",
    "        #print(type(predict))\n",
    "        auc_result, update_op = auc_score\n",
    "        \n",
    "        train_loss_results.append(loss_value)\n",
    "        train_auc_results.append(auc_result)\n",
    "        \n",
    "        t1_epoch = time.time()\n",
    "        dur = t1_epoch-t0_epoch\n",
    "        print(\"Iter: {:3}, Time (in sec): {:.2f}, Loss: {:.4f}, AUC : {:.4f}\".format(epoch,\\\n",
    "                                                                                    dur, loss_value, auc_result))\n",
    "        #print(\"Predictions : {}\".format(predict.flatten()))\n",
    "        #print()\n",
    "     \n",
    "    # use wavenet function > see later (for now simplest way)\n",
    "    #save(saver, sess, LOGDIR, EPOCHS)\n",
    "    saver.save(sess, LOGDIR)\n",
    "\n",
    "end = time.time()\n",
    "duration2 = end-start\n",
    "print(\"Total time: {:.2f} sec.\".format(duration2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# modify this : the epoch axis not not integers which doesn't make sense\n",
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"AUC score\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_auc_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 10\n",
    "\n",
    "audios_test, tags_test, order_test, order_test2 = load_audio_label(cleaned, num_songs=TEST_SIZE, sub_dir=TEST_DIR)\n",
    "\n",
    "audios_test_tf = tf.convert_to_tensor(audios_test, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"conv1d/kernel:0\", shape=(3, 1, 64), dtype=float32_ref) must be from the same graph as Tensor(\"Const:0\", shape=(180, 51776, 1), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-0a9c27da35b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBASIC_CONFIG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNB_LABELS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#predictions = merge_predictions(predictions, order2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreduced_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EPFL/Master/semester_project/pds/models.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(x, is_training, config)\u001b[0m\n\u001b[1;32m    375\u001b[0m     '''\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwave_frontend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m     \u001b[0;31m# The following line builds the model that achieved better results in our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;31m# experiments. It is based on a spectrogram front-end (num_filters=16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EPFL/Master/semester_project/pds/models.py\u001b[0m in \u001b[0;36mwave_frontend\u001b[0;34m(x, is_training)\u001b[0m\n\u001b[1;32m     55\u001b[0m                              \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                              \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                              kernel_initializer=initializer)\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mbn_conv0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(inputs, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0m_reuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m       _scope=name)\n\u001b[0;32m--> 214\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \"\"\"\n\u001b[0;32m--> 817\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_set_learning_phase_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'causal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         name=self.name)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv1d\u001b[0;34m(self, input, filter, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   \u001b[0;31m# pylint: enable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 553\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    555\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 553\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    555\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[1;32m   2449\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0minvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m   \"\"\"\n\u001b[0;32m-> 2451\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"conv1d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2452\u001b[0m     \u001b[0;31m# Reshape the input tensor to [batch, 1, in_width, in_channels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"NHWC\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"NWC\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6021\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6022\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6023\u001b[0;31m       \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6024\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6025\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[0;34m(op_input_list, graph)\u001b[0m\n\u001b[1;32m   5662\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5663\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5664\u001b[0;31m         \u001b[0m_assert_same_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5665\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5666\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[0;34m(original_item, item)\u001b[0m\n\u001b[1;32m   5598\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5599\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" % (item,\n\u001b[0;32m-> 5600\u001b[0;31m                                                                 original_item))\n\u001b[0m\u001b[1;32m   5601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor(\"conv1d/kernel:0\", shape=(3, 1, 64), dtype=float32_ref) must be from the same graph as Tensor(\"Const:0\", shape=(180, 51776, 1), dtype=float32)."
     ]
    }
   ],
   "source": [
    "net = build_model(audio_tf, is_training=False, config=BASIC_CONFIG) \n",
    "predictions = tf.layers.dense(net, NB_LABELS, activation=tf.sigmoid)\n",
    "#predictions = merge_predictions(predictions, order2)\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = tags, logits = predictions)\n",
    "reduced_loss = tf.reduce_mean(loss)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(reduced_loss)\n",
    "auc = tf.metrics.auc(labels = tags, predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/\n",
      "Model restored.\n"
     ]
    }
   ],
   "source": [
    "variables_to_restore = {\n",
    "    var.name[:-2]: var for var in tf.global_variables()\n",
    "    if not ('state_buffer' in var.name or 'pointer' in var.name)}\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "      # Restore variables from disk.\n",
    "    saver.restore(sess, LOGDIR)\n",
    "    print(\"Model restored.\")\n",
    "    \n",
    "    init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "    sess.run(init) \n",
    "\n",
    "    predicts = sess.run([audios_test_tf, predictions, train_op, reduced_loss, auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score : (0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "# Print some results \n",
    "print(\"AUC Score :\", predicts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS : [[0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.60562223 0.5653917 ]\n",
      " [0.6056222  0.5653917 ]\n",
      " [0.6056222  0.5653917 ]]\n",
      "TRUE : [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"PREDICTIONS :\", predicts[1])\n",
    "print(\"TRUE :\", tags_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following TF tutorial for custom training\n",
    "https://github.com/tensorflow/docs/blob/master/site/en/tutorials/eager/custom_training_walkthrough.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
