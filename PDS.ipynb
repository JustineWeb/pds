{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import itertools\n",
    "\n",
    "#import progressbar\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from time import sleep\n",
    "\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTT_DIR = \"../MTT/\"\n",
    "DATA_DIRECTORY = MTT_DIR + \"dataset/\"\n",
    "WAV_DIRECTORY = MTT_DIR + \"wav-dataset/\"\n",
    "\n",
    "# CSV containing song details (title, artist, id, mp3_path,...)\n",
    "CLIP_INFO_FINAL = \"clip_info_final.csv\"\n",
    "# CSV containg the labels (clip_id, labels, mp3_path)\n",
    "ANNOTATIONS_FINAL = \"annotations_final.csv\"\n",
    "# CSV : what is it useful for ?\n",
    "COMPARISONS_FINAL = \"comparisons_final.csv\"\n",
    "LABELS_FILE = MTT_DIR + ANNOTATIONS_FINAL\n",
    "\n",
    "SUB_DIRS = \"0123456789abcdef\"\n",
    "\n",
    "LOGDIR = \"checkpoints/\"\n",
    "\n",
    "AUDIO1_path = \"../MTT/mtt_data_mp3.zip/0/american_bach_soloists-j_s__bach_\\\n",
    "_transcriptions_of_italian_music-02-concerto_in_a_minor_for_four_harpsichords\\\n",
    "_bwv_1065_ii_largo-88-117.mp3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LTS2 Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines all the needed data paths, when running on LTS2 server.\n",
    "Don't run this cell if you are not running the jupyter notebook on the LTS2 server ! (will overwrite the variables defined on the cell above).\n",
    "\n",
    "You can either create a cell with your own paths, or modify the cell above with your custom paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTT_DIR = \"/mnt/scratch/students/jjgweber-MagnaTagATune/\"\n",
    "DATA_DIRECTORY = MTT_DIR + \"dataset/\"\n",
    "WAV_DIRECTORY = MTT_DIR + \"wav-dataset/\"\n",
    "\n",
    "# CSV containg the labels (clip_id, labels, mp3_path)\n",
    "ANNOTATIONS_FINAL = \"annotations_final.csv\"\n",
    "\n",
    "LABELS_FILE = MTT_DIR + ANNOTATIONS_FINAL\n",
    "\n",
    "# need to create this directory on the server !!\n",
    "LOGDIR = \"checkpoints/\"\n",
    "\n",
    "SUB_DIRS = \"0123456789abcdef\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NB = 25880 #25863\n",
    "FILE_LENGTH = 465984\n",
    "# 465984 = 2 × 2 × 2 × 2 × 2 × 2 × 3 × 3 × 809\n",
    "# useful for batches > for now divide by 9 (instead of 10)\n",
    "\n",
    "BATCH_NB = 9\n",
    "BATCH_SIZE = int(FILE_LENGTH/BATCH_NB)\n",
    "SAMPLE_SIZE = 0\n",
    "SAMPLE_RATE = 16000\n",
    "RECEPTIVE_FIELD = 0\n",
    "\n",
    "TRAIN_DIR = \"0123456789abcde\"\n",
    "TEST_DIR =\"f\"\n",
    "\n",
    "BASIC_CONFIG ={'numOutputNeurons':500}\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables which are often modified to test the algorithm\n",
    "NB_SONGS = 20\n",
    "EPOCHS = 50 # check in paper\n",
    "LABELS_NAME = ['guitar', 'techno']\n",
    "NB_LABELS = len(LABELS_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading tool functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(labels_file_name):\n",
    "    pd.read_csv(labels_file_name)\n",
    "\n",
    "def randomize_files(files):\n",
    "    for file in files:\n",
    "        file_index = random.randint(0, (len(files) - 1))\n",
    "        yield files[file_index]\n",
    "\n",
    "\n",
    "# ATTENTION : in the current configuration, everytime this function is called it goes through \n",
    "# all the sub-directories even if the sample is set to 6\n",
    "# it only prunes the output at the end\n",
    "# > there could be a more efficient way for doing this\n",
    "# TODO later\n",
    "def find_files(directory, pattern='*.mp3', sample=None, sub_dir=None):\n",
    "    '''Recursively finds all files matching the pattern.'''\n",
    "    # subdir sould be a string, for example \"abc03\", \n",
    "    # meaning we take data from directories a,b,c,0 and 3\n",
    "    \n",
    "    files = []\n",
    "    directories = []\n",
    "    \n",
    "    # TODO : add lines to check format of input\n",
    "    # TODO : try/except ?\n",
    "    \n",
    "    if sub_dir!=None :\n",
    "        for c in sub_dir :\n",
    "            directories.append(directory+c+\"/\")\n",
    "    else :\n",
    "        directories.append(directory)\n",
    "    \n",
    "    for path in directories :\n",
    "        for root, dirnames, filenames in os.walk(path):\n",
    "            for filename in fnmatch.filter(filenames, pattern):\n",
    "                files.append(os.path.join(root, filename))\n",
    "\n",
    "    if sample!=None :\n",
    "        try:\n",
    "            return files[:sample]\n",
    "        except TypeError:\n",
    "            print(\"Argument sample should be either None, or an integer :\\\n",
    "             the number of first n samples to take.\")\n",
    "    else :\n",
    "        return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration : 2.25\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "labels = pd.read_csv(LABELS_FILE, sep = '\"\\t\"')\n",
    "end = time.time()\n",
    "print(\"Duration : {:.3}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare header to put back in the end\n",
    "# remove quotes and take all columns except the first one\n",
    "header = list(map(lambda x : x.replace('\"', ''), labels))[1:]\n",
    "# add back the first column, separated in two\n",
    "header = ['clip_id', 'no_voice']+header\n",
    "# create dictionary\n",
    "header = dict(enumerate(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_id</th>\n",
       "      <th>no_voice</th>\n",
       "      <th>singer</th>\n",
       "      <th>duet</th>\n",
       "      <th>plucking</th>\n",
       "      <th>hard rock</th>\n",
       "      <th>world</th>\n",
       "      <th>bongos</th>\n",
       "      <th>harpsichord</th>\n",
       "      <th>female singing</th>\n",
       "      <th>...</th>\n",
       "      <th>rap</th>\n",
       "      <th>metal</th>\n",
       "      <th>hip hop</th>\n",
       "      <th>quick</th>\n",
       "      <th>water</th>\n",
       "      <th>baroque</th>\n",
       "      <th>women</th>\n",
       "      <th>fiddle</th>\n",
       "      <th>english</th>\n",
       "      <th>mp3_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  clip_id no_voice singer duet plucking hard rock world bongos harpsichord  \\\n",
       "0       2        0      0    0        0         0     0      0           0   \n",
       "1       6        0      0    0        0         0     0      0           0   \n",
       "2      10        0      0    0        0         0     0      0           0   \n",
       "3      11        0      0    0        0         0     0      0           0   \n",
       "4      12        0      0    0        0         0     0      0           0   \n",
       "\n",
       "  female singing                        ...                         rap metal  \\\n",
       "0              0                        ...                           0     0   \n",
       "1              0                        ...                           0     0   \n",
       "2              0                        ...                           0     0   \n",
       "3              0                        ...                           0     0   \n",
       "4              0                        ...                           0     0   \n",
       "\n",
       "  hip hop quick water baroque women fiddle english  \\\n",
       "0       0     0     0       0     0      0       0   \n",
       "1       0     0     0       1     0      0       0   \n",
       "2       0     0     0       0     0      0       0   \n",
       "3       0     0     0       0     0      0       0   \n",
       "4       0     0     0       0     0      0       0   \n",
       "\n",
       "                                            mp3_path  \n",
       "0  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "1  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "2  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "3  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "4  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solve format problem : two first columns are merged\n",
    "# extract first column and rest\n",
    "left, right = labels['\"clip_id\\t\"\"no voice\"'], labels.iloc[:, 1:]\n",
    "# split first column in two part at separator \"\\t\"\n",
    "split = left.str.split(pat = \"\\t\", expand=True).replace('\"', '')\n",
    "\n",
    "# put back the first column which is now two, with the rest\n",
    "cleaned = pd.concat([split, right], axis=1, ignore_index=True) \n",
    "# clean by removing quotes and add back header\n",
    "cleaned = cleaned.apply(lambda col : col.apply(lambda x : x.replace('\"', ''))).rename(columns = header)\n",
    "cleaned.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : Some statistics on the MTT dataset ?\n",
    "nb_labels_per_song = cleaned.iloc[:,1:-1].astype(int).sum(axis=1)\n",
    "nb_song_per_label = cleaned.iloc[:,1:-1].astype(int).sum(axis=0)\n",
    "nb_song_per_label = nb_song_per_label.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label header is the header without clip_id and mp3_path > length 188 instead of 190\n",
    "label_header = np.asarray(list(header.values()))[1:-1]\n",
    "label_header_by_freq = np.asarray(nb_song_per_label.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,6))\n",
    "\n",
    "plot_nb = 70\n",
    "\n",
    "y_pos = np.arange(plot_nb)\n",
    "plt.bar(y_pos, nb_song_per_label[:plot_nb], align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, nb_song_per_label[:plot_nb])\n",
    "plt.ylabel('Occurence')\n",
    "plt.title('Label histogram')\n",
    "plt.xticks(np.arange(plot_nb), label_header_by_freq[:plot_nb], rotation=90, fontsize = 13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most frequent labels to start with for training\n",
    "most_freq = nb_song_per_label\n",
    "for i in range(len(nb_song_per_label)) :\n",
    "    if nb_song_per_label[i] > 2000:\n",
    "        print(i, \"> \", label_header_by_freq[i], \" -- \", nb_song_per_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_10_labels = label_header_by_freq[:10]\n",
    "best_30_labels = label_header_by_freq[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of songs : \" , cleaned.shape[0])\n",
    "print(\"Number of labels : \" , cleaned.shape[1]-2) # -2 is for index columns and mp3 path column\n",
    "print(\"Max number of songs tagged with the same label : \",max(nb_song_per_label))\n",
    "print(\"Max number of labels for a single song : \",max(nb_labels_per_song))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-occurence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from : https://stackoverflow.com/questions/20574257/constructing-a-co-occurrence-matrix-in-python-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_values(pc, fmt=\"%.2f\", **kw):\n",
    "    '''\n",
    "    Heatmap with text in each cell with matplotlib's pyplot\n",
    "    Source: http://stackoverflow.com/a/25074150/395857 \n",
    "    By HYRY\n",
    "    '''\n",
    "    #from itertools import izip\n",
    "    pc.update_scalarmappable()\n",
    "    ax = pc.axes\n",
    "    for p, color, value in zip(pc.get_paths(), pc.get_facecolors(), pc.get_array()):\n",
    "        x, y = p.vertices[:-2, :].mean(0)\n",
    "        if np.all(color[:3] > 0.5):\n",
    "            color = (0.0, 0.0, 0.0)\n",
    "        else:\n",
    "            color = (1.0, 1.0, 1.0)\n",
    "        ax.text(x, y, fmt % value, ha=\"center\", va=\"center\", color=color, **kw)\n",
    "\n",
    "def cm2inch(*tupl):\n",
    "    '''\n",
    "    Specify figure size in centimeter in matplotlib\n",
    "    Source: http://stackoverflow.com/a/22787457/395857\n",
    "    By gns-ank\n",
    "    '''\n",
    "    inch = 2.54\n",
    "    if type(tupl[0]) == tuple:\n",
    "        return tuple(i/inch for i in tupl[0])\n",
    "    else:\n",
    "        return tuple(i/inch for i in tupl)\n",
    "\n",
    "def heatmap(AUC, title, xlabel, ylabel, xticklabels, yticklabels):\n",
    "    '''\n",
    "    Inspired by:\n",
    "    - http://stackoverflow.com/a/16124677/395857 \n",
    "    - http://stackoverflow.com/a/25074150/395857\n",
    "    '''\n",
    "\n",
    "    # Plot it out\n",
    "    fig, ax = plt.subplots()    \n",
    "    c = ax.pcolor(AUC, edgecolors='k', linestyle= 'dashed', linewidths=0.2, cmap='RdBu', vmin=0.0, vmax=1.0)\n",
    "\n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_yticks(np.arange(AUC.shape[0]) + 0.5, minor=False)\n",
    "    ax.set_xticks(np.arange(AUC.shape[1]) + 0.5, minor=False)\n",
    "\n",
    "    # set tick labels\n",
    "    #ax.set_xticklabels(np.arange(1,AUC.shape[1]+1), minor=False)\n",
    "    ax.set_xticklabels(xticklabels, minor=False)\n",
    "    ax.set_yticklabels(yticklabels, minor=False)\n",
    "\n",
    "    # set title and x/y labels\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)      \n",
    "\n",
    "    # Remove last blank column\n",
    "    plt.xlim( (0, AUC.shape[1]) )\n",
    "\n",
    "    # Turn off all the ticks\n",
    "    ax = plt.gca()    \n",
    "    for t in ax.xaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "    for t in ax.yaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "\n",
    "    # Add color bar\n",
    "    plt.colorbar(c)\n",
    "\n",
    "    # Add text in each cell \n",
    "    show_values(c)\n",
    "\n",
    "    # Proper orientation (origin at the top left instead of bottom left)\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    "\n",
    "    # resize \n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(cm2inch(40, 20))\n",
    "\n",
    "\n",
    "\n",
    "def check_overlaps(label_headers, label_data):\n",
    "\n",
    "\n",
    "    print('labels:\\n{0}'.format(label_data))\n",
    "\n",
    "    # Compute cooccurrence matrix \n",
    "    cooccurrence_matrix = np.dot(label_data.transpose(),label_data)\n",
    "    print('\\ncooccurrence_matrix:\\n{0}'.format(cooccurrence_matrix)) \n",
    "\n",
    "    # Compute cooccurrence matrix in percentage\n",
    "    # FYI: http://stackoverflow.com/questions/19602187/numpy-divide-each-row-by-a-vector-element\n",
    "    #      http://stackoverflow.com/questions/26248654/numpy-return-0-with-divide-by-zero/32106804#32106804\n",
    "    cooccurrence_matrix_diagonal = np.diagonal(cooccurrence_matrix)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        cooccurrence_matrix_percentage = np.nan_to_num(np.true_divide(cooccurrence_matrix, \\\n",
    "                                                                      cooccurrence_matrix_diagonal[:, None]))\n",
    "    print('\\ncooccurrence_matrix_percentage:\\n{0}'.format(cooccurrence_matrix_percentage))\n",
    "\n",
    "    # Add count in labels\n",
    "    label_header_with_count = [ '{0} ({1})'.format(label_header, cooccurrence_matrix_diagonal[label_number]) \\\n",
    "                               for label_number, label_header in enumerate(label_headers)]  \n",
    "    print('\\nlabel_header_with_count: {0}'.format(label_header_with_count))\n",
    "\n",
    "    # Plotting\n",
    "    x_axis_size = cooccurrence_matrix_percentage.shape[0]\n",
    "    y_axis_size = cooccurrence_matrix_percentage.shape[1]\n",
    "    title = \"Co-occurrence matrix\\n\"\n",
    "    xlabel= ''#\"Labels\"\n",
    "    ylabel= ''#\"Labels\"\n",
    "    xticklabels = label_header_with_count\n",
    "    yticklabels = label_header_with_count\n",
    "    heatmap(cooccurrence_matrix_percentage, title, xlabel, ylabel, xticklabels, yticklabels)\n",
    "    plt.savefig('image_output.png', dpi=300, format='png', bbox_inches='tight') \n",
    "    # use format='svg' or 'pdf' for vectorial pictures\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_labels = best_10_labels\n",
    "check_overlaps(chosen_labels, cleaned.loc[:,chosen_labels].values.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and format mp3 data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create wav files from the mp3 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should not run this, it was only supposed to be used once for converting all mp3 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_mp3_to_wav(files, wav_dir):\n",
    "    print(\"Start converting files from mp3 to wav...\")\n",
    "    count = 0\n",
    "    for file_name in files :\n",
    "        \n",
    "        file_name_cut = file_name[len(DATA_DIRECTORY):-4]\n",
    "\n",
    "        dir_path = wav_dir + file_name_cut[:2]\n",
    "\n",
    "        new_file_name = wav_dir + file_name_cut + \".wav\"\n",
    "        \n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "            \n",
    "        try :\n",
    "            y, sr = librosa.load(file_name, sr=None, mono=True)\n",
    "            librosa.output.write_wav(new_file_name, y, sr)\n",
    "            \n",
    "        except EOFError :\n",
    "            print(\"EOFERROR : The following file could not be loaded with librosa - \", file_name) \n",
    "            \n",
    "        count +=1\n",
    "        if (count % 200) == 0:\n",
    "            print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0a = time.time()\n",
    "files = find_files(DATA_DIRECTORY)\n",
    "t1a = time.time()\n",
    "from_mp3_to_wav(files, WAV_DIRECTORY)\n",
    "t2a = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Find files time : {:.3f} sec\".format(t1a-t0a))\n",
    "print(\"From mp3 to wav time : {:.2f} hours\".format((t2a-t1a)/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Time to convert 1 song from mp3 to wav : {:.4f} sec\".format((t2a-t1a)/FILE_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading audio & tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Example \n",
    "# load_audio_label(cleaned, num_songs=100, directory=WAV_DIRECTORY, sub_dir=TRAIN_DIR, file_type=\"wav\")\n",
    "\n",
    "def load_audio_label(labels, num_songs=NB_SONGS, sample_rate=None, directory=WAV_DIRECTORY, \\\n",
    "                     labels_name=LABELS_NAME, sub_dir=None, file_type=\"wav\"):\n",
    "    \n",
    "    assert (file_type==\"wav\" or file_type==\"mp3\"), \"The argument file_type should be either 'wav', either 'mp3'.\"\n",
    "    if (file_type==\"wav\" and directory!=WAV_DIRECTORY) or (file_type==\"mp3\" and directory!=DATA_DIRECTORY):\n",
    "        warnings.warn(\"File type and directory may not correspond. Make sure the \\\n",
    "        directory gave as parameter contains the right type of files\", FutureWarning, stacklevel=2)\n",
    "\n",
    "    if file_type==\"mp3\" :\n",
    "        files = find_files(directory, sample=num_songs, sub_dir=sub_dir)\n",
    "    if file_type==\"wav\" :\n",
    "        files = find_files(directory, sample=num_songs, sub_dir=sub_dir, pattern='*.wav')\n",
    " \n",
    "    randomized_files = randomize_files(files)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    audios = np.ndarray(shape=(num_songs * BATCH_NB, BATCH_SIZE, 1), dtype=np.float32, order='F')\n",
    "    tags = np.ndarray(shape=(num_songs * BATCH_NB, NB_LABELS), dtype=np.float32, order='F')\n",
    "    order = np.zeros(num_songs * BATCH_NB, dtype=int)\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    for filename in randomized_files:\n",
    "\n",
    "        # Load audio (MP3/WAV) file        \n",
    "        try :\n",
    "            audio, _ = librosa.load(filename, sr=sample_rate, mono=True)\n",
    "        except EOFError :\n",
    "            print(\"EOFERROR : The following file could not be loaded with librosa - \", filename)\n",
    "\n",
    "        audio = audio.reshape(-1, 1)\n",
    "         \n",
    "        for n in range(BATCH_NB) :\n",
    "            audios[idx] = audio[n*BATCH_SIZE: (n+1)*BATCH_SIZE,:]\n",
    "            \n",
    "            # take labels or corresponding song\n",
    "            \n",
    "            if file_type==\"mp3\" :\n",
    "                select_labels  = labels.loc[labels['mp3_path']==filename[len(directory):]]\n",
    "            \n",
    "            if file_type==\"wav\" :\n",
    "                select_labels  = labels.loc[labels['mp3_path']==filename[len(directory):-4]+\".mp3\"]\n",
    "\n",
    "            # select wanted labels\n",
    "            select_labels = select_labels[labels_name]\n",
    "\n",
    "            tags[idx] = select_labels.values.reshape(NB_LABELS)\n",
    "            \n",
    "            order[idx] = count\n",
    "            \n",
    "            idx +=1\n",
    "        \n",
    "        count +=1\n",
    "        if (count % 10) == 0:\n",
    "            print(count)\n",
    "    \n",
    "    return audios, tags, order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "10\n",
      "20\n",
      ">> Total loading time - 20 songs : 0.90 sec\n"
     ]
    }
   ],
   "source": [
    "# load audios and labels > convert to numpy\n",
    "# CAREFUL : the argument num_songs is important and shouldn't be too big \n",
    "# > otherwise MEMORY ISSUES !!!!!!\n",
    "print(\"Loading data ...\")\n",
    "start = time.time()\n",
    "audios, tags, order = load_audio_label(cleaned, sub_dir=TRAIN_DIR, \\\n",
    "                                file_type=\"mp3\", directory=DATA_DIRECTORY)\n",
    "end = time.time()\n",
    "duration = end-start\n",
    "print(\">> Total loading time - {} songs : {:.2f} sec\".format(NB_SONGS, duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of audios list :\n",
      "(180, 51776, 1)\n",
      "\n",
      ">> shape is : [num_song, num_batches, batch_size, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of audios list :\")\n",
    "print(audios.shape)\n",
    "print()\n",
    "print(\">> shape is : [num_song, num_batches, batch_size, 1]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tags list :\n",
      "(180, 2)\n",
      "\n",
      ">> shape is : [num_song, num_labels (mp3 file and id excluded), 1] \n",
      "(or : [num_song, num_labels, 1, str_len, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of tags list :\")\n",
    "print(tags.shape)\n",
    "print()\n",
    "print(\">> shape is : [num_song, num_labels (mp3 file and id excluded), 1] \")\n",
    "print(\"(or : [num_song, num_labels, 1, str_len, 1])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save neural net state tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used for now\n",
    "def save(saver, sess, logdir, step):\n",
    "    model_name = 'model.ckpt'\n",
    "    checkpoint_path = os.path.join(logdir, model_name)\n",
    "    print('Storing checkpoint to {} ...'.format(logdir), end=\"\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if not os.path.exists(logdir):\n",
    "        os.makedirs(logdir)\n",
    "\n",
    "    saver.save(sess, checkpoint_path, global_step=step)\n",
    "    print(' Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell everytime before relaunching tensorflow session\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep results for plotting\n",
    "train_loss_results = []\n",
    "train_auc_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines used to understand local vs global vs trainable\n",
    "'''print(\"GLOBAL :\", [str(i.name) for i in tf.global_variables()])\n",
    "    print(\"LOCAL :\", [str(i.name) for i in tf.local_variables()])\n",
    "    print(\"TRAINABLE :\",[str(i.name) for i in tf.trainable_variables()]) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Initializing tf model ...\")\n",
    "\n",
    "audio_tf= tf.convert_to_tensor(audios, np.float32)\n",
    "print(\"Input shape : {}\".format(audio_tf.shape))\n",
    "print(\"Labels : {}\".format(tags.flatten()))\n",
    "print()\n",
    "\n",
    "net = build_model(audio_tf, is_training=True, config=BASIC_CONFIG) \n",
    "predictions = tf.layers.dense(net, NB_LABELS, activation=tf.sigmoid)\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = tags, logits = predictions)\n",
    "reduced_loss = tf.reduce_mean(loss)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(reduced_loss)\n",
    "auc = tf.metrics.auc(labels = tags, predictions=predictions)\n",
    "\n",
    "\n",
    "# Saver for storing checkpoints of the model. (Wavenets)\n",
    "saver = tf.train.Saver(var_list=tf.global_variables())\n",
    "    \n",
    "print(\"Start training...\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in tqdm(range(EPOCHS)):\n",
    "        predict, _, loss_value, auc_score = sess.run([predictions, train_op, reduced_loss, auc])\n",
    "        \n",
    "        auc_result, update_op = auc_score\n",
    "        \n",
    "        train_loss_results.append(loss_value)\n",
    "        train_auc_results.append(auc_result)\n",
    "        \n",
    "        print(\"Iter: {:2}, Loss: {:.4f}, AUC : {:.4f}\".format(i, loss_value, auc_result))\n",
    "        #print(\"Predictions : {}\".format(predict.flatten()))\n",
    "        #print()\n",
    "     \n",
    "    # use wavenet function > see later (for now simplest way)\n",
    "    #save(saver, sess, LOGDIR, EPOCHS)\n",
    "    saver.save(sess, LOGDIR)\n",
    "\n",
    "end = time.time()\n",
    "duration2 = end-start\n",
    "print(\"Total time: {:.2f} sec.\".format(duration2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this : the epoch axis not not integers which doesn't make sense\n",
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"AUC score\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_auc_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 10\n",
    "\n",
    "audios_test, tags_test = load_audio_label(cleaned, num_songs=TEST_SIZE, sub_dir=TEST_DIR)\n",
    "\n",
    "audios_test_tf = tf.convert_to_tensor(audios_test, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_restore = {\n",
    "    var.name[:-2]: var for var in tf.global_variables()\n",
    "    if not ('state_buffer' in var.name or 'pointer' in var.name)}\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "      # Restore variables from disk.\n",
    "    saver.restore(sess, LOGDIR)\n",
    "    print(\"Model restored.\")\n",
    "    \n",
    "    init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "    sess.run(init) \n",
    "\n",
    "    predicts = sess.run([audios_test_tf, predictions, train_op, reduced_loss, auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some results \n",
    "print(\"AUC Score :\", predicts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PREDICTIONS :\", predicts[1])\n",
    "print(\"TRUE :\", tags_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following TF tutorial for custom training\n",
    "https://github.com/tensorflow/docs/blob/master/site/en/tutorials/eager/custom_training_walkthrough.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
