{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is this useful ? >> I think yes to avaoid taking all ressources available from the 4 GPUs\n",
    "from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())\n",
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "import fnmatch\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import itertools\n",
    "\n",
    "#import progressbar\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from tools import *\n",
    "from loading import * \n",
    "from labels_analysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTT_DIR = \"../MTT/\"\n",
    "DATA_DIRECTORY = MTT_DIR + \"dataset/\"\n",
    "WAV_DIRECTORY = MTT_DIR + \"wav-dataset/\"\n",
    "\n",
    "# CSV containing song details (title, artist, id, mp3_path,...)\n",
    "CLIP_INFO_FINAL = \"clip_info_final.csv\"\n",
    "# CSV containg the labels (clip_id, labels, mp3_path)\n",
    "ANNOTATIONS_FINAL = \"annotations_final.csv\"\n",
    "# CSV : what is it useful for ?\n",
    "COMPARISONS_FINAL = \"comparisons_final.csv\"\n",
    "LABELS_FILE = MTT_DIR + ANNOTATIONS_FINAL\n",
    "\n",
    "LOGDIR = \"checkpoints/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LTS2 Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines all the needed data paths, when running on LTS2 server.\n",
    "Don't run this cell if you are not running the jupyter notebook on the LTS2 server ! (will overwrite the variables defined on the cell above).\n",
    "\n",
    "You can either create a cell with your own paths, or modify the cell above with your custom paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTT_DIR = \"/mnt/scratch/students/jjgweber-MagnaTagATune/\"\n",
    "DATA_DIRECTORY = MTT_DIR + \"dataset/\"\n",
    "WAV_DIRECTORY = MTT_DIR + \"wav-dataset/\"\n",
    "\n",
    "# CSV containg the labels (clip_id, labels, mp3_path)\n",
    "ANNOTATIONS_FINAL = \"annotations_final.csv\"\n",
    "\n",
    "LABELS_FILE = MTT_DIR + ANNOTATIONS_FINAL\n",
    "\n",
    "# need to create this directory on the server !!\n",
    "LOGDIR = \"checkpoints/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NB = 25880 #25863\n",
    "FILE_LENGTH = 465984\n",
    "# 465984 = 2 × 2 × 2 × 2 × 2 × 2 × 3 × 3 × 809\n",
    "# useful for batches > for now divide by 9 (instead of 10)\n",
    "\n",
    "BATCH_NB = 9\n",
    "BATCH_SIZE = int(FILE_LENGTH/BATCH_NB)\n",
    "SAMPLE_SIZE = 0\n",
    "SAMPLE_RATE = 16000\n",
    "RECEPTIVE_FIELD = 0\n",
    "\n",
    "TRAIN_DIR = \"0123456789abcde\"\n",
    "TEST_DIR =\"f\"\n",
    "\n",
    "BASIC_CONFIG ={'numOutputNeurons':500}\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables which are often modified to test the algorithm\n",
    "NB_SONGS = 20\n",
    "GROUP_SIZE = 20\n",
    "EPOCHS = 16 # check in paper\n",
    "LABELS_NAME = ['guitar', 'techno']\n",
    "NB_LABELS = len(LABELS_NAME)\n",
    "threshold_tag = 0.7\n",
    "majority = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjgweber/pds/loading.py:197: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  labels = pd.read_csv(labels_path, sep = '\"\\t\"')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading csv file : 3.77\n"
     ]
    }
   ],
   "source": [
    "labels, header = load_and_clean_labels(LABELS_FILE)\n",
    "#labels.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs :  25863\n",
      "Number of labels :  188\n",
      "Max number of songs tagged with the same label :  4852\n",
      "Max number of labels for a single song :  27\n"
     ]
    }
   ],
   "source": [
    "nb_labels_per_song, nb_song_per_label, label_header_by_freq = label_stats(labels, header, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_10_labels = label_header_by_freq[:10]\n",
    "best_30_labels = label_header_by_freq[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-occurence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_labels = best_10_labels\n",
    "#check_overlaps(chosen_labels, labels.loc[:,chosen_labels].values.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and format mp3 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training variables \n",
    "TRAIN_DIR = \"0123456789abc\"\n",
    "TEST_DIR = \"def\"\n",
    "EPOCHS = 100\n",
    "BATCH_NB = 9\n",
    "BATCH_SIZE = int(FILE_LENGTH/BATCH_NB)\n",
    "#LOGDIR =\n",
    "LABELS_NAME = ['guitar', 'techno']\n",
    "NB_LABELS = len(LABELS_NAME)\n",
    "LEARNING_RATE = 0.001\n",
    "GROUP_SIZE = 10\n",
    "SAMPLE_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir, pattern, file_type = return_params_mp3_wav(\"mp3\", DATA_DIRECTORY, WAV_DIRECTORY)\n",
    "# also need labels but computed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_tf_model(input_shape, nb_labels, nb_batch, batch_size, learning_rate, is_training=True) :\n",
    "    print(\"Initialize tf model ...\")\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=(input_shape*nb_batch, batch_size, 1))\n",
    "    y = tf.placeholder(tf.float32, shape=(input_shape*nb_batch, nb_labels))\n",
    "\n",
    "    net = build_model(x, is_training=is_training, config=BASIC_CONFIG) \n",
    "    predictions = tf.layers.dense(net, nb_labels, activation=tf.sigmoid)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = y, logits = predictions)\n",
    "    reduced_loss = tf.reduce_mean(loss)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(reduced_loss)\n",
    "    auc = tf.metrics.auc(labels = y, predictions=predictions)\n",
    "    \n",
    "    # Saver for storing checkpoints of the model. (Wavenets)\n",
    "    saver = tf.train.Saver(var_list=tf.global_variables())\n",
    "    \n",
    "    return x, y, net, predictions, loss, reduced_loss,  train_op, auc, saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_dir, group_size, sample_size, file_type, train_dir, epochs, \\\n",
    "          labels, labels_name, nb_labels, batch_size, nb_batch, logdir, learning_rate) :\n",
    "    \n",
    "    pattern = \"\"\n",
    "    if file_type == \"mp3\" :\n",
    "        pattern = \"*.mp3\"\n",
    "    if file_type == \"wav\" :\n",
    "        pattern = \"*.wav\"\n",
    "    else :\n",
    "        print(\"Argument should be either \\\"mp3\\\" or \\\"wav\\\".\")\n",
    "        \n",
    "    # keep results for plotting\n",
    "    train_loss_results = []\n",
    "    train_auc_results = []\n",
    "\n",
    "\n",
    "    files_by_group = find_files_group_select(data_dir, labels, labels_name, group_size, sample=sample_size, \\\n",
    "                                             pattern=pattern, sub_dir=train_dir)\n",
    "    \n",
    "    n_groups = len(files_by_group)\n",
    "    #print(data_dir, labels, labels_name, group_size)\n",
    "\n",
    "    x, y, net, predictions, loss, reduced_loss, \\\n",
    "    train_op, auc, saver = initialize_tf_model(len(files_by_group[0]), nb_labels, nb_batch,\\\n",
    "                                               batch_size, learning_rate)\n",
    "    print(\"Start training...\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "        sess.run(init)\n",
    "\n",
    "        # Go through the whole DS at each EPOCH\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "\n",
    "            t0_epoch = time.time()\n",
    "\n",
    "            # Group by group\n",
    "            for count, g in enumerate(files_by_group) :\n",
    "\n",
    "                # Load audio and labels\n",
    "                tload0 = time.time()\n",
    "                audios, tags = load_audio_label_aux(labels, g, len(data_dir), labels_name=labels_name, \\\n",
    "                        nb_labels=nb_labels, file_type=file_type, batch_size=batch_size, nb_batch=nb_batch)\n",
    "                \n",
    "                tload1 = time.time()\n",
    "\n",
    "                if count==0 :\n",
    "                    print(\">> Total loading time : {:.2f} sec\".format(tload1-tload0))\n",
    "                #audio_tf = tf.convert_to_tensor(audios, np.float32)\n",
    "\n",
    "                # add check to verify if there is something to restore\n",
    "                #saver.restore(sess, LOGDIR)\n",
    "\n",
    "                predict, _, loss_value, auc_score = sess.run([predictions, train_op, reduced_loss, auc],\\\n",
    "                                                             feed_dict={x: audios, y: tags})\n",
    "                auc_result, update_op = auc_score\n",
    "\n",
    "                saver.save(sess, logdir)\n",
    "\n",
    "\n",
    "                train_loss_results.append(loss_value)\n",
    "                train_auc_results.append(auc_result)\n",
    "\n",
    "                print(\"Group {} done. {} left.\".format(count, n_groups-count))\n",
    "\n",
    "\n",
    "            t1_epoch = time.time()\n",
    "\n",
    "            dur = t1_epoch-t0_epoch\n",
    "\n",
    "            print(\"Iter: {:3}, Time (in sec): {:.2f}, Loss: {:.4f}, AUC : {:.4f}\"\\\n",
    "                  .format(epoch, dur, loss_value, auc_result))\n",
    "            print()\n",
    "\n",
    "    end = time.time()\n",
    "    duration2 = end-start\n",
    "    print(\"Total time: {:.2f} sec.\".format(duration2))\n",
    "    return train_loss_results, train_auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all(group_size) :\n",
    "    train_loss_results, train_auc_results = train(data_dir, group_size, None, file_type,\\\n",
    "                                                  TRAIN_DIR, EPOCHS, labels, LABELS_NAME, NB_LABELS, \\\n",
    "                                                  BATCH_SIZE, BATCH_NB, LOGDIR, LEARNING_RATE)\n",
    "    return train_loss_results, train_auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_shape(group_size, sample_size) :\n",
    "    train_loss_results, train_auc_results = train(data_dir, group_size, sample_size, file_type,\\\n",
    "                                                  TRAIN_DIR, EPOCHS, labels, LABELS_NAME, NB_LABELS, \\\n",
    "                                                  BATCH_SIZE, BATCH_NB, LOGDIR, LEARNING_RATE)\n",
    "    return train_loss_results, train_auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_labels_choice(labels_name, nb_labels) :\n",
    "    train_loss_results, train_auc_results = train(data_dir, GROUP_SIZE, SAMPLE_SIZE, file_type, \\\n",
    "                                                  TRAIN_DIR, EPOCHS, labels, labels_name, nb_labels, \\\n",
    "                                                  BATCH_SIZE, BATCH_NB, LOGDIR, LEARNING_RATE)\n",
    "    return train_loss_results, train_auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_learning_rate(l_rate) :\n",
    "    train_loss_results, train_auc_results = train(data_dir, group_size, sample_size, file_type, \\\n",
    "                                                  TRAIN_DIR, EPOCHS, labels, labels_name, nb_labels, \\\n",
    "                                                  BATCH_SIZE, BATCH_NB, LOGDIR, l_rate)\n",
    "    return train_loss_results, train_auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argument should be either \"mp3\" or \"wav\".\n",
      "All labels : 25863 songs >>> Selected for given labels : 7727.\n",
      "Initialize tf model ...\n",
      "Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2959fd6080d499dbf5c0364b4dc384f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 songs ...\n",
      ">> Total loading time : 14.24 sec\n",
      "Group 0 done. 314 left.\n",
      "Loading 20 songs ...\n",
      "Group 1 done. 313 left.\n",
      "Loading 20 songs ...\n",
      "Group 2 done. 312 left.\n",
      "Loading 20 songs ...\n",
      "Group 3 done. 311 left.\n",
      "Loading 20 songs ...\n",
      "Group 4 done. 310 left.\n",
      "Loading 20 songs ...\n",
      "Group 5 done. 309 left.\n",
      "Loading 20 songs ...\n",
      "Group 6 done. 308 left.\n",
      "Loading 20 songs ...\n",
      "Group 7 done. 307 left.\n",
      "Loading 20 songs ...\n",
      "Group 8 done. 306 left.\n",
      "Loading 20 songs ...\n",
      "Group 9 done. 305 left.\n",
      "Loading 20 songs ...\n",
      "Group 10 done. 304 left.\n",
      "Loading 20 songs ...\n",
      "Group 11 done. 303 left.\n",
      "Loading 20 songs ...\n",
      "Group 12 done. 302 left.\n",
      "Loading 20 songs ...\n",
      "Group 13 done. 301 left.\n",
      "Loading 20 songs ...\n",
      "Group 14 done. 300 left.\n",
      "Loading 20 songs ...\n",
      "Group 15 done. 299 left.\n",
      "Loading 20 songs ...\n",
      "Group 16 done. 298 left.\n",
      "Loading 20 songs ...\n",
      "Group 17 done. 297 left.\n",
      "Loading 20 songs ...\n",
      "Group 18 done. 296 left.\n",
      "Loading 20 songs ...\n",
      "Group 19 done. 295 left.\n",
      "Loading 20 songs ...\n",
      "Group 20 done. 294 left.\n",
      "Loading 20 songs ...\n",
      "Group 21 done. 293 left.\n",
      "Loading 20 songs ...\n",
      "Group 22 done. 292 left.\n",
      "Loading 20 songs ...\n",
      "Group 23 done. 291 left.\n",
      "Loading 20 songs ...\n",
      "Group 24 done. 290 left.\n",
      "Loading 20 songs ...\n",
      "Group 25 done. 289 left.\n",
      "Loading 20 songs ...\n",
      "Group 26 done. 288 left.\n",
      "Loading 20 songs ...\n",
      "Group 27 done. 287 left.\n",
      "Loading 20 songs ...\n",
      "Group 28 done. 286 left.\n",
      "Loading 20 songs ...\n",
      "Group 29 done. 285 left.\n",
      "Loading 20 songs ...\n",
      "Group 30 done. 284 left.\n",
      "Loading 20 songs ...\n",
      "Group 31 done. 283 left.\n",
      "Loading 20 songs ...\n",
      "Group 32 done. 282 left.\n",
      "Loading 20 songs ...\n",
      "Group 33 done. 281 left.\n",
      "Loading 20 songs ...\n",
      "Group 34 done. 280 left.\n",
      "Loading 20 songs ...\n",
      "Group 35 done. 279 left.\n",
      "Loading 20 songs ...\n",
      "Group 36 done. 278 left.\n",
      "Loading 20 songs ...\n",
      "Group 37 done. 277 left.\n",
      "Loading 20 songs ...\n",
      "Group 38 done. 276 left.\n",
      "Loading 20 songs ...\n",
      "Group 39 done. 275 left.\n",
      "Loading 20 songs ...\n",
      "Group 40 done. 274 left.\n",
      "Loading 20 songs ...\n",
      "Group 41 done. 273 left.\n",
      "Loading 20 songs ...\n",
      "Group 42 done. 272 left.\n",
      "Loading 20 songs ...\n",
      "Group 43 done. 271 left.\n",
      "Loading 20 songs ...\n",
      "Group 44 done. 270 left.\n",
      "Loading 20 songs ...\n",
      "Group 45 done. 269 left.\n",
      "Loading 20 songs ...\n",
      "Group 46 done. 268 left.\n",
      "Loading 20 songs ...\n",
      "Group 47 done. 267 left.\n",
      "Loading 20 songs ...\n",
      "Group 48 done. 266 left.\n",
      "Loading 20 songs ...\n",
      "Group 49 done. 265 left.\n",
      "Loading 20 songs ...\n",
      "Group 50 done. 264 left.\n",
      "Loading 20 songs ...\n",
      "Group 51 done. 263 left.\n",
      "Loading 20 songs ...\n",
      "Group 52 done. 262 left.\n",
      "Loading 20 songs ...\n",
      "Group 53 done. 261 left.\n",
      "Loading 20 songs ...\n",
      "Group 54 done. 260 left.\n",
      "Loading 20 songs ...\n",
      "Group 55 done. 259 left.\n",
      "Loading 20 songs ...\n",
      "Group 56 done. 258 left.\n",
      "Loading 20 songs ...\n",
      "Group 57 done. 257 left.\n",
      "Loading 20 songs ...\n",
      "Group 58 done. 256 left.\n",
      "Loading 20 songs ...\n",
      "Group 59 done. 255 left.\n",
      "Loading 20 songs ...\n",
      "Group 60 done. 254 left.\n",
      "Loading 20 songs ...\n",
      "Group 61 done. 253 left.\n",
      "Loading 20 songs ...\n",
      "Group 62 done. 252 left.\n",
      "Loading 20 songs ...\n",
      "Group 63 done. 251 left.\n",
      "Loading 20 songs ...\n",
      "Group 64 done. 250 left.\n",
      "Loading 20 songs ...\n",
      "Group 65 done. 249 left.\n",
      "Loading 20 songs ...\n",
      "Group 66 done. 248 left.\n",
      "Loading 20 songs ...\n",
      "Group 67 done. 247 left.\n",
      "Loading 20 songs ...\n",
      "Group 68 done. 246 left.\n",
      "Loading 20 songs ...\n",
      "Group 69 done. 245 left.\n",
      "Loading 20 songs ...\n",
      "Group 70 done. 244 left.\n",
      "Loading 20 songs ...\n",
      "Group 71 done. 243 left.\n",
      "Loading 20 songs ...\n",
      "Group 72 done. 242 left.\n",
      "Loading 20 songs ...\n",
      "Group 73 done. 241 left.\n",
      "Loading 20 songs ...\n",
      "Group 74 done. 240 left.\n",
      "Loading 20 songs ...\n",
      "Group 75 done. 239 left.\n",
      "Loading 20 songs ...\n",
      "Group 76 done. 238 left.\n",
      "Loading 20 songs ...\n",
      "Group 77 done. 237 left.\n",
      "Loading 20 songs ...\n",
      "Group 78 done. 236 left.\n",
      "Loading 20 songs ...\n",
      "Group 79 done. 235 left.\n",
      "Loading 20 songs ...\n",
      "Group 80 done. 234 left.\n",
      "Loading 20 songs ...\n",
      "Group 81 done. 233 left.\n",
      "Loading 20 songs ...\n",
      "Group 82 done. 232 left.\n",
      "Loading 20 songs ...\n",
      "Group 83 done. 231 left.\n",
      "Loading 20 songs ...\n",
      "Group 84 done. 230 left.\n",
      "Loading 20 songs ...\n",
      "Group 85 done. 229 left.\n",
      "Loading 20 songs ...\n",
      "Group 86 done. 228 left.\n",
      "Loading 20 songs ...\n",
      "Group 87 done. 227 left.\n",
      "Loading 20 songs ...\n",
      "Group 88 done. 226 left.\n",
      "Loading 20 songs ...\n",
      "Group 89 done. 225 left.\n",
      "Loading 20 songs ...\n",
      "Group 90 done. 224 left.\n",
      "Loading 20 songs ...\n",
      "Group 91 done. 223 left.\n",
      "Loading 20 songs ...\n",
      "Group 92 done. 222 left.\n",
      "Loading 20 songs ...\n",
      "Group 93 done. 221 left.\n",
      "Loading 20 songs ...\n",
      "Group 94 done. 220 left.\n",
      "Loading 20 songs ...\n",
      "Group 95 done. 219 left.\n",
      "Loading 20 songs ...\n",
      "Group 96 done. 218 left.\n",
      "Loading 20 songs ...\n",
      "Group 97 done. 217 left.\n",
      "Loading 20 songs ...\n",
      "Group 98 done. 216 left.\n",
      "Loading 20 songs ...\n",
      "Group 99 done. 215 left.\n",
      "Loading 20 songs ...\n",
      "Group 100 done. 214 left.\n",
      "Loading 20 songs ...\n",
      "Group 101 done. 213 left.\n",
      "Loading 20 songs ...\n",
      "Group 102 done. 212 left.\n",
      "Loading 20 songs ...\n",
      "Group 103 done. 211 left.\n",
      "Loading 20 songs ...\n",
      "Group 104 done. 210 left.\n",
      "Loading 20 songs ...\n",
      "Group 105 done. 209 left.\n",
      "Loading 20 songs ...\n",
      "Group 106 done. 208 left.\n",
      "Loading 20 songs ...\n",
      "Group 107 done. 207 left.\n",
      "Loading 20 songs ...\n",
      "Group 108 done. 206 left.\n",
      "Loading 20 songs ...\n",
      "Group 109 done. 205 left.\n",
      "Loading 20 songs ...\n",
      "Group 110 done. 204 left.\n",
      "Loading 20 songs ...\n",
      "Group 111 done. 203 left.\n",
      "Loading 20 songs ...\n",
      "Group 112 done. 202 left.\n",
      "Loading 20 songs ...\n",
      "Group 113 done. 201 left.\n",
      "Loading 20 songs ...\n",
      "Group 114 done. 200 left.\n",
      "Loading 20 songs ...\n",
      "Group 115 done. 199 left.\n",
      "Loading 20 songs ...\n",
      "Group 116 done. 198 left.\n",
      "Loading 20 songs ...\n",
      "Group 117 done. 197 left.\n",
      "Loading 20 songs ...\n",
      "Group 118 done. 196 left.\n",
      "Loading 20 songs ...\n",
      "Group 119 done. 195 left.\n",
      "Loading 20 songs ...\n",
      "Group 120 done. 194 left.\n",
      "Loading 20 songs ...\n",
      "Group 121 done. 193 left.\n",
      "Loading 20 songs ...\n",
      "Group 122 done. 192 left.\n",
      "Loading 20 songs ...\n",
      "Group 123 done. 191 left.\n",
      "Loading 20 songs ...\n",
      "Group 124 done. 190 left.\n",
      "Loading 20 songs ...\n",
      "Group 125 done. 189 left.\n",
      "Loading 20 songs ...\n",
      "Group 126 done. 188 left.\n",
      "Loading 20 songs ...\n",
      "Group 127 done. 187 left.\n",
      "Loading 20 songs ...\n",
      "Group 128 done. 186 left.\n",
      "Loading 20 songs ...\n",
      "Group 129 done. 185 left.\n",
      "Loading 20 songs ...\n",
      "Group 130 done. 184 left.\n",
      "Loading 20 songs ...\n",
      "Group 131 done. 183 left.\n",
      "Loading 20 songs ...\n",
      "Group 132 done. 182 left.\n",
      "Loading 20 songs ...\n",
      "Group 133 done. 181 left.\n",
      "Loading 20 songs ...\n",
      "Group 134 done. 180 left.\n",
      "Loading 20 songs ...\n",
      "Group 135 done. 179 left.\n",
      "Loading 20 songs ...\n",
      "Group 136 done. 178 left.\n",
      "Loading 20 songs ...\n",
      "Group 137 done. 177 left.\n",
      "Loading 20 songs ...\n",
      "Group 138 done. 176 left.\n",
      "Loading 20 songs ...\n",
      "Group 139 done. 175 left.\n",
      "Loading 20 songs ...\n",
      "Group 140 done. 174 left.\n",
      "Loading 20 songs ...\n",
      "Group 141 done. 173 left.\n",
      "Loading 20 songs ...\n",
      "Group 142 done. 172 left.\n",
      "Loading 20 songs ...\n",
      "EOFERROR : The following file could not be loaded with librosa -  /mnt/scratch/students/jjgweber-MagnaTagATune/dataset/6/norine_braun-now_and_zen-08-gently-117-146.mp3\n",
      "Group 143 done. 171 left.\n",
      "Loading 20 songs ...\n",
      "Group 144 done. 170 left.\n",
      "Loading 20 songs ...\n",
      "Group 145 done. 169 left.\n",
      "Loading 20 songs ...\n",
      "Group 146 done. 168 left.\n",
      "Loading 20 songs ...\n",
      "Group 147 done. 167 left.\n",
      "Loading 20 songs ...\n",
      "Group 148 done. 166 left.\n",
      "Loading 20 songs ...\n",
      "Group 149 done. 165 left.\n",
      "Loading 20 songs ...\n",
      "Group 150 done. 164 left.\n",
      "Loading 20 songs ...\n",
      "Group 151 done. 163 left.\n",
      "Loading 20 songs ...\n",
      "Group 152 done. 162 left.\n",
      "Loading 20 songs ...\n",
      "Group 153 done. 161 left.\n",
      "Loading 20 songs ...\n",
      "Group 154 done. 160 left.\n",
      "Loading 20 songs ...\n",
      "Group 155 done. 159 left.\n",
      "Loading 20 songs ...\n",
      "Group 156 done. 158 left.\n",
      "Loading 20 songs ...\n",
      "Group 157 done. 157 left.\n",
      "Loading 20 songs ...\n",
      "Group 158 done. 156 left.\n",
      "Loading 20 songs ...\n",
      "Group 159 done. 155 left.\n",
      "Loading 20 songs ...\n",
      "Group 160 done. 154 left.\n",
      "Loading 20 songs ...\n",
      "Group 161 done. 153 left.\n",
      "Loading 20 songs ...\n",
      "Group 162 done. 152 left.\n",
      "Loading 20 songs ...\n",
      "Group 163 done. 151 left.\n",
      "Loading 20 songs ...\n",
      "Group 164 done. 150 left.\n",
      "Loading 20 songs ...\n",
      "Group 165 done. 149 left.\n",
      "Loading 20 songs ...\n",
      "Group 166 done. 148 left.\n",
      "Loading 20 songs ...\n",
      "Group 167 done. 147 left.\n",
      "Loading 20 songs ...\n",
      "Group 168 done. 146 left.\n",
      "Loading 20 songs ...\n",
      "Group 169 done. 145 left.\n",
      "Loading 20 songs ...\n",
      "Group 170 done. 144 left.\n",
      "Loading 20 songs ...\n",
      "Group 171 done. 143 left.\n",
      "Loading 20 songs ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 172 done. 142 left.\n",
      "Loading 20 songs ...\n",
      "Group 173 done. 141 left.\n",
      "Loading 20 songs ...\n",
      "Group 174 done. 140 left.\n",
      "Loading 20 songs ...\n",
      "Group 175 done. 139 left.\n",
      "Loading 20 songs ...\n",
      "Group 176 done. 138 left.\n",
      "Loading 20 songs ...\n",
      "Group 177 done. 137 left.\n",
      "Loading 20 songs ...\n",
      "Group 178 done. 136 left.\n",
      "Loading 20 songs ...\n",
      "Group 179 done. 135 left.\n",
      "Loading 20 songs ...\n",
      "Group 180 done. 134 left.\n",
      "Loading 20 songs ...\n",
      "Group 181 done. 133 left.\n",
      "Loading 20 songs ...\n",
      "Group 182 done. 132 left.\n",
      "Loading 20 songs ...\n",
      "Group 183 done. 131 left.\n",
      "Loading 20 songs ...\n",
      "Group 184 done. 130 left.\n",
      "Loading 20 songs ...\n",
      "Group 185 done. 129 left.\n",
      "Loading 20 songs ...\n",
      "Group 186 done. 128 left.\n",
      "Loading 20 songs ...\n",
      "Group 187 done. 127 left.\n",
      "Loading 20 songs ...\n",
      "Group 188 done. 126 left.\n",
      "Loading 20 songs ...\n",
      "Group 189 done. 125 left.\n",
      "Loading 20 songs ...\n",
      "Group 190 done. 124 left.\n",
      "Loading 20 songs ...\n",
      "Group 191 done. 123 left.\n",
      "Loading 20 songs ...\n",
      "Group 192 done. 122 left.\n",
      "Loading 20 songs ...\n",
      "Group 193 done. 121 left.\n",
      "Loading 20 songs ...\n",
      "Group 194 done. 120 left.\n",
      "Loading 20 songs ...\n",
      "Group 195 done. 119 left.\n",
      "Loading 20 songs ...\n",
      "Group 196 done. 118 left.\n",
      "Loading 20 songs ...\n",
      "Group 197 done. 117 left.\n",
      "Loading 20 songs ...\n",
      "Group 198 done. 116 left.\n",
      "Loading 20 songs ...\n",
      "Group 199 done. 115 left.\n",
      "Loading 20 songs ...\n",
      "Group 200 done. 114 left.\n",
      "Loading 20 songs ...\n",
      "Group 201 done. 113 left.\n",
      "Loading 20 songs ...\n",
      "Group 202 done. 112 left.\n",
      "Loading 20 songs ...\n",
      "Group 203 done. 111 left.\n",
      "Loading 20 songs ...\n",
      "Group 204 done. 110 left.\n",
      "Loading 20 songs ...\n",
      "Group 205 done. 109 left.\n",
      "Loading 20 songs ...\n",
      "Group 206 done. 108 left.\n",
      "Loading 20 songs ...\n",
      "Group 207 done. 107 left.\n",
      "Loading 20 songs ...\n",
      "Group 208 done. 106 left.\n",
      "Loading 20 songs ...\n",
      "Group 209 done. 105 left.\n",
      "Loading 20 songs ...\n",
      "Group 210 done. 104 left.\n",
      "Loading 20 songs ...\n",
      "Group 211 done. 103 left.\n",
      "Loading 20 songs ...\n",
      "Group 212 done. 102 left.\n",
      "Loading 20 songs ...\n",
      "Group 213 done. 101 left.\n",
      "Loading 20 songs ...\n",
      "Group 214 done. 100 left.\n",
      "Loading 20 songs ...\n",
      "Group 215 done. 99 left.\n",
      "Loading 20 songs ...\n",
      "Group 216 done. 98 left.\n",
      "Loading 20 songs ...\n",
      "Group 217 done. 97 left.\n",
      "Loading 20 songs ...\n",
      "Group 218 done. 96 left.\n",
      "Loading 20 songs ...\n",
      "Group 219 done. 95 left.\n",
      "Loading 20 songs ...\n",
      "Group 220 done. 94 left.\n",
      "Loading 20 songs ...\n",
      "Group 221 done. 93 left.\n",
      "Loading 20 songs ...\n",
      "Group 222 done. 92 left.\n",
      "Loading 20 songs ...\n",
      "Group 223 done. 91 left.\n",
      "Loading 20 songs ...\n",
      "Group 224 done. 90 left.\n",
      "Loading 20 songs ...\n",
      "Group 225 done. 89 left.\n",
      "Loading 20 songs ...\n",
      "Group 226 done. 88 left.\n",
      "Loading 20 songs ...\n",
      "Group 227 done. 87 left.\n",
      "Loading 20 songs ...\n",
      "Group 228 done. 86 left.\n",
      "Loading 20 songs ...\n",
      "Group 229 done. 85 left.\n",
      "Loading 20 songs ...\n",
      "Group 230 done. 84 left.\n",
      "Loading 20 songs ...\n",
      "Group 231 done. 83 left.\n",
      "Loading 20 songs ...\n",
      "Group 232 done. 82 left.\n",
      "Loading 20 songs ...\n",
      "Group 233 done. 81 left.\n",
      "Loading 20 songs ...\n",
      "Group 234 done. 80 left.\n",
      "Loading 20 songs ...\n",
      "Group 235 done. 79 left.\n",
      "Loading 20 songs ...\n",
      "Group 236 done. 78 left.\n",
      "Loading 20 songs ...\n",
      "Group 237 done. 77 left.\n",
      "Loading 20 songs ...\n",
      "Group 238 done. 76 left.\n",
      "Loading 20 songs ...\n",
      "Group 239 done. 75 left.\n",
      "Loading 20 songs ...\n",
      "Group 240 done. 74 left.\n",
      "Loading 20 songs ...\n",
      "Group 241 done. 73 left.\n",
      "Loading 20 songs ...\n",
      "Group 242 done. 72 left.\n",
      "Loading 20 songs ...\n",
      "Group 243 done. 71 left.\n",
      "Loading 20 songs ...\n",
      "Group 244 done. 70 left.\n",
      "Loading 20 songs ...\n",
      "Group 245 done. 69 left.\n",
      "Loading 20 songs ...\n",
      "Group 246 done. 68 left.\n",
      "Loading 20 songs ...\n",
      "Group 247 done. 67 left.\n",
      "Loading 20 songs ...\n",
      "Group 248 done. 66 left.\n",
      "Loading 20 songs ...\n",
      "Group 249 done. 65 left.\n",
      "Loading 20 songs ...\n",
      "Group 250 done. 64 left.\n",
      "Loading 20 songs ...\n",
      "Group 251 done. 63 left.\n",
      "Loading 20 songs ...\n",
      "Group 252 done. 62 left.\n",
      "Loading 20 songs ...\n",
      "Group 253 done. 61 left.\n",
      "Loading 20 songs ...\n",
      "Group 254 done. 60 left.\n",
      "Loading 20 songs ...\n",
      "Group 255 done. 59 left.\n",
      "Loading 20 songs ...\n",
      "Group 256 done. 58 left.\n",
      "Loading 20 songs ...\n",
      "Group 257 done. 57 left.\n",
      "Loading 20 songs ...\n",
      "Group 258 done. 56 left.\n",
      "Loading 20 songs ...\n",
      "Group 259 done. 55 left.\n",
      "Loading 20 songs ...\n",
      "Group 260 done. 54 left.\n",
      "Loading 20 songs ...\n",
      "Group 261 done. 53 left.\n",
      "Loading 20 songs ...\n",
      "Group 262 done. 52 left.\n",
      "Loading 20 songs ...\n",
      "Group 263 done. 51 left.\n",
      "Loading 20 songs ...\n",
      "Group 264 done. 50 left.\n",
      "Loading 20 songs ...\n",
      "Group 265 done. 49 left.\n",
      "Loading 20 songs ...\n",
      "Group 266 done. 48 left.\n",
      "Loading 20 songs ...\n",
      "Group 267 done. 47 left.\n",
      "Loading 20 songs ...\n",
      "Group 268 done. 46 left.\n",
      "Loading 20 songs ...\n",
      "Group 269 done. 45 left.\n",
      "Loading 20 songs ...\n",
      "Group 270 done. 44 left.\n",
      "Loading 20 songs ...\n",
      "Group 271 done. 43 left.\n",
      "Loading 20 songs ...\n",
      "Group 272 done. 42 left.\n",
      "Loading 20 songs ...\n",
      "Group 273 done. 41 left.\n",
      "Loading 20 songs ...\n",
      "Group 274 done. 40 left.\n",
      "Loading 20 songs ...\n",
      "Group 275 done. 39 left.\n",
      "Loading 20 songs ...\n",
      "Group 276 done. 38 left.\n",
      "Loading 20 songs ...\n",
      "Group 277 done. 37 left.\n",
      "Loading 20 songs ...\n",
      "Group 278 done. 36 left.\n",
      "Loading 20 songs ...\n",
      "Group 279 done. 35 left.\n",
      "Loading 20 songs ...\n",
      "Group 280 done. 34 left.\n",
      "Loading 20 songs ...\n",
      "Group 281 done. 33 left.\n",
      "Loading 20 songs ...\n",
      "Group 282 done. 32 left.\n",
      "Loading 20 songs ...\n",
      "Group 283 done. 31 left.\n",
      "Loading 20 songs ...\n",
      "Group 284 done. 30 left.\n",
      "Loading 20 songs ...\n",
      "Group 285 done. 29 left.\n",
      "Loading 20 songs ...\n",
      "Group 286 done. 28 left.\n",
      "Loading 20 songs ...\n",
      "Group 287 done. 27 left.\n",
      "Loading 20 songs ...\n",
      "Group 288 done. 26 left.\n",
      "Loading 20 songs ...\n",
      "Group 289 done. 25 left.\n",
      "Loading 20 songs ...\n",
      "Group 290 done. 24 left.\n",
      "Loading 20 songs ...\n",
      "Group 291 done. 23 left.\n",
      "Loading 20 songs ...\n",
      "Group 292 done. 22 left.\n",
      "Loading 20 songs ...\n",
      "Group 293 done. 21 left.\n",
      "Loading 20 songs ...\n",
      "Group 294 done. 20 left.\n",
      "Loading 20 songs ...\n",
      "Group 295 done. 19 left.\n",
      "Loading 20 songs ...\n",
      "Group 296 done. 18 left.\n",
      "Loading 20 songs ...\n",
      "Group 297 done. 17 left.\n",
      "Loading 20 songs ...\n",
      "Group 298 done. 16 left.\n",
      "Loading 20 songs ...\n",
      "Group 299 done. 15 left.\n",
      "Loading 20 songs ...\n",
      "Group 300 done. 14 left.\n",
      "Loading 20 songs ...\n",
      "Group 301 done. 13 left.\n",
      "Loading 20 songs ...\n",
      "Group 302 done. 12 left.\n",
      "Loading 20 songs ...\n",
      "Group 303 done. 11 left.\n",
      "Loading 20 songs ...\n",
      "Group 304 done. 10 left.\n",
      "Loading 20 songs ...\n",
      "Group 305 done. 9 left.\n",
      "Loading 20 songs ...\n",
      "Group 306 done. 8 left.\n",
      "Loading 20 songs ...\n",
      "Group 307 done. 7 left.\n",
      "Loading 20 songs ...\n",
      "Group 308 done. 6 left.\n",
      "Loading 20 songs ...\n",
      "Group 309 done. 5 left.\n",
      "Loading 20 songs ...\n",
      "Group 310 done. 4 left.\n",
      "Loading 20 songs ...\n",
      "Group 311 done. 3 left.\n",
      "Loading 20 songs ...\n",
      "Group 312 done. 2 left.\n",
      "Loading 11 songs ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (99, 51776, 1) for Tensor 'Placeholder:0', which has shape '(180, 51776, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f93163fd1949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loss_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auc_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-55c66ea395c3>\u001b[0m in \u001b[0;36mtrain_all\u001b[0;34m(group_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m     train_loss_results, train_auc_results = train(data_dir, group_size, None, file_type,\\\n\u001b[1;32m      3\u001b[0m                                                   \u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLABELS_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNB_LABELS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                                   BATCH_SIZE, BATCH_NB, LOGDIR, LEARNING_RATE)\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loss_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auc_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-5c13f5ea12af>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_dir, group_size, sample_size, file_type, train_dir, epochs, labels, labels_name, nb_labels, batch_size, nb_batch, logdir, learning_rate)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 predict, _, loss_value, auc_score = sess.run([predictions, train_op, reduced_loss, auc],\\\n\u001b[0;32m---> 59\u001b[0;31m                                                              feed_dict={x: audios, y: tags})\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mauc_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/semester_project/myenv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/semester_project/myenv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1128\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1129\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (99, 51776, 1) for Tensor 'Placeholder:0', which has shape '(180, 51776, 1)'"
     ]
    }
   ],
   "source": [
    "train_loss_results, train_auc_results = train_all(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_auc_loss(train_loss_results, train_auc_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 10\n",
    "\n",
    "test_files = find_files_group(data_dir, test_size, sample=test_size, pattern=pattern, sub_dir=TEST_DIR)\n",
    "\n",
    "audios_test, tags_test = load_audio_label_aux(labels, test_files[0], len(data_dir), labels_name=LABELS_NAME, \\\n",
    "                        nb_labels=NB_LABELS, file_type=file_type, batch_size=BATCH_SIZE, nb_batch=BATCH_NB)\n",
    "#audios_test_tf = tf.convert_to_tensor(audios_test, np.float32)\n",
    "\n",
    "# for testing I guess no need to give several groups to the network ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, net, predictions, loss, reduced_loss,  train_op, auc, saver = initialize_tf_model(len(test_files[0]), \\\n",
    "                                                                                        is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_restore = {\n",
    "    var.name[:-2]: var for var in tf.global_variables()\n",
    "    if not ('state_buffer' in var.name or 'pointer' in var.name)}\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "      # Restore variables from disk.\n",
    "    saver.restore(sess, LOGDIR)\n",
    "    print(\"Model restored.\")\n",
    "    \n",
    "    init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "    sess.run(init) \n",
    "\n",
    "    predicts = sess.run([predictions, train_op, reduced_loss, auc], \\\n",
    "                        feed_dict={x: audios_test, y: tags_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some results \n",
    "print(\"AUC Score :\", predicts[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PREDICTIONS :\", predicts[0])\n",
    "print(\"TRUE :\", tags_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following TF tutorial for custom training\n",
    "https://github.com/tensorflow/docs/blob/master/site/en/tutorials/eager/custom_training_walkthrough.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir, pattern, file_type = return_params_mp3_wav(\"mp3\", DATA_DIRECTORY, WAV_DIRECTORY)\n",
    "group_size, sample_size =10, 50\n",
    "train(data_dir, group_size, sample_size, file_type, TRAIN_DIR, EPOCHS, labels, LABELS_NAME, NB_LABELS, \\\n",
    "     BATCH_SIZE, BATCH_NB, LOGDIR, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VERSION 2 : feed group by group\n",
    "def train_v2(group_size=10, sample_size=50):\n",
    "\n",
    "    files_by_group = find_files_group(data_dir, group_size, sample=sample_size, pattern=pattern, sub_dir=TRAIN_DIR)\n",
    "    n_groups = len(files_by_group)\n",
    "\n",
    "    x, y, net, predictions, loss, reduced_loss,  train_op, auc, saver = initialize_tf_model()\n",
    "\n",
    "    print(\"Start training...\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "        sess.run(init)\n",
    "\n",
    "        # Go through the whole DS at each EPOCH\n",
    "        for epoch in tqdm(range(EPOCHS)):\n",
    "\n",
    "            t0_epoch = time.time()\n",
    "\n",
    "            # Group by group\n",
    "            for count, g in enumerate(files_by_group) :\n",
    "\n",
    "                # Load audio and labels\n",
    "                tload0 = time.time()\n",
    "                audios, tags = load_audio_label_aux(labels, g, len(data_dir), labels_name=LABELS_NAME, \\\n",
    "                        nb_labels=NB_LABELS, file_type=file_type, batch_size=BATCH_SIZE, nb_batch=BATCH_NB)\n",
    "                tload1 = time.time()\n",
    "\n",
    "                if count==0 :\n",
    "                    print(\">> Total loading time : {:.2f} sec\".format(tload1-tload0))\n",
    "                #audio_tf = tf.convert_to_tensor(audios, np.float32)\n",
    "\n",
    "                # add check to verify if there is something to restore\n",
    "                #saver.restore(sess, LOGDIR)\n",
    "\n",
    "                predict, _, loss_value, auc_score = sess.run([predictions, train_op, reduced_loss, auc],\\\n",
    "                                                             feed_dict={x: audios, y: tags})\n",
    "                auc_result, update_op = auc_score\n",
    "\n",
    "                saver.save(sess, LOGDIR)\n",
    "\n",
    "\n",
    "                train_loss_results.append(loss_value)\n",
    "                train_auc_results.append(auc_result)\n",
    "\n",
    "                print(\"Group {} done. {} left.\".format(count, n_groups-count))\n",
    "\n",
    "\n",
    "            t1_epoch = time.time()\n",
    "\n",
    "            dur = t1_epoch-t0_epoch\n",
    "\n",
    "            print(\"Iter: {:3}, Time (in sec): {:.2f}, Loss: {:.4f}, AUC : {:.4f}\"\\\n",
    "                  .format(epoch, dur, loss_value, auc_result))\n",
    "            print()\n",
    "\n",
    "        end = time.time()\n",
    "        duration2 = end-start\n",
    "        print(\"Total time: {:.2f} sec.\".format(duration2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and format mp3 data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading audio & tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Use Example \n",
    " load audios and labels > convert to numpy\n",
    " CAREFUL : the argument num_songs is important and shouldn't be too big \n",
    " > otherwise MEMORY ISSUES !!!!!!\n",
    "\n",
    "audios, tags, order, order2 = load_audio_label(cleaned, num_songs=NB_SONGS, sub_dir=TRAIN_DIR, \\\n",
    "                                file_type=\"mp3\", directory=DATA_DIRECTORY, randomize_batch=True) '''\n",
    "\n",
    "def load_audio_label(labels, num_songs, sample_rate=None, directory=WAV_DIRECTORY, \\\n",
    "                     labels_name=LABELS_NAME, sub_dir=None, file_type=\"wav\", randomize_batch=False):\n",
    "    \n",
    "    assert (file_type==\"wav\" or file_type==\"mp3\"), \"The argument file_type should be either 'wav', either 'mp3'.\"\n",
    "    if (file_type==\"wav\" and directory!=WAV_DIRECTORY) or (file_type==\"mp3\" and directory!=DATA_DIRECTORY):\n",
    "        warnings.warn(\"File type and directory may not correspond. Make sure the \\\n",
    "        directory gave as parameter contains the right type of files\", FutureWarning, stacklevel=2)\n",
    "        \n",
    "    if num_songs > 20 :\n",
    "        warnings.warn(\"The argument num_song should not be too high (above 20), make sure this will \\\n",
    "        not cause memory error.\", FutureWarning, stacklevel=2)\n",
    "       \n",
    "    \n",
    "    print(\"Loading data ...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    if file_type==\"mp3\" :\n",
    "        files = find_files(directory, sample=num_songs, sub_dir=sub_dir)\n",
    "    if file_type==\"wav\" :\n",
    "        files = find_files(directory, sample=num_songs, sub_dir=sub_dir, pattern='*.wav')\n",
    " \n",
    "    randomized_files = randomize_files(files)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    audios = np.ndarray(shape=(num_songs * BATCH_NB, BATCH_SIZE, 1), dtype=np.float32, order='F')\n",
    "    tags = np.ndarray(shape=(num_songs * BATCH_NB, NB_LABELS), dtype=np.float32, order='F')\n",
    "    order = np.zeros(num_songs * BATCH_NB, dtype=int)\n",
    "    order2 = np.zeros(num_songs * BATCH_NB, dtype=int)\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    for filename in randomized_files:\n",
    "\n",
    "        # Load audio (MP3/WAV) file        \n",
    "        try :\n",
    "            audio, _ = librosa.load(filename, sr=sample_rate, mono=True)\n",
    "        except EOFError :\n",
    "            print(\"EOFERROR : The following file could not be loaded with librosa - \", filename)\n",
    "\n",
    "        audio = audio.reshape(-1, 1)\n",
    "         \n",
    "        for n in range(BATCH_NB) :\n",
    "            audios[idx] = audio[n*BATCH_SIZE: (n+1)*BATCH_SIZE,:]\n",
    "            \n",
    "            # take labels or corresponding song\n",
    "            \n",
    "            if file_type==\"mp3\" :\n",
    "                select_labels  = labels.loc[labels['mp3_path']==filename[len(directory):]]\n",
    "            \n",
    "            if file_type==\"wav\" :\n",
    "                select_labels  = labels.loc[labels['mp3_path']==filename[len(directory):-4]+\".mp3\"]\n",
    "\n",
    "            # select wanted labels\n",
    "            select_labels = select_labels[labels_name]\n",
    "\n",
    "            tags[idx] = select_labels.values.reshape(NB_LABELS)\n",
    "            \n",
    "            order[idx] = count\n",
    "            order2[idx] = idx\n",
    "            idx +=1\n",
    "        \n",
    "        count +=1\n",
    "        if (count % 10) == 0:\n",
    "            print(count)\n",
    "    \n",
    "    if randomize_batch :\n",
    "        rng_state = np.random.get_state()\n",
    "        np.random.shuffle(audios)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(tags)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(order)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(order2)\n",
    "        \n",
    "    end = time.time()\n",
    "    duration = end-start\n",
    "    print(\">> Total loading time - {} songs : {:.2f} sec\".format(num_songs, duration))\n",
    "    print()\n",
    "    print(\"Shape of audios list :\", audios.shape)\n",
    "    print(\"Shape of tags list :\", tags.shape)\n",
    "    return audios, tags, order, order2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one is not correct yet I think\n",
    "def load_audio_label_prim(labels, num_songs, sample_rate=None, directory=WAV_DIRECTORY, \\\n",
    "                     labels_name=LABELS_NAME, sub_dir=None, file_type=\"wav\", randomize_batch=False):\n",
    "    \n",
    "    \n",
    "    assert (file_type==\"wav\" or file_type==\"mp3\"), \"The argument file_type should be either 'wav', either 'mp3'.\"\n",
    "    if (file_type==\"wav\" and directory!=WAV_DIRECTORY) or (file_type==\"mp3\" and directory!=DATA_DIRECTORY):\n",
    "        warnings.warn(\"File type and directory may not correspond. Make sure the \\\n",
    "        directory gave as parameter contains the right type of files\", FutureWarning, stacklevel=2)\n",
    "        \n",
    "    if num_songs > 20 :\n",
    "        warnings.warn(\"The argument num_song should not be too high (above 20), make sure this will \\\n",
    "        not cause memory error.\", FutureWarning, stacklevel=2)\n",
    "        \n",
    "    print(\"Loading data ...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    if group_size != None:\n",
    "        if file_type==\"mp3\" :\n",
    "            files = find_files_group(directory, group_size, sample=num_songs, sub_dir=sub_dir, pattern='*.mp3')\n",
    "        if file_type==\"wav\" :\n",
    "            files = find_files_group(directory, group_size, sample=num_songs, sub_dir=sub_dir, pattern='*.wav')\n",
    "    \n",
    "    else :\n",
    "        if file_type==\"mp3\" :\n",
    "            files = find_files(directory, sample=num_songs, sub_dir=sub_dir, pattern='*.mp3')\n",
    "        if file_type==\"wav\" :\n",
    "            files = find_files(directory, sample=num_songs, sub_dir=sub_dir, pattern='*.wav')\n",
    "            \n",
    "    randomized_files = randomize_files(files)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    audios = np.ndarray(shape=(num_songs * BATCH_NB, BATCH_SIZE, 1), dtype=np.float32, order='F')\n",
    "    tags = np.ndarray(shape=(num_songs * BATCH_NB, NB_LABELS), dtype=np.float32, order='F')\n",
    "    order = np.zeros(num_songs * BATCH_NB, dtype=int)\n",
    "    order2 = np.zeros(num_songs * BATCH_NB, dtype=int)\n",
    "    \n",
    "\n",
    "    \n",
    "    if group_size != None :\n",
    "        for group in files :\n",
    "            load_audio_label_aux(cleaned, group, len(directory), labels_name=labels_name, file_type=file_type)\n",
    "    \n",
    "    # check where to put this after        \n",
    "    if randomize_batch :\n",
    "        rng_state = np.random.get_state()\n",
    "        np.random.shuffle(audios)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(tags)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(order)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(order2)\n",
    "        \n",
    "    end = time.time()\n",
    "    duration = end-start\n",
    "    print(\">> Total loading time - {} songs : {:.2f} sec\".format(num_songs, duration))\n",
    "    print()\n",
    "    print(\"Shape of audios list :\", audios.shape)\n",
    "    print(\"Shape of tags list :\", tags.shape)\n",
    "    return audios, tags, order, order2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save neural net state tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used for now\n",
    "def save(saver, sess, logdir, step):\n",
    "    model_name = 'model.ckpt'\n",
    "    checkpoint_path = os.path.join(logdir, model_name)\n",
    "    print('Storing checkpoint to {} ...'.format(logdir), end=\"\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if not os.path.exists(logdir):\n",
    "        os.makedirs(logdir)\n",
    "\n",
    "    saver.save(sess, checkpoint_path, global_step=step)\n",
    "    print(' Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean argument passing\n",
    "def merge_predictions(predictions, order, num_songs = NB_SONGS, threshold=0.5, majority=5):\n",
    "    print(\"ORD:\",order)\n",
    "    print(type(predictions[0]))\n",
    "    #tf.map_fn(tf.invert_permutation, (predictions, order))\n",
    "    ordered = tf.gather(predictions, indices=order, axis=0)\n",
    "    \n",
    "    new_predictions = np.zeros(num_songs * BATCH_NB, dtype= np.float32)\n",
    "    \n",
    "    count1 = 0\n",
    "    for b in range(BATCH_NB) :\n",
    "        if ordered[b] > threshold :\n",
    "            count1 +=1\n",
    "            \n",
    "    if count1 >= majority :\n",
    "        for b in range(BATCH_NB) :\n",
    "            new_predictions[b] = 1\n",
    "    \n",
    "    return tf.convert_to_tensor(new_predictions, np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell everytime before relaunching tensorflow session\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VERSION 1 : DOESN'T HANDLE GROUPS - feeds all sample of given size to the network \n",
    "\n",
    "def train_v1() :\n",
    "    \n",
    "    # keep results for plotting\n",
    "    train_loss_results = []\n",
    "    train_auc_results = []\n",
    "\n",
    "    print(\"Initializing tf model ...\")\n",
    "\n",
    "    audio_tf= tf.convert_to_tensor(audios, np.float32)\n",
    "    print(\"Input shape : {}\".format(audio_tf.shape))\n",
    "    print(\"Labels : {}\".format(tags.flatten()))\n",
    "    print()\n",
    "\n",
    "    net = build_model(audio_tf, is_training=True, config=BASIC_CONFIG) \n",
    "    predictions = tf.layers.dense(net, NB_LABELS, activation=tf.sigmoid)\n",
    "    #predictions = merge_predictions(predictions, order2)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = tags, logits = predictions)\n",
    "    reduced_loss = tf.reduce_mean(loss)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(reduced_loss)\n",
    "    auc = tf.metrics.auc(labels = tags, predictions=predictions)\n",
    "\n",
    "\n",
    "    # Saver for storing checkpoints of the model. (Wavenets)\n",
    "    saver = tf.train.Saver(var_list=tf.global_variables())\n",
    "\n",
    "    print(\"Start training...\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "        sess.run(init)\n",
    "\n",
    "        for epoch in tqdm(range(EPOCHS)):\n",
    "            t0_epoch = time.time()\n",
    "            predict, _, loss_value, auc_score = sess.run([predictions, train_op, reduced_loss, auc])\n",
    "            #print(type(predict))\n",
    "            auc_result, update_op = auc_score\n",
    "\n",
    "            train_loss_results.append(loss_value)\n",
    "            train_auc_results.append(auc_result)\n",
    "\n",
    "            t1_epoch = time.time()\n",
    "            dur = t1_epoch-t0_epoch\n",
    "            print(\"Iter: {:3}, Time (in sec): {:.2f}, Loss: {:.4f}, AUC : {:.4f}\".format(epoch,\\\n",
    "                                                                                        dur, \\\n",
    "                                                                                         loss_value, auc_result))\n",
    "            #print(\"Predictions : {}\".format(predict.flatten()))\n",
    "            #print()\n",
    "\n",
    "        # use wavenet function > see later (for now simplest way)\n",
    "        #save(saver, sess, LOGDIR, EPOCHS)\n",
    "        saver.save(sess, LOGDIR)\n",
    "\n",
    "    end = time.time()\n",
    "    duration2 = end-start\n",
    "    print(\"Total time: {:.2f} sec.\".format(duration2))\n",
    "    \n",
    "    return train_loss_results, train_auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import wave\n",
    "#files_by_group = find_files_group(WAV_DIRECTORY, GROUP_SIZE, pattern='*.wav', sub_dir=TRAIN_DIR)\n",
    "\n",
    "#for g in files_by_group:\n",
    "  #  for f in g :\n",
    "   #     print(f)\n",
    "    #    audio = wave.open(f, mode='rb')\n",
    "     #   print(audio.getparams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment1():\n",
    "    GROUP_SIZE=10\n",
    "\n",
    "    files_by_group = find_files_group(WAV_DIRECTORY, GROUP_SIZE, pattern='*.wav', sub_dir=TRAIN_DIR)\n",
    "\n",
    "    print(\"Initialize tf model ...\")\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=(len(files_by_group[0])*BATCH_NB, BATCH_SIZE, 1))\n",
    "    y = tf.placeholder(tf.float32, shape=(len(files_by_group[0])*BATCH_NB, NB_LABELS))\n",
    "\n",
    "    net = build_model(x, is_training=True, config=BASIC_CONFIG) \n",
    "    predictions = tf.layers.dense(net, NB_LABELS, activation=tf.sigmoid)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = y, logits = predictions)\n",
    "    reduced_loss = tf.reduce_mean(loss)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(reduced_loss)\n",
    "    auc = tf.metrics.auc(labels = y, predictions=predictions)\n",
    "\n",
    "    # Saver for storing checkpoints of the model. (Wavenets)\n",
    "    saver = tf.train.Saver(var_list=tf.global_variables())\n",
    "\n",
    "    print(\"Start training...\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "        sess.run(init)\n",
    "\n",
    "        # Go through the whole DS at each EPOCH\n",
    "        for epoch in tqdm(range(EPOCHS)):\n",
    "\n",
    "            t0_epoch = time.time()\n",
    "\n",
    "            # Group by group\n",
    "            for g in files_by_group :\n",
    "\n",
    "                # Load audio and labels\n",
    "                audios, tags = load_audio_label_aux(cleaned, g, len(WAV_DIRECTORY), labels_name=LABELS_NAME, \\\n",
    "                        nb_labels=NB_LABELS, file_type=\"wav\", batch_size=BATCH_SIZE, nb_batch=BATCH_NB)\n",
    "\n",
    "                #audio_tf = tf.convert_to_tensor(audios, np.float32)\n",
    "\n",
    "                # add check to verify if there is something to restore\n",
    "                #saver.restore(sess, LOGDIR)\n",
    "\n",
    "                predict, _, loss_value, auc_score = sess.run([predictions, train_op, reduced_loss, auc],\\\n",
    "                                                             feed_dict={x: audios, y: tags})\n",
    "                auc_result, update_op = auc_score\n",
    "\n",
    "                saver.save(sess, LOGDIR)\n",
    "\n",
    "\n",
    "                train_loss_results.append(loss_value)\n",
    "                train_auc_results.append(auc_result)\n",
    "\n",
    "                print(\"Group done.\")\n",
    "\n",
    "\n",
    "            t1_epoch = time.time()\n",
    "\n",
    "            dur = t1_epoch-t0_epoch\n",
    "\n",
    "            print(\"Iter: {:3}, Time (in sec): {:.2f}, Loss: {:.4f}, AUC : {:.4f}\"\\\n",
    "                  .format(epoch, dur, loss_value, auc_result))\n",
    "\n",
    "\n",
    "\n",
    "        end = time.time()\n",
    "        duration2 = end-start\n",
    "        print(\"Total time: {:.2f} sec.\".format(duration2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 10\n",
    "\n",
    "audios_test, tags_test, order_test, order_test2 = load_audio_label(cleaned, num_songs=TEST_SIZE, sub_dir=TEST_DIR)\n",
    "\n",
    "audios_test_tf = tf.convert_to_tensor(audios_test, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = build_model(audio_tf, is_training=False, config=BASIC_CONFIG) \n",
    "predictions = tf.layers.dense(net, NB_LABELS, activation=tf.sigmoid)\n",
    "#predictions = merge_predictions(predictions, order2)\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = tags, logits = predictions)\n",
    "reduced_loss = tf.reduce_mean(loss)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(reduced_loss)\n",
    "auc = tf.metrics.auc(labels = tags, predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_restore = {\n",
    "    var.name[:-2]: var for var in tf.global_variables()\n",
    "    if not ('state_buffer' in var.name or 'pointer' in var.name)}\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "      # Restore variables from disk.\n",
    "    saver.restore(sess, LOGDIR)\n",
    "    print(\"Model restored.\")\n",
    "    \n",
    "    init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "    sess.run(init) \n",
    "\n",
    "    predicts = sess.run([audios_test_tf, predictions, train_op, reduced_loss, auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some results \n",
    "print(\"AUC Score :\", predicts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PREDICTIONS :\", predicts[1])\n",
    "print(\"TRUE :\", tags_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following TF tutorial for custom training\n",
    "https://github.com/tensorflow/docs/blob/master/site/en/tutorials/eager/custom_training_walkthrough.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
