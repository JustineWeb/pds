{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is this useful ? >> I think yes to avaoid taking all ressources available from the 4 GPUs\n",
    "from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "import fnmatch\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import itertools\n",
    "\n",
    "#import progressbar\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from tools import *\n",
    "from loading import * \n",
    "from labels_analysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTT_DIR = \"../MTT/\"\n",
    "DATA_DIRECTORY = MTT_DIR + \"dataset/\"\n",
    "WAV_DIRECTORY = MTT_DIR + \"wav-dataset/\"\n",
    "\n",
    "# CSV containing song details (title, artist, id, mp3_path,...)\n",
    "CLIP_INFO_FINAL = \"clip_info_final.csv\"\n",
    "# CSV containg the labels (clip_id, labels, mp3_path)\n",
    "ANNOTATIONS_FINAL = \"annotations_final.csv\"\n",
    "# CSV : what is it useful for ?\n",
    "COMPARISONS_FINAL = \"comparisons_final.csv\"\n",
    "LABELS_FILE = MTT_DIR + ANNOTATIONS_FINAL\n",
    "\n",
    "LOGDIR = \"checkpoints/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LTS2 Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines all the needed data paths, when running on LTS2 server.\n",
    "Don't run this cell if you are not running the jupyter notebook on the LTS2 server ! (will overwrite the variables defined on the cell above).\n",
    "\n",
    "You can either create a cell with your own paths, or modify the cell above with your custom paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTT_DIR = \"/mnt/scratch/students/jjgweber-MagnaTagATune/\"\n",
    "DATA_DIRECTORY = MTT_DIR + \"dataset/\"\n",
    "WAV_DIRECTORY = MTT_DIR + \"wav-dataset/\"\n",
    "\n",
    "# CSV containg the labels (clip_id, labels, mp3_path)\n",
    "ANNOTATIONS_FINAL = \"annotations_final.csv\"\n",
    "\n",
    "LABELS_FILE = MTT_DIR + ANNOTATIONS_FINAL\n",
    "\n",
    "# need to create this directory on the server !!\n",
    "LOGDIR = \"checkpoints/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NB = 25880 #25863\n",
    "FILE_LENGTH = 465984\n",
    "# 465984 = 2 × 2 × 2 × 2 × 2 × 2 × 3 × 3 × 809\n",
    "# useful for batches > for now divide by 9 (instead of 10)\n",
    "\n",
    "BATCH_NB = 9\n",
    "BATCH_SIZE = int(FILE_LENGTH/BATCH_NB)\n",
    "SAMPLE_SIZE = 0\n",
    "SAMPLE_RATE = 16000\n",
    "RECEPTIVE_FIELD = 0\n",
    "\n",
    "TRAIN_DIR = \"0123456789abcde\"\n",
    "TEST_DIR =\"f\"\n",
    "\n",
    "BASIC_CONFIG ={'numOutputNeurons':500}\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables which are often modified to test the algorithm\n",
    "NB_SONGS = 20\n",
    "GROUP_SIZE = 20\n",
    "EPOCHS = 16 # check in paper\n",
    "LABELS_NAME = ['guitar', 'techno']\n",
    "NB_LABELS = len(LABELS_NAME)\n",
    "threshold_tag = 0.7\n",
    "majority = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjgweber/pds/loading.py:197: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  labels = pd.read_csv(labels_path, sep = '\"\\t\"')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading csv file : 3.45\n"
     ]
    }
   ],
   "source": [
    "labels, header = load_and_clean_labels(LABELS_FILE)\n",
    "#labels.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs :  25863\n",
      "Number of labels :  188\n",
      "Max number of songs tagged with the same label :  4852\n",
      "Max number of labels for a single song :  27\n"
     ]
    }
   ],
   "source": [
    "nb_labels_per_song, nb_song_per_label, label_header_by_freq = label_stats(labels, header, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_10_labels = label_header_by_freq[:10]\n",
    "best_30_labels = label_header_by_freq[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-occurence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_labels = best_10_labels\n",
    "#check_overlaps(chosen_labels, labels.loc[:,chosen_labels].values.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and format mp3 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training variables \n",
    "TRAIN_DIR = \"0123456789abcde\"\n",
    "EPOCHS = 5\n",
    "BATCH_NB = 9\n",
    "BATCH_SIZE = int(FILE_LENGTH/BATCH_NB)\n",
    "#LOGDIR =\n",
    "LABELS_NAME = ['guitar', 'techno']\n",
    "NB_LABELS = len(LABELS_NAME)\n",
    "LEARNING_RATE = 0.001\n",
    "GROUP_SIZE = 10\n",
    "SAMPLE_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir, pattern, file_type = return_params_mp3_wav(\"mp3\", DATA_DIRECTORY, WAV_DIRECTORY)\n",
    "# also need labels but computed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_tf_model(input_shape, nb_labels, nb_batch, batch_size, learning_rate, is_training=True) :\n",
    "    print(\"Initialize tf model ...\")\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=(input_shape*nb_batch, batch_size, 1))\n",
    "    y = tf.placeholder(tf.float32, shape=(input_shape*nb_batch, nb_labels))\n",
    "\n",
    "    net = build_model(x, is_training=is_training, config=BASIC_CONFIG) \n",
    "    predictions = tf.layers.dense(net, nb_labels, activation=tf.sigmoid)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = y, logits = predictions)\n",
    "    reduced_loss = tf.reduce_mean(loss)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(reduced_loss)\n",
    "    auc = tf.metrics.auc(labels = y, predictions=predictions)\n",
    "    \n",
    "    # Saver for storing checkpoints of the model. (Wavenets)\n",
    "    saver = tf.train.Saver(var_list=tf.global_variables())\n",
    "    \n",
    "    return x, y, net, predictions, loss, reduced_loss,  train_op, auc, saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_dir, group_size, sample_size, file_type, train_dir, epochs, \\\n",
    "          labels, labels_name, nb_labels, batch_size, nb_batch, logdir, learning_rate) :\n",
    "    \n",
    "    pattern = \"\"\n",
    "    if file_type == \"mp3\" :\n",
    "        pattern = \"*.mp3\"\n",
    "    if file_type == \"wav\" :\n",
    "        pattern = \"*.wav\"\n",
    "    else :\n",
    "        print(\"Argument should be either \\\"mp3\\\" or \\\"wav\\\".\")\n",
    "        \n",
    "    # keep results for plotting\n",
    "    train_loss_results = []\n",
    "    train_auc_results = []\n",
    "\n",
    "\n",
    "    files_by_group = find_files_group_select(data_dir, labels, labels_name, group_size, sample=sample_size, \\\n",
    "                                             pattern=pattern, sub_dir=train_dir)\n",
    "    \n",
    "    n_groups = len(files_by_group)\n",
    "    #print(data_dir, labels, labels_name, group_size)\n",
    "\n",
    "    x, y, net, predictions, loss, reduced_loss, \\\n",
    "    train_op, auc, saver = initialize_tf_model(len(files_by_group[0]), nb_labels, nb_batch,\\\n",
    "                                               batch_size, learning_rate)\n",
    "    print(\"Start training...\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "        sess.run(init)\n",
    "\n",
    "        # Go through the whole DS at each EPOCH\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "\n",
    "            t0_epoch = time.time()\n",
    "\n",
    "            # Group by group\n",
    "            for count, g in enumerate(files_by_group) :\n",
    "\n",
    "                # Load audio and labels\n",
    "                tload0 = time.time()\n",
    "                audios, tags = load_audio_label_aux(labels, g, len(data_dir), labels_name=labels_name, \\\n",
    "                        nb_labels=nb_labels, file_type=file_type, batch_size=batch_size, nb_batch=nb_batch)\n",
    "                \n",
    "                tload1 = time.time()\n",
    "\n",
    "                if count==0 :\n",
    "                    print(\">> Total loading time : {:.2f} sec\".format(tload1-tload0))\n",
    "                #audio_tf = tf.convert_to_tensor(audios, np.float32)\n",
    "\n",
    "                # add check to verify if there is something to restore\n",
    "                #saver.restore(sess, LOGDIR)\n",
    "\n",
    "                predict, _, loss_value, auc_score = sess.run([predictions, train_op, reduced_loss, auc],\\\n",
    "                                                             feed_dict={x: audios, y: tags})\n",
    "                auc_result, update_op = auc_score\n",
    "\n",
    "                saver.save(sess, logdir)\n",
    "\n",
    "\n",
    "                train_loss_results.append(loss_value)\n",
    "                train_auc_results.append(auc_result)\n",
    "\n",
    "                print(\"Group {} done. {} left.\".format(count, n_groups-count))\n",
    "\n",
    "\n",
    "            t1_epoch = time.time()\n",
    "\n",
    "            dur = t1_epoch-t0_epoch\n",
    "\n",
    "            print(\"Iter: {:3}, Time (in sec): {:.2f}, Loss: {:.4f}, AUC : {:.4f}\"\\\n",
    "                  .format(epoch, dur, loss_value, auc_result))\n",
    "            print()\n",
    "\n",
    "    end = time.time()\n",
    "    duration2 = end-start\n",
    "    print(\"Total time: {:.2f} sec.\".format(duration2))\n",
    "    return train_loss_results, train_auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all(group_size) :\n",
    "    train_loss_results, train_auc_results = train(data_dir, group_size, None, file_type,\\\n",
    "                                                  TRAIN_DIR, EPOCHS, labels, LABELS_NAME, NB_LABELS, \\\n",
    "                                                  BATCH_SIZE, BATCH_NB, LOGDIR, LEARNING_RATE)\n",
    "    return train_loss_results, train_auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_shape(group_size, sample_size) :\n",
    "    train_loss_results, train_auc_results = train(data_dir, group_size, sample_size, file_type,\\\n",
    "                                                  TRAIN_DIR, EPOCHS, labels, LABELS_NAME, NB_LABELS, \\\n",
    "                                                  BATCH_SIZE, BATCH_NB, LOGDIR, LEARNING_RATE)\n",
    "    return train_loss_results, train_auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_labels_choice(labels_name, nb_labels) :\n",
    "    train_loss_results, train_auc_results = train(data_dir, GROUP_SIZE, SAMPLE_SIZE, file_type, \\\n",
    "                                                  TRAIN_DIR, EPOCHS, labels, labels_name, nb_labels, \\\n",
    "                                                  BATCH_SIZE, BATCH_NB, LOGDIR, LEARNING_RATE)\n",
    "    return train_loss_results, train_auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_learning_rate(l_rate) :\n",
    "    train_loss_results, train_auc_results = train(data_dir, group_size, sample_size, file_type, \\\n",
    "                                                  TRAIN_DIR, EPOCHS, labels, labels_name, nb_labels, \\\n",
    "                                                  BATCH_SIZE, BATCH_NB, LOGDIR, l_rate)\n",
    "    return train_loss_results, train_auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argument should be either \"mp3\" or \"wav\".\n",
      "All labels : 25863 songs >>> Selected for given labels : 7727.\n",
      "Initialize tf model ...\n",
      "Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5801ef1e62ae4cdc934b47216383839d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 songs ...\n",
      ">> Total loading time : 8.68 sec\n",
      "Group 0 done. 352 left.\n",
      "Loading 20 songs ...\n",
      "Group 1 done. 351 left.\n",
      "Loading 20 songs ...\n",
      "Group 2 done. 350 left.\n",
      "Loading 20 songs ...\n",
      "Group 3 done. 349 left.\n",
      "Loading 20 songs ...\n",
      "Group 4 done. 348 left.\n",
      "Loading 20 songs ...\n",
      "Group 5 done. 347 left.\n",
      "Loading 20 songs ...\n",
      "Group 6 done. 346 left.\n",
      "Loading 20 songs ...\n",
      "Group 7 done. 345 left.\n",
      "Loading 20 songs ...\n",
      "Group 8 done. 344 left.\n",
      "Loading 20 songs ...\n",
      "Group 9 done. 343 left.\n",
      "Loading 20 songs ...\n",
      "Group 10 done. 342 left.\n",
      "Loading 20 songs ...\n",
      "Group 11 done. 341 left.\n",
      "Loading 20 songs ...\n",
      "Group 12 done. 340 left.\n",
      "Loading 20 songs ...\n",
      "Group 13 done. 339 left.\n",
      "Loading 20 songs ...\n",
      "Group 14 done. 338 left.\n",
      "Loading 20 songs ...\n",
      "Group 15 done. 337 left.\n",
      "Loading 20 songs ...\n",
      "Group 16 done. 336 left.\n",
      "Loading 20 songs ...\n",
      "Group 17 done. 335 left.\n",
      "Loading 20 songs ...\n",
      "Group 18 done. 334 left.\n",
      "Loading 20 songs ...\n"
     ]
    }
   ],
   "source": [
    "train_loss_results, train_auc_results = train_all(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_auc_loss(train_loss_results, train_auc_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 10\n",
    "\n",
    "test_files = find_files_group(data_dir, test_size, sample=test_size, pattern=pattern, sub_dir=TEST_DIR)\n",
    "\n",
    "audios_test, tags_test = load_audio_label_aux(labels, test_files[0], len(data_dir), labels_name=LABELS_NAME, \\\n",
    "                        nb_labels=NB_LABELS, file_type=file_type, batch_size=BATCH_SIZE, nb_batch=BATCH_NB)\n",
    "#audios_test_tf = tf.convert_to_tensor(audios_test, np.float32)\n",
    "\n",
    "# for testing I guess no need to give several groups to the network ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, net, predictions, loss, reduced_loss,  train_op, auc, saver = initialize_tf_model(len(test_files[0]), \\\n",
    "                                                                                        is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_restore = {\n",
    "    var.name[:-2]: var for var in tf.global_variables()\n",
    "    if not ('state_buffer' in var.name or 'pointer' in var.name)}\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "      # Restore variables from disk.\n",
    "    saver.restore(sess, LOGDIR)\n",
    "    print(\"Model restored.\")\n",
    "    \n",
    "    init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "    sess.run(init) \n",
    "\n",
    "    predicts = sess.run([predictions, train_op, reduced_loss, auc], \\\n",
    "                        feed_dict={x: audios_test, y: tags_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some results \n",
    "print(\"AUC Score :\", predicts[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PREDICTIONS :\", predicts[0])\n",
    "print(\"TRUE :\", tags_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following TF tutorial for custom training\n",
    "https://github.com/tensorflow/docs/blob/master/site/en/tutorials/eager/custom_training_walkthrough.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir, pattern, file_type = return_params_mp3_wav(\"mp3\", DATA_DIRECTORY, WAV_DIRECTORY)\n",
    "group_size, sample_size =10, 50\n",
    "train(data_dir, group_size, sample_size, file_type, TRAIN_DIR, EPOCHS, labels, LABELS_NAME, NB_LABELS, \\\n",
    "     BATCH_SIZE, BATCH_NB, LOGDIR, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VERSION 2 : feed group by group\n",
    "def train_v2(group_size=10, sample_size=50):\n",
    "\n",
    "    files_by_group = find_files_group(data_dir, group_size, sample=sample_size, pattern=pattern, sub_dir=TRAIN_DIR)\n",
    "    n_groups = len(files_by_group)\n",
    "\n",
    "    x, y, net, predictions, loss, reduced_loss,  train_op, auc, saver = initialize_tf_model()\n",
    "\n",
    "    print(\"Start training...\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "        sess.run(init)\n",
    "\n",
    "        # Go through the whole DS at each EPOCH\n",
    "        for epoch in tqdm(range(EPOCHS)):\n",
    "\n",
    "            t0_epoch = time.time()\n",
    "\n",
    "            # Group by group\n",
    "            for count, g in enumerate(files_by_group) :\n",
    "\n",
    "                # Load audio and labels\n",
    "                tload0 = time.time()\n",
    "                audios, tags = load_audio_label_aux(labels, g, len(data_dir), labels_name=LABELS_NAME, \\\n",
    "                        nb_labels=NB_LABELS, file_type=file_type, batch_size=BATCH_SIZE, nb_batch=BATCH_NB)\n",
    "                tload1 = time.time()\n",
    "\n",
    "                if count==0 :\n",
    "                    print(\">> Total loading time : {:.2f} sec\".format(tload1-tload0))\n",
    "                #audio_tf = tf.convert_to_tensor(audios, np.float32)\n",
    "\n",
    "                # add check to verify if there is something to restore\n",
    "                #saver.restore(sess, LOGDIR)\n",
    "\n",
    "                predict, _, loss_value, auc_score = sess.run([predictions, train_op, reduced_loss, auc],\\\n",
    "                                                             feed_dict={x: audios, y: tags})\n",
    "                auc_result, update_op = auc_score\n",
    "\n",
    "                saver.save(sess, LOGDIR)\n",
    "\n",
    "\n",
    "                train_loss_results.append(loss_value)\n",
    "                train_auc_results.append(auc_result)\n",
    "\n",
    "                print(\"Group {} done. {} left.\".format(count, n_groups-count))\n",
    "\n",
    "\n",
    "            t1_epoch = time.time()\n",
    "\n",
    "            dur = t1_epoch-t0_epoch\n",
    "\n",
    "            print(\"Iter: {:3}, Time (in sec): {:.2f}, Loss: {:.4f}, AUC : {:.4f}\"\\\n",
    "                  .format(epoch, dur, loss_value, auc_result))\n",
    "            print()\n",
    "\n",
    "        end = time.time()\n",
    "        duration2 = end-start\n",
    "        print(\"Total time: {:.2f} sec.\".format(duration2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and format mp3 data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading audio & tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Use Example \n",
    " load audios and labels > convert to numpy\n",
    " CAREFUL : the argument num_songs is important and shouldn't be too big \n",
    " > otherwise MEMORY ISSUES !!!!!!\n",
    "\n",
    "audios, tags, order, order2 = load_audio_label(cleaned, num_songs=NB_SONGS, sub_dir=TRAIN_DIR, \\\n",
    "                                file_type=\"mp3\", directory=DATA_DIRECTORY, randomize_batch=True) '''\n",
    "\n",
    "def load_audio_label(labels, num_songs, sample_rate=None, directory=WAV_DIRECTORY, \\\n",
    "                     labels_name=LABELS_NAME, sub_dir=None, file_type=\"wav\", randomize_batch=False):\n",
    "    \n",
    "    assert (file_type==\"wav\" or file_type==\"mp3\"), \"The argument file_type should be either 'wav', either 'mp3'.\"\n",
    "    if (file_type==\"wav\" and directory!=WAV_DIRECTORY) or (file_type==\"mp3\" and directory!=DATA_DIRECTORY):\n",
    "        warnings.warn(\"File type and directory may not correspond. Make sure the \\\n",
    "        directory gave as parameter contains the right type of files\", FutureWarning, stacklevel=2)\n",
    "        \n",
    "    if num_songs > 20 :\n",
    "        warnings.warn(\"The argument num_song should not be too high (above 20), make sure this will \\\n",
    "        not cause memory error.\", FutureWarning, stacklevel=2)\n",
    "       \n",
    "    \n",
    "    print(\"Loading data ...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    if file_type==\"mp3\" :\n",
    "        files = find_files(directory, sample=num_songs, sub_dir=sub_dir)\n",
    "    if file_type==\"wav\" :\n",
    "        files = find_files(directory, sample=num_songs, sub_dir=sub_dir, pattern='*.wav')\n",
    " \n",
    "    randomized_files = randomize_files(files)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    audios = np.ndarray(shape=(num_songs * BATCH_NB, BATCH_SIZE, 1), dtype=np.float32, order='F')\n",
    "    tags = np.ndarray(shape=(num_songs * BATCH_NB, NB_LABELS), dtype=np.float32, order='F')\n",
    "    order = np.zeros(num_songs * BATCH_NB, dtype=int)\n",
    "    order2 = np.zeros(num_songs * BATCH_NB, dtype=int)\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    for filename in randomized_files:\n",
    "\n",
    "        # Load audio (MP3/WAV) file        \n",
    "        try :\n",
    "            audio, _ = librosa.load(filename, sr=sample_rate, mono=True)\n",
    "        except EOFError :\n",
    "            print(\"EOFERROR : The following file could not be loaded with librosa - \", filename)\n",
    "\n",
    "        audio = audio.reshape(-1, 1)\n",
    "         \n",
    "        for n in range(BATCH_NB) :\n",
    "            audios[idx] = audio[n*BATCH_SIZE: (n+1)*BATCH_SIZE,:]\n",
    "            \n",
    "            # take labels or corresponding song\n",
    "            \n",
    "            if file_type==\"mp3\" :\n",
    "                select_labels  = labels.loc[labels['mp3_path']==filename[len(directory):]]\n",
    "            \n",
    "            if file_type==\"wav\" :\n",
    "                select_labels  = labels.loc[labels['mp3_path']==filename[len(directory):-4]+\".mp3\"]\n",
    "\n",
    "            # select wanted labels\n",
    "            select_labels = select_labels[labels_name]\n",
    "\n",
    "            tags[idx] = select_labels.values.reshape(NB_LABELS)\n",
    "            \n",
    "            order[idx] = count\n",
    "            order2[idx] = idx\n",
    "            idx +=1\n",
    "        \n",
    "        count +=1\n",
    "        if (count % 10) == 0:\n",
    "            print(count)\n",
    "    \n",
    "    if randomize_batch :\n",
    "        rng_state = np.random.get_state()\n",
    "        np.random.shuffle(audios)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(tags)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(order)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(order2)\n",
    "        \n",
    "    end = time.time()\n",
    "    duration = end-start\n",
    "    print(\">> Total loading time - {} songs : {:.2f} sec\".format(num_songs, duration))\n",
    "    print()\n",
    "    print(\"Shape of audios list :\", audios.shape)\n",
    "    print(\"Shape of tags list :\", tags.shape)\n",
    "    return audios, tags, order, order2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one is not correct yet I think\n",
    "def load_audio_label_prim(labels, num_songs, sample_rate=None, directory=WAV_DIRECTORY, \\\n",
    "                     labels_name=LABELS_NAME, sub_dir=None, file_type=\"wav\", randomize_batch=False):\n",
    "    \n",
    "    \n",
    "    assert (file_type==\"wav\" or file_type==\"mp3\"), \"The argument file_type should be either 'wav', either 'mp3'.\"\n",
    "    if (file_type==\"wav\" and directory!=WAV_DIRECTORY) or (file_type==\"mp3\" and directory!=DATA_DIRECTORY):\n",
    "        warnings.warn(\"File type and directory may not correspond. Make sure the \\\n",
    "        directory gave as parameter contains the right type of files\", FutureWarning, stacklevel=2)\n",
    "        \n",
    "    if num_songs > 20 :\n",
    "        warnings.warn(\"The argument num_song should not be too high (above 20), make sure this will \\\n",
    "        not cause memory error.\", FutureWarning, stacklevel=2)\n",
    "        \n",
    "    print(\"Loading data ...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    if group_size != None:\n",
    "        if file_type==\"mp3\" :\n",
    "            files = find_files_group(directory, group_size, sample=num_songs, sub_dir=sub_dir, pattern='*.mp3')\n",
    "        if file_type==\"wav\" :\n",
    "            files = find_files_group(directory, group_size, sample=num_songs, sub_dir=sub_dir, pattern='*.wav')\n",
    "    \n",
    "    else :\n",
    "        if file_type==\"mp3\" :\n",
    "            files = find_files(directory, sample=num_songs, sub_dir=sub_dir, pattern='*.mp3')\n",
    "        if file_type==\"wav\" :\n",
    "            files = find_files(directory, sample=num_songs, sub_dir=sub_dir, pattern='*.wav')\n",
    "            \n",
    "    randomized_files = randomize_files(files)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    audios = np.ndarray(shape=(num_songs * BATCH_NB, BATCH_SIZE, 1), dtype=np.float32, order='F')\n",
    "    tags = np.ndarray(shape=(num_songs * BATCH_NB, NB_LABELS), dtype=np.float32, order='F')\n",
    "    order = np.zeros(num_songs * BATCH_NB, dtype=int)\n",
    "    order2 = np.zeros(num_songs * BATCH_NB, dtype=int)\n",
    "    \n",
    "\n",
    "    \n",
    "    if group_size != None :\n",
    "        for group in files :\n",
    "            load_audio_label_aux(cleaned, group, len(directory), labels_name=labels_name, file_type=file_type)\n",
    "    \n",
    "    # check where to put this after        \n",
    "    if randomize_batch :\n",
    "        rng_state = np.random.get_state()\n",
    "        np.random.shuffle(audios)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(tags)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(order)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(order2)\n",
    "        \n",
    "    end = time.time()\n",
    "    duration = end-start\n",
    "    print(\">> Total loading time - {} songs : {:.2f} sec\".format(num_songs, duration))\n",
    "    print()\n",
    "    print(\"Shape of audios list :\", audios.shape)\n",
    "    print(\"Shape of tags list :\", tags.shape)\n",
    "    return audios, tags, order, order2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save neural net state tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used for now\n",
    "def save(saver, sess, logdir, step):\n",
    "    model_name = 'model.ckpt'\n",
    "    checkpoint_path = os.path.join(logdir, model_name)\n",
    "    print('Storing checkpoint to {} ...'.format(logdir), end=\"\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if not os.path.exists(logdir):\n",
    "        os.makedirs(logdir)\n",
    "\n",
    "    saver.save(sess, checkpoint_path, global_step=step)\n",
    "    print(' Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean argument passing\n",
    "def merge_predictions(predictions, order, num_songs = NB_SONGS, threshold=0.5, majority=5):\n",
    "    print(\"ORD:\",order)\n",
    "    print(type(predictions[0]))\n",
    "    #tf.map_fn(tf.invert_permutation, (predictions, order))\n",
    "    ordered = tf.gather(predictions, indices=order, axis=0)\n",
    "    \n",
    "    new_predictions = np.zeros(num_songs * BATCH_NB, dtype= np.float32)\n",
    "    \n",
    "    count1 = 0\n",
    "    for b in range(BATCH_NB) :\n",
    "        if ordered[b] > threshold :\n",
    "            count1 +=1\n",
    "            \n",
    "    if count1 >= majority :\n",
    "        for b in range(BATCH_NB) :\n",
    "            new_predictions[b] = 1\n",
    "    \n",
    "    return tf.convert_to_tensor(new_predictions, np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell everytime before relaunching tensorflow session\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VERSION 1 : DOESN'T HANDLE GROUPS - feeds all sample of given size to the network \n",
    "\n",
    "def train_v1() :\n",
    "    \n",
    "    # keep results for plotting\n",
    "    train_loss_results = []\n",
    "    train_auc_results = []\n",
    "\n",
    "    print(\"Initializing tf model ...\")\n",
    "\n",
    "    audio_tf= tf.convert_to_tensor(audios, np.float32)\n",
    "    print(\"Input shape : {}\".format(audio_tf.shape))\n",
    "    print(\"Labels : {}\".format(tags.flatten()))\n",
    "    print()\n",
    "\n",
    "    net = build_model(audio_tf, is_training=True, config=BASIC_CONFIG) \n",
    "    predictions = tf.layers.dense(net, NB_LABELS, activation=tf.sigmoid)\n",
    "    #predictions = merge_predictions(predictions, order2)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = tags, logits = predictions)\n",
    "    reduced_loss = tf.reduce_mean(loss)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(reduced_loss)\n",
    "    auc = tf.metrics.auc(labels = tags, predictions=predictions)\n",
    "\n",
    "\n",
    "    # Saver for storing checkpoints of the model. (Wavenets)\n",
    "    saver = tf.train.Saver(var_list=tf.global_variables())\n",
    "\n",
    "    print(\"Start training...\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "        sess.run(init)\n",
    "\n",
    "        for epoch in tqdm(range(EPOCHS)):\n",
    "            t0_epoch = time.time()\n",
    "            predict, _, loss_value, auc_score = sess.run([predictions, train_op, reduced_loss, auc])\n",
    "            #print(type(predict))\n",
    "            auc_result, update_op = auc_score\n",
    "\n",
    "            train_loss_results.append(loss_value)\n",
    "            train_auc_results.append(auc_result)\n",
    "\n",
    "            t1_epoch = time.time()\n",
    "            dur = t1_epoch-t0_epoch\n",
    "            print(\"Iter: {:3}, Time (in sec): {:.2f}, Loss: {:.4f}, AUC : {:.4f}\".format(epoch,\\\n",
    "                                                                                        dur, \\\n",
    "                                                                                         loss_value, auc_result))\n",
    "            #print(\"Predictions : {}\".format(predict.flatten()))\n",
    "            #print()\n",
    "\n",
    "        # use wavenet function > see later (for now simplest way)\n",
    "        #save(saver, sess, LOGDIR, EPOCHS)\n",
    "        saver.save(sess, LOGDIR)\n",
    "\n",
    "    end = time.time()\n",
    "    duration2 = end-start\n",
    "    print(\"Total time: {:.2f} sec.\".format(duration2))\n",
    "    \n",
    "    return train_loss_results, train_auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import wave\n",
    "#files_by_group = find_files_group(WAV_DIRECTORY, GROUP_SIZE, pattern='*.wav', sub_dir=TRAIN_DIR)\n",
    "\n",
    "#for g in files_by_group:\n",
    "  #  for f in g :\n",
    "   #     print(f)\n",
    "    #    audio = wave.open(f, mode='rb')\n",
    "     #   print(audio.getparams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment1():\n",
    "    GROUP_SIZE=10\n",
    "\n",
    "    files_by_group = find_files_group(WAV_DIRECTORY, GROUP_SIZE, pattern='*.wav', sub_dir=TRAIN_DIR)\n",
    "\n",
    "    print(\"Initialize tf model ...\")\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=(len(files_by_group[0])*BATCH_NB, BATCH_SIZE, 1))\n",
    "    y = tf.placeholder(tf.float32, shape=(len(files_by_group[0])*BATCH_NB, NB_LABELS))\n",
    "\n",
    "    net = build_model(x, is_training=True, config=BASIC_CONFIG) \n",
    "    predictions = tf.layers.dense(net, NB_LABELS, activation=tf.sigmoid)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = y, logits = predictions)\n",
    "    reduced_loss = tf.reduce_mean(loss)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(reduced_loss)\n",
    "    auc = tf.metrics.auc(labels = y, predictions=predictions)\n",
    "\n",
    "    # Saver for storing checkpoints of the model. (Wavenets)\n",
    "    saver = tf.train.Saver(var_list=tf.global_variables())\n",
    "\n",
    "    print(\"Start training...\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "        sess.run(init)\n",
    "\n",
    "        # Go through the whole DS at each EPOCH\n",
    "        for epoch in tqdm(range(EPOCHS)):\n",
    "\n",
    "            t0_epoch = time.time()\n",
    "\n",
    "            # Group by group\n",
    "            for g in files_by_group :\n",
    "\n",
    "                # Load audio and labels\n",
    "                audios, tags = load_audio_label_aux(cleaned, g, len(WAV_DIRECTORY), labels_name=LABELS_NAME, \\\n",
    "                        nb_labels=NB_LABELS, file_type=\"wav\", batch_size=BATCH_SIZE, nb_batch=BATCH_NB)\n",
    "\n",
    "                #audio_tf = tf.convert_to_tensor(audios, np.float32)\n",
    "\n",
    "                # add check to verify if there is something to restore\n",
    "                #saver.restore(sess, LOGDIR)\n",
    "\n",
    "                predict, _, loss_value, auc_score = sess.run([predictions, train_op, reduced_loss, auc],\\\n",
    "                                                             feed_dict={x: audios, y: tags})\n",
    "                auc_result, update_op = auc_score\n",
    "\n",
    "                saver.save(sess, LOGDIR)\n",
    "\n",
    "\n",
    "                train_loss_results.append(loss_value)\n",
    "                train_auc_results.append(auc_result)\n",
    "\n",
    "                print(\"Group done.\")\n",
    "\n",
    "\n",
    "            t1_epoch = time.time()\n",
    "\n",
    "            dur = t1_epoch-t0_epoch\n",
    "\n",
    "            print(\"Iter: {:3}, Time (in sec): {:.2f}, Loss: {:.4f}, AUC : {:.4f}\"\\\n",
    "                  .format(epoch, dur, loss_value, auc_result))\n",
    "\n",
    "\n",
    "\n",
    "        end = time.time()\n",
    "        duration2 = end-start\n",
    "        print(\"Total time: {:.2f} sec.\".format(duration2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 10\n",
    "\n",
    "audios_test, tags_test, order_test, order_test2 = load_audio_label(cleaned, num_songs=TEST_SIZE, sub_dir=TEST_DIR)\n",
    "\n",
    "audios_test_tf = tf.convert_to_tensor(audios_test, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = build_model(audio_tf, is_training=False, config=BASIC_CONFIG) \n",
    "predictions = tf.layers.dense(net, NB_LABELS, activation=tf.sigmoid)\n",
    "#predictions = merge_predictions(predictions, order2)\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = tags, logits = predictions)\n",
    "reduced_loss = tf.reduce_mean(loss)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(reduced_loss)\n",
    "auc = tf.metrics.auc(labels = tags, predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_restore = {\n",
    "    var.name[:-2]: var for var in tf.global_variables()\n",
    "    if not ('state_buffer' in var.name or 'pointer' in var.name)}\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "      # Restore variables from disk.\n",
    "    saver.restore(sess, LOGDIR)\n",
    "    print(\"Model restored.\")\n",
    "    \n",
    "    init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "    sess.run(init) \n",
    "\n",
    "    predicts = sess.run([audios_test_tf, predictions, train_op, reduced_loss, auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some results \n",
    "print(\"AUC Score :\", predicts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PREDICTIONS :\", predicts[1])\n",
    "print(\"TRUE :\", tags_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following TF tutorial for custom training\n",
    "https://github.com/tensorflow/docs/blob/master/site/en/tutorials/eager/custom_training_walkthrough.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
